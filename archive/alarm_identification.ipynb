{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd0e2bfb1b1dd0bcdebdb315279aa118b1f834444d4ba3ba6d660e9f6ce7703f6a2",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e2bfb1b1dd0bcdebdb315279aa118b1f834444d4ba3ba6d660e9f6ce7703f6a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Identify Alarms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Get unqiue ICU stays in CHARTEVENTS.csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CHARTEVENTS into Dask DataFrame (parallel DataFrame composed of many smaller Pandas DataFrames)\n",
    "import dask.dataframe as dd\n",
    "chartevents = dd.read_csv('./mimic/CHARTEVENTS.csv', dtype={\n",
    "    'ICUSTAY_ID': 'float64','CGID': 'float64','ERROR': 'float64','STOPPED': 'object','VALUE': 'object','WARNING': 'float64','RESULTSTATUS': 'object'})\n",
    "chartevents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "with ProgressBar():\n",
    "    unique_icustays = pd.Series(chartevents.ICUSTAY_ID.unique().compute())\n",
    "    # Computing duration on Marius' laptop (Intel i5-5200U CPU @ 2.20GHz): 11min 15.4s\n",
    "    # Note: The progress bar does not progress consistently, but jumps, e.g. in this calculation, in the second half.\n",
    "\n",
    "display(unique_icustays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save unique_icustays as parquet file\n",
    "pd.DataFrame(unique_icustays).to_parquet('./icustays/unique_icustays.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read unique_icustays from parquet file\n",
    "import pandas as pd\n",
    "unique_icustays = pd.read_parquet('./icustays/unique_icustays.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read unique_icustays from parquet file to dask data frame\n",
    "import dask.dataframe as dd\n",
    "unique_icustays = dd.read_parquet('./icustays/unique_icustays.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Create subset of CHARTEVENTS by filtering for selected ITEMIDs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ITEMIDs to be filtered by\n",
    "itemid_filter = [220045, 220046, 220047, 220179, 223751, 223752, 220180, 220277, 223769, 223770]\n",
    "# 220045 Heart Rate\n",
    "# 220046 Heart rate Alarm - High\n",
    "# 220047 Heart Rate Alarm - Low\n",
    "# 220179 Non Invasive Blood Pressure systolic\n",
    "# 223751 Non-Invasive Blood Pressure Alarm - High\n",
    "# 223752 Non-Invasive Blood Pressure Alarm - Low\n",
    "# 220180 Non Invasive Blood Pressure diastolic\n",
    "# 220277 O2 saturation pulseoxymetry\n",
    "# 223769 O2 Saturation Pulseoxymetry Alarm - High\n",
    "# 223770 O2 Saturation Pulseoxymetry Alarm - Low\n",
    "\n",
    "import pandas as pd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "with ProgressBar():\n",
    "    chartevents_subset = chartevents[chartevents.ITEMID.isin(itemid_filter)].compute()\n",
    "    # Computing duration on Marius' laptop (Intel i5-5200U CPU @ 2.20GHz): 12min 26.5s\n",
    "\n",
    "display(chartevents_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_subset as parquet file\n",
    "pd.DataFrame(chartevents_subset).to_parquet('./icustays/chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "import pandas as pd\n",
    "chartevents_subset = pd.read_parquet('./icustays/chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read chartevents_subset from parquet file to dask data frame\n",
    "import dask.dataframe as dd\n",
    "chartevents_subset = dd.read_parquet('./icustays/chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Get unqiue ICU stays in chartevents_subset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "import pandas as pd\n",
    "chartevents_subset = pd.read_parquet('./icustays/chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute unqiue ICU stays in chartevents_subset \n",
    "unique_icustays_in_chartevents_subset = pd.Series(chartevents_subset.ICUSTAY_ID.unique()).rename('ICUSTAY_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save unique_icustays as parquet file\n",
    "pd.DataFrame(unique_icustays_in_chartevents_subset).to_parquet('./icustays/unique_icustays_in_chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read unique_icustays_in_chartevents_subset from parquet file to pandas data frame\n",
    "import pandas as pd\n",
    "unique_icustays_in_chartevents_subset = pd.read_parquet('./icustays/unique_icustays_in_chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Identify alarms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow up: What happens of the itemid is not available for the icustay?\n",
    "# Note: writing to parquet requires to convert int64 columns to string columns, which must be considered when using them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create data frame with the ITEMDIDs of the vital parameter and associated alarm thresholds to filter by.\n",
    "# We could also store this in a CSV file later and read it from there.\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "display(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents from parquet file to pandas data frame\n",
    "chartevents = pd.read_parquet('./icustays/chartevents_subset.parquet', engine='pyarrow')\n",
    "\n",
    "# Read unique_icustays from parquet file\n",
    "unique_icustays = pd.read_parquet('./icustays/unique_icustays_in_chartevents_subset.parquet', engine='pyarrow')\n",
    "unique_icustays = unique_icustays['ICUSTAY_ID']\n",
    "unique_icustays = unique_icustays[3000:3999] # [0:999] # [1000:1999] # [2000:2999] ...\n",
    "\n",
    "# unique_icustays = [269851.0] # For test pruposes\n",
    "\n",
    "# Path of the folder in which the individual files are stored (one parquet file per ICU Stay)\n",
    "path_to_dir = './icustays/'\n",
    "\n",
    "# Create an empty dictionary in which the merged time series will be stored. \n",
    "merged_time_series = dict()\n",
    "\n",
    "# Create an empty dictionary in which the merged, triggered alarms will be stored.\n",
    "merged_alarm_series = dict()\n",
    "\n",
    "for icustay in unique_icustays:\n",
    "    \n",
    "    # Create an empty dictionary in which the individual time series will be stored.\n",
    "    single_time_series = dict()\n",
    "\n",
    "    # Create an empty dictionary in which the triggered alarms will be stored.\n",
    "    single_alarm_series = dict()\n",
    "    \n",
    "    for i, parameter in parameters.iterrows():\n",
    "\n",
    "        # For each parameter, create three time-indexed series\n",
    "        # One series for the vital parameter value, one for the high alarm threshold, and one for the low alarm threshold.\n",
    "        # Important: The series must be sorted by CHARTTIME before setting the index!\n",
    "        # Otherwise, errors may occur later during the interpolation because the 'previous value' may not be the temporally preceding value.\n",
    "        single_time_series[parameter['LABEL'] + '_VALUE'] = chartevents[(chartevents[\"ICUSTAY_ID\"] == icustay) & (chartevents[\"ITEMID\"] == parameter['VALUE'])][\n",
    "            ['CHARTTIME','VALUENUM']\n",
    "            ].sort_values(by=['CHARTTIME']).set_index('CHARTTIME').squeeze(axis=1).rename(parameter['VALUE'])\n",
    "        \n",
    "        single_time_series[parameter['LABEL'] + '_THRESHOLD_HIGH'] = chartevents[(chartevents[\"ICUSTAY_ID\"] == icustay) & (chartevents[\"ITEMID\"] == parameter['THRESHOLD_HIGH'])][\n",
    "            ['CHARTTIME','VALUENUM']\n",
    "            ].sort_values(by=['CHARTTIME']).set_index('CHARTTIME').squeeze(axis=1).rename(parameter['THRESHOLD_HIGH'])\n",
    "        \n",
    "        single_time_series[parameter['LABEL'] + '_THRESHOLD_LOW'] = chartevents[(chartevents[\"ICUSTAY_ID\"] == icustay) & (chartevents[\"ITEMID\"] == parameter['THRESHOLD_LOW'])][\n",
    "            ['CHARTTIME','VALUENUM']\n",
    "            ].sort_values(by=['CHARTTIME']).set_index('CHARTTIME').squeeze(axis=1).rename(parameter['THRESHOLD_LOW'])\n",
    "\n",
    "    else:\n",
    "        None\n",
    "    \n",
    "    # Merge the individual time-indexed series into one data frame\n",
    "    merged_time_series[icustay] = pd.concat(single_time_series, axis=1)\n",
    "    # Convert index to datetime format\n",
    "    merged_time_series[icustay].index = pd.to_datetime(merged_time_series[icustay].index)\n",
    "    # Interpolate missing values using the last available value.\n",
    "    # If there is no previous value available, no value will be inserted during the interpolation. The value remains NaN.\n",
    "    # Note: Currently, vital parameters and alarm thresholds are not differentiated, so interpolation is also applied to vital parameters.\n",
    "    # We may need to reconsider the interpolation of vital parameters since these may change between measurements (as opposed to the alarm limits for which changes are always recorded).\n",
    "    merged_time_series[icustay] = merged_time_series[icustay].interpolate('pad')\n",
    "    \n",
    "    \"\"\"\n",
    "    # Save merged_time_series of the ICU stay as parquet file\n",
    "    # To do so the int64 column names have to be converted to strings, because parquet must have string column names.\n",
    "    merged_time_series[icustay].columns = merged_time_series[icustay].columns.astype(str)\n",
    "    merged_time_series[icustay].to_parquet(f'{path_to_dir}{icustay}.parquet', engine='pyarrow')\n",
    "    \"\"\"\n",
    "\n",
    "    # For each parameter, add two columns to the merged_time_series dataframe\n",
    "    # One column contains the difference between the vital parameter value and the high alarm threshold; one the difference between the  vital parameter value and the low alarm limit\n",
    "    # Subsequently, identify triggered alarms\n",
    "    for i, parameter in parameters.iterrows():\n",
    "        merged_time_series[icustay]['DIF_' + parameter['LABEL'] + '_VALUE_THRESHOLD_HIGH'] = merged_time_series[icustay][parameter['LABEL'] + '_VALUE'] - merged_time_series[icustay][parameter['LABEL'] + '_THRESHOLD_HIGH']\n",
    "        merged_time_series[icustay]['DIF_' + parameter['LABEL'] + '_VALUE_THRESHOLD_LOW'] = merged_time_series[icustay][parameter['LABEL'] + '_VALUE'] - merged_time_series[icustay][parameter['LABEL'] + '_THRESHOLD_LOW']\n",
    "        \n",
    "        alarm_high = pd.DataFrame(merged_time_series[icustay][(merged_time_series[icustay]['DIF_' + parameter['LABEL'] + '_VALUE_THRESHOLD_HIGH'] >= 0)].reset_index()[[\n",
    "            'CHARTTIME',\n",
    "            str(parameter['LABEL'] + '_VALUE')\n",
    "            ]])\n",
    "        alarm_high = alarm_high.rename(columns={\n",
    "            str(parameter['LABEL'] + '_VALUE') : 'PARAMETER_VALUENUM'})\n",
    "        alarm_high = alarm_high.assign(\n",
    "            ICUSTAY_ID=icustay,\n",
    "            PARAMETER_ITEMID=parameter['VALUE'],\n",
    "            CROSSED_THRESHOLD_ITEMID=parameter['THRESHOLD_HIGH'],\n",
    "            CROSSED_THRESHOLD_TYPE='HIGH')\n",
    "        single_alarm_series[parameter['LABEL'] + '_ALARM_HIGH'] = alarm_high\n",
    "\n",
    "        alarm_low = pd.DataFrame(merged_time_series[icustay][(merged_time_series[icustay]['DIF_' + parameter['LABEL'] + '_VALUE_THRESHOLD_LOW'] <= 0)].reset_index()[[\n",
    "            'CHARTTIME',\n",
    "            str(parameter['LABEL'] + '_VALUE')\n",
    "            ]])\n",
    "        alarm_low = alarm_low.rename(columns={\n",
    "            str(parameter['LABEL'] + '_VALUE') : 'PARAMETER_VALUENUM'})\n",
    "        alarm_low = alarm_low.assign(\n",
    "            ICUSTAY_ID=icustay,\n",
    "            PARAMETER_ITEMID=parameter['VALUE'],\n",
    "            CROSSED_THRESHOLD_ITEMID=parameter['THRESHOLD_LOW'],\n",
    "            CROSSED_THRESHOLD_TYPE='LOW')\n",
    "        single_alarm_series[parameter['LABEL'] + '_ALARM_LOW'] = alarm_low\n",
    "\n",
    "    else:\n",
    "        None\n",
    "\n",
    "    merged_alarm_series[icustay] = pd.concat(single_alarm_series, axis=0)\n",
    "    merged_alarm_series[icustay].index = merged_alarm_series[icustay].index.droplevel()\n",
    "    merged_alarm_series[icustay] = merged_alarm_series[icustay][['ICUSTAY_ID','PARAMETER_ITEMID','CHARTTIME','PARAMETER_VALUENUM','CROSSED_THRESHOLD_ITEMID','CROSSED_THRESHOLD_TYPE']]\n",
    "    merged_alarm_series[icustay] = merged_alarm_series[icustay].sort_values(by=['CHARTTIME'],ignore_index=True)\n",
    "\n",
    "else:\n",
    "    None\n",
    "\n",
    "all_triggered_alarms = pd.concat(merged_alarm_series, axis=0)\n",
    "all_triggered_alarms.index = all_triggered_alarms.index.droplevel()\n",
    "all_triggered_alarms = all_triggered_alarms.reset_index(drop=True)\n",
    "all_triggered_alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_triggered_alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all_triggered_alarms as parquet file\n",
    "all_triggered_alarms.to_parquet(f'{path_to_dir}triggered_alarms_3000_3999.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read triggered alarms from parquet file\n",
    "# import pandas as pd\n",
    "# triggered_alarms = pd.read_parquet('./icustays/triggered_alarms_2000_2999.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Debug\n",
    "\"\"\"\n",
    "Failed with icustay 269851.0\n",
    "ValueError: cannot reindex from a duplicate axis\n",
    "\n",
    "pd.concat(single_time_series, axis=1) does not work\n",
    "\"\"\""
   ]
  }
 ]
}