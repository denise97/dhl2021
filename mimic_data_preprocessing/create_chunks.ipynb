{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0c24247fa39158f46a54dbb99bb8811b81cd84bf3c9aa6e8294d53a41a5837da9",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Perform  Parameter-Specific Chunking on Vital Parameters\n",
    "Based on the visual analysis (derive_chunking_rules.ipynb), we derived two possible chunking options:\n",
    "* Chunk after 60 min timedelta to previous measurement\n",
    "* Chunk after 120 min timedelta to previous measurement\n",
    "\n",
    "After the discussion with the teaching team, we decided to **chunk after 65 min timedelta to previous measurement** with the possibility to adapt that in future"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Expand Chartevents by Information about Timedelta to Previous Measurement\n",
    "\n",
    "### Load and Prepare Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_clean from parquet file to pandas data frame\n",
    "chartevents_subset = pd.read_parquet('./data/chartevents_clean.parquet', engine='pyarrow')\n",
    "unique_icu_stays = pd.read_parquet('./data/unique_icustays_in_chartevents_subset.parquet', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant ICUSTAY_ID for analysis - only the ones appearing for the analyzed ITEMIDs\n",
    "icustayid_filter = unique_icu_stays.ICUSTAY_ID\n",
    "\n",
    "# Filter by ICUSTAY\n",
    "chunk_analysis_data = chartevents_subset[chartevents_subset.ICUSTAY_ID.isin(icustayid_filter)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6719837"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Chunk Analysis is only being conducted on the vital parameters, not thresholds\n",
    "# Filter for ITEMIDs that refer to vital parameters\n",
    "# Heart Rate: 220045 | NBP: 220179 | O2: 220277\n",
    "itemids_for_values_filter = [220045, 220179, 220277]\n",
    "chunk_analysis_data = chunk_analysis_data[chunk_analysis_data.ITEMID.isin(itemids_for_values_filter)].copy()\n",
    "len(chunk_analysis_data)"
   ]
  },
  {
   "source": [
    "### Create New Data Frame Columns for Analysis\n",
    "\n",
    "Example of relevant resulting data frame columns:\n",
    "\n",
    "ICUSTAY_ID  |  ITEMID  | CHARTTIME           | VALUENUM | **CHARTTIME_PREV**         | **DIF_CHARTTIME_PREV_MIN**\n",
    "\n",
    "20221       |   220045 | 2181-11-25T19:06:00 | 115      | NaA | NaN\n",
    "\n",
    "20221       |   220045 | 2181-11-25T19:16:00 | 113      | 2181-11-25T19:06:00 | 44"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Add Timestamp of Next Measurement as Column to Row of Current Measurement - CHARTTIME_NEXT \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: Keep chunk_analysis_data as is, only add a new column that holds the previous timestamp, the difference can then be performed outside the loop\n",
    "# Prerequisite: Sorted Data by ICUSTAY_ID,ITEMID,CHARTTIME\n",
    "chunk_analysis_data = chunk_analysis_data.sort_values(by=['ICUSTAY_ID','ITEMID','CHARTTIME'])\n",
    "chunk_analysis_data['CHARTTIME_PREV'] = chunk_analysis_data.groupby(['ICUSTAY_ID','ITEMID'])['CHARTTIME'].shift(1)"
   ]
  },
  {
   "source": [
    "Calculate Difference between Timestamps - DIF_CHARTTIME_PREV_MIN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_analysis_data['DIF_CHARTTIME_PREV'] = chunk_analysis_data['CHARTTIME']-chunk_analysis_data['CHARTTIME_PREV']\n",
    "chunk_analysis_data['DIF_CHARTTIME_PREV_S'] = chunk_analysis_data['DIF_CHARTTIME_PREV'].dt.total_seconds()\n",
    "chunk_analysis_data['DIF_CHARTTIME_PREV_MIN'] = divmod(chunk_analysis_data['DIF_CHARTTIME_PREV_S'], 60)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop helper columns\n",
    "chunk_analysis_data = chunk_analysis_data.drop(columns='DIF_CHARTTIME_PREV')\n",
    "chunk_analysis_data = chunk_analysis_data.drop(columns='DIF_CHARTTIME_PREV_S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ROW_ID  SUBJECT_ID   HADM_ID  ICUSTAY_ID    ITEMID           CHARTTIME  \\\n",
       "0  14005075.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 19:06:00   \n",
       "1  14005090.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 19:16:00   \n",
       "2  14005105.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 20:00:00   \n",
       "3  14005111.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 21:00:00   \n",
       "4  14005117.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 22:00:00   \n",
       "\n",
       "            STORETIME     CGID VALUE  VALUENUM VALUEUOM  WARNING  ERROR  \\\n",
       "0 2181-11-25 19:17:00  20622.0   115     115.0      bpm      0.0    0.0   \n",
       "1 2181-11-25 19:16:00  20622.0   114     114.0      bpm      0.0    0.0   \n",
       "2 2181-11-25 22:02:00  21108.0   113     113.0      bpm      0.0    0.0   \n",
       "3 2181-11-25 22:02:00  21108.0   108     108.0      bpm      0.0    0.0   \n",
       "4 2181-11-25 22:02:00  21108.0   110     110.0      bpm      0.0    0.0   \n",
       "\n",
       "  RESULTSTATUS STOPPED  VALUENUM_CLEAN CLEANING_FLAG      CHARTTIME_PREV  \\\n",
       "0         None    None           115.0          None                 NaT   \n",
       "1         None    None           114.0          None 2181-11-25 19:06:00   \n",
       "2         None    None           113.0          None 2181-11-25 19:16:00   \n",
       "3         None    None           108.0          None 2181-11-25 20:00:00   \n",
       "4         None    None           110.0          None 2181-11-25 21:00:00   \n",
       "\n",
       "   DIF_CHARTTIME_PREV_MIN  \n",
       "0                     NaN  \n",
       "1                    10.0  \n",
       "2                    44.0  \n",
       "3                    60.0  \n",
       "4                    60.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ROW_ID</th>\n      <th>SUBJECT_ID</th>\n      <th>HADM_ID</th>\n      <th>ICUSTAY_ID</th>\n      <th>ITEMID</th>\n      <th>CHARTTIME</th>\n      <th>STORETIME</th>\n      <th>CGID</th>\n      <th>VALUE</th>\n      <th>VALUENUM</th>\n      <th>VALUEUOM</th>\n      <th>WARNING</th>\n      <th>ERROR</th>\n      <th>RESULTSTATUS</th>\n      <th>STOPPED</th>\n      <th>VALUENUM_CLEAN</th>\n      <th>CLEANING_FLAG</th>\n      <th>CHARTTIME_PREV</th>\n      <th>DIF_CHARTTIME_PREV_MIN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14005075.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 19:06:00</td>\n      <td>2181-11-25 19:17:00</td>\n      <td>20622.0</td>\n      <td>115</td>\n      <td>115.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>115.0</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14005090.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 19:16:00</td>\n      <td>2181-11-25 19:16:00</td>\n      <td>20622.0</td>\n      <td>114</td>\n      <td>114.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>114.0</td>\n      <td>None</td>\n      <td>2181-11-25 19:06:00</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14005105.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 20:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>113</td>\n      <td>113.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>113.0</td>\n      <td>None</td>\n      <td>2181-11-25 19:16:00</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14005111.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 21:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>108</td>\n      <td>108.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>108.0</td>\n      <td>None</td>\n      <td>2181-11-25 20:00:00</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14005117.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 22:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>110</td>\n      <td>110.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>110.0</td>\n      <td>None</td>\n      <td>2181-11-25 21:00:00</td>\n      <td>60.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "chunk_analysis_data.head()"
   ]
  },
  {
   "source": [
    "## Apply Chunking Rule\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As discussed above, it was decided to chunk after 65 minutes Timedelta to Previous Measurement\n",
    "chunking_dif = 65"
   ]
  },
  {
   "source": [
    "Introduce new Chunk Id for first row that violates chunking difference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of relevant resulting data frame columns (chunk_data_merged):\n",
    "\n",
    "# ICUSTAY_ID  |  ITEMID  | CHARTTIME           | VALUENUM | CHARTTIME_PREV      | DIF_CHARTTIME_PREV_MIN**  | CHUNK_ID\n",
    "# 20221       |   220045 | 2181-11-25T19:06:00 | 115      | NaA                 | NaN                       | NaN\n",
    "# 20221       |   220045 | 2181-11-25T19:16:00 | 114      | 2181-11-25T19:06:00 | 10                        | NaN\n",
    "# 20221       |   220045 | 2181-11-25T21:00:00 | 113      | 2181-11-25T19:06:00 | 114                       | 20221_220045_2181-11-25T21:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all rows where Timedelta to Previous Measurement is larger than chunking dif\n",
    "chunk_data = chunk_analysis_data[chunk_analysis_data[\"DIF_CHARTTIME_PREV_MIN\"] > chunking_dif].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique Chunking ID to these rows - consisting of ICUSTAY_ID, ITEMID and the CHARTTIME\n",
    "chunk_data[\"CHUNK_ID\"] = chunk_data.ICUSTAY_ID.map(str) + \"_\" + chunk_data.ITEMID.map(str) + \"_\" + chunk_data.CHARTTIME.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "237226\n237226\n"
     ]
    }
   ],
   "source": [
    "# Check uniqueness - can only be violated if multiple measurements for that itemid/icustayid occured at the same charttime\n",
    "print(len(chunk_data[\"CHUNK_ID\"].value_counts()))\n",
    "print(len(chunk_data))\n",
    "# Uniqueness for this dataset is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep CHUNKID and index\n",
    "chunk_data_subset = chunk_data[\"CHUNK_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge back to all rows via index\n",
    "# Now we have a data set that has a CHUNK_ID at the beginning of each measurement that was conducted later than the chunking rule allows\n",
    "chunk_data_merged = pd.merge(chunk_analysis_data, chunk_data_subset,  how='left', left_index=True, right_index=True )"
   ]
  },
  {
   "source": [
    "Introduce new Chunk Id for first row of each ICUSTAY_ID and ITEMID combination"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of relevant resulting data frame columns (chunk_data_merged_2):\n",
    "# ICUSTAY_ID  |  ITEMID  | CHARTTIME           | VALUENUM | CHARTTIME_PREV      | DIF_CHARTTIME_PREV_MIN    | CHUNK_ID                        |CHUNK_ID_MIN\n",
    "# 20221       |   220045 | 2181-11-25T19:06:00 | 115      | NaA                 | NaN                       | NaN                             |20221_220045_2181-11-25T19:06:00\n",
    "# 20221       |   220045 | 2181-11-25T19:16:00 | 114      | 2181-11-25T19:06:00 | 10                        | NaN                             |NaN\n",
    "# 20221       |   220045 | 2181-11-25T21:00:00 | 113      | 2181-11-25T19:06:00 | 114                       | 20221_220045_2181-11-25T21:00:00|NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Chunk ID to first measurement of ICUSTAY_ID - ITEMID combination \n",
    "# First, calculate min timestamp\n",
    "chunk_data_min = chunk_data_merged.groupby(['ICUSTAY_ID','ITEMID'])['CHARTTIME'].min()\n",
    "chunk_data_min_df = chunk_data_min.to_frame()\n",
    "chunk_data_min_df.reset_index(inplace=True)\n",
    "\n",
    "# Second, for each first Charttime (by ICUSTAY_ID/ITEMID) create a Chunk ID\n",
    "chunk_data_min_df[\"CHUNK_ID_MIN\"] = chunk_data_min_df.ICUSTAY_ID.map(str) + \"_\" + chunk_data_min_df.ITEMID.map(str) + \"_\" + chunk_data_min_df.CHARTTIME.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge that back so we have a chunk id for each first Measurement (by ICUSTAYID/TEMID)\n",
    "chunk_data_merged_2 = pd.merge(chunk_data_merged, chunk_data_min_df,  how='left', on=['ICUSTAY_ID','ITEMID','CHARTTIME'])"
   ]
  },
  {
   "source": [
    "Pass CHUNK_ID_MIN to CHUNK_ID\n",
    "\n",
    "That way we have a column that has a CHUNK_ID at the beginning of each measurement that was conducted later than the chunking rule allows as well as an initial CHUNK_ID"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICUSTAY_ID  |  ITEMID  | CHARTTIME           | VALUENUM | CHARTTIME_PREV      | DIF_CHARTTIME_PREV_MIN    | CHUNK_ID                        |CHUNK_ID_MIN\n",
    "# 20221       |   220045 | 2181-11-25T19:06:00 | 115      | NaA                 | NaN                       | 20221_220045_2181-11-25T19:06:00|20221_220045_2181-11-25T19:06:00\n",
    "# 20221       |   220045 | 2181-11-25T19:16:00 | 114      | 2181-11-25T19:06:00 | 10                        | NaN                             |NaN\n",
    "# 20221       |   220045 | 2181-11-25T21:00:00 | 113      | 2181-11-25T19:06:00 | 114                       | 20221_220045_2181-11-25T21:00:00|NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# if CHUNK_ID_MIN not NaN,write chunk_id_min in chunk_id\n",
    "chunk_data_merged_2['CHUNK_ID'] = np.where(chunk_data_merged_2['CHUNK_ID_MIN'].notnull(), chunk_data_merged_2['CHUNK_ID_MIN'], chunk_data_merged_2['CHUNK_ID'])"
   ]
  },
  {
   "source": [
    "Fill all cells with previous CHUNK_ID, until new CHUNK_ID occurs\n",
    "\n",
    "Data must be sorted to make that work. By having a CHUNK_ID for each first occurance of ICUSTAY_ID - ITEM_ID, we make sure to not write CHUNK_IDs to other ICUSTAYs or ITEMIDs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICUSTAY_ID  |  ITEMID  | CHARTTIME           | VALUENUM | CHARTTIME_PREV      |  CHUNK_ID                       |CHUNK_ID_MIN                    | CHUNK_ID_FILLED\n",
    "# 20221       |   220045 | 2181-11-25T19:06:00 | 115      | NaN                 | 20221_220045_2181-11-25T19:06:00|20221_220045_2181-11-25T19:06:00|20221_220045_2181-11-25T19:06:00\n",
    "# 20221       |   220045 | 2181-11-25T19:16:00 | 114      | 2181-11-25T19:06:00 | NaN                             |NaN                             |20221_220045_2181-11-25T19:06:00\n",
    "# 20221       |   220045 | 2181-11-25T21:00:00 | 113      | 2181-11-25T19:06:00 | 20221_220045_2181-11-25T21:00:00|NaN                             |20221_220045_2181-11-25T21:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data_merged_2['CHUNK_ID_FILLED'] = chunk_data_merged_2['CHUNK_ID'].fillna(method='ffill')"
   ]
  },
  {
   "source": [
    "Remove Helper Columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data_merged_2 = chunk_data_merged_2.drop(columns='CHUNK_ID_MIN')\n",
    "# we could drop more helper columns but CHUNK_ID will become helpful for the visualization to directely see were a Chunk ID first was introduced so we keep that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ROW_ID  SUBJECT_ID   HADM_ID  ICUSTAY_ID    ITEMID           CHARTTIME  \\\n",
       "0  14005075.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 19:06:00   \n",
       "1  14005090.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 19:16:00   \n",
       "2  14005105.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 20:00:00   \n",
       "3  14005111.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 21:00:00   \n",
       "4  14005117.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 22:00:00   \n",
       "\n",
       "            STORETIME     CGID VALUE  VALUENUM  ... WARNING  ERROR  \\\n",
       "0 2181-11-25 19:17:00  20622.0   115     115.0  ...     0.0    0.0   \n",
       "1 2181-11-25 19:16:00  20622.0   114     114.0  ...     0.0    0.0   \n",
       "2 2181-11-25 22:02:00  21108.0   113     113.0  ...     0.0    0.0   \n",
       "3 2181-11-25 22:02:00  21108.0   108     108.0  ...     0.0    0.0   \n",
       "4 2181-11-25 22:02:00  21108.0   110     110.0  ...     0.0    0.0   \n",
       "\n",
       "   RESULTSTATUS STOPPED VALUENUM_CLEAN  CLEANING_FLAG      CHARTTIME_PREV  \\\n",
       "0          None    None          115.0           None                 NaT   \n",
       "1          None    None          114.0           None 2181-11-25 19:06:00   \n",
       "2          None    None          113.0           None 2181-11-25 19:16:00   \n",
       "3          None    None          108.0           None 2181-11-25 20:00:00   \n",
       "4          None    None          110.0           None 2181-11-25 21:00:00   \n",
       "\n",
       "  DIF_CHARTTIME_PREV_MIN                               CHUNK_ID  \\\n",
       "0                    NaN  200001.0_220045.0_2181-11-25 19:06:00   \n",
       "1                   10.0                                    NaN   \n",
       "2                   44.0                                    NaN   \n",
       "3                   60.0                                    NaN   \n",
       "4                   60.0                                    NaN   \n",
       "\n",
       "                         CHUNK_ID_FILLED  \n",
       "0  200001.0_220045.0_2181-11-25 19:06:00  \n",
       "1  200001.0_220045.0_2181-11-25 19:06:00  \n",
       "2  200001.0_220045.0_2181-11-25 19:06:00  \n",
       "3  200001.0_220045.0_2181-11-25 19:06:00  \n",
       "4  200001.0_220045.0_2181-11-25 19:06:00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ROW_ID</th>\n      <th>SUBJECT_ID</th>\n      <th>HADM_ID</th>\n      <th>ICUSTAY_ID</th>\n      <th>ITEMID</th>\n      <th>CHARTTIME</th>\n      <th>STORETIME</th>\n      <th>CGID</th>\n      <th>VALUE</th>\n      <th>VALUENUM</th>\n      <th>...</th>\n      <th>WARNING</th>\n      <th>ERROR</th>\n      <th>RESULTSTATUS</th>\n      <th>STOPPED</th>\n      <th>VALUENUM_CLEAN</th>\n      <th>CLEANING_FLAG</th>\n      <th>CHARTTIME_PREV</th>\n      <th>DIF_CHARTTIME_PREV_MIN</th>\n      <th>CHUNK_ID</th>\n      <th>CHUNK_ID_FILLED</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14005075.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 19:06:00</td>\n      <td>2181-11-25 19:17:00</td>\n      <td>20622.0</td>\n      <td>115</td>\n      <td>115.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>115.0</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14005090.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 19:16:00</td>\n      <td>2181-11-25 19:16:00</td>\n      <td>20622.0</td>\n      <td>114</td>\n      <td>114.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>114.0</td>\n      <td>None</td>\n      <td>2181-11-25 19:06:00</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14005105.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 20:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>113</td>\n      <td>113.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>113.0</td>\n      <td>None</td>\n      <td>2181-11-25 19:16:00</td>\n      <td>44.0</td>\n      <td>NaN</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14005111.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 21:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>108</td>\n      <td>108.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>108.0</td>\n      <td>None</td>\n      <td>2181-11-25 20:00:00</td>\n      <td>60.0</td>\n      <td>NaN</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14005117.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 22:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>110</td>\n      <td>110.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>110.0</td>\n      <td>None</td>\n      <td>2181-11-25 21:00:00</td>\n      <td>60.0</td>\n      <td>NaN</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "chunk_data_merged_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as parquet file\n",
    "pd.DataFrame(chunk_data_merged_2).to_parquet('./data/chartevents_clean_values_with_chunkid_' + str(chunking_dif) + '.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "# Apply Chunk IDs on Thresholds"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Load and Prepare Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "chartevents_subset = pd.read_parquet('./data/chartevents_clean.parquet', engine='pyarrow')\n",
    "chunk_data = pd.read_parquet('./data/chartevents_clean_values_with_chunkid_65.parquet', engine='pyarrow')\n",
    "unique_icu_stays = pd.read_parquet('./data/unique_icustays_in_chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant ICUSTAY_ID for analysis - only the ones appearing for the analyzed ITEMIDs\n",
    "icustayid_filter = unique_icu_stays.ICUSTAY_ID\n",
    "\n",
    "# Filter by ICUSTAY\n",
    "chunk_analysis_data = chartevents_subset[chartevents_subset.ICUSTAY_ID.isin(icustayid_filter)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match columns for later union\n",
    "import numpy as np\n",
    "chunk_data = chunk_data.drop(columns=['CHARTTIME_PREV', 'DIF_CHARTTIME_PREV_MIN','CHUNK_ID'])\n",
    "chartevents_subset.insert(loc=len(chartevents_subset.columns), column='CHUNK_ID_FILLED', value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ROW_ID  SUBJECT_ID   HADM_ID  ICUSTAY_ID    ITEMID           CHARTTIME  \\\n",
       "0  14005075.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 19:06:00   \n",
       "1  14005090.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 19:16:00   \n",
       "2  14005105.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 20:00:00   \n",
       "3  14005111.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 21:00:00   \n",
       "4  14005117.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 22:00:00   \n",
       "\n",
       "            STORETIME     CGID VALUE  VALUENUM VALUEUOM  WARNING  ERROR  \\\n",
       "0 2181-11-25 19:17:00  20622.0   115     115.0      bpm      0.0    0.0   \n",
       "1 2181-11-25 19:16:00  20622.0   114     114.0      bpm      0.0    0.0   \n",
       "2 2181-11-25 22:02:00  21108.0   113     113.0      bpm      0.0    0.0   \n",
       "3 2181-11-25 22:02:00  21108.0   108     108.0      bpm      0.0    0.0   \n",
       "4 2181-11-25 22:02:00  21108.0   110     110.0      bpm      0.0    0.0   \n",
       "\n",
       "  RESULTSTATUS STOPPED  VALUENUM_CLEAN CLEANING_FLAG  CHUNK_ID_FILLED  \n",
       "0         None    None           115.0          None              NaN  \n",
       "1         None    None           114.0          None              NaN  \n",
       "2         None    None           113.0          None              NaN  \n",
       "3         None    None           108.0          None              NaN  \n",
       "4         None    None           110.0          None              NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ROW_ID</th>\n      <th>SUBJECT_ID</th>\n      <th>HADM_ID</th>\n      <th>ICUSTAY_ID</th>\n      <th>ITEMID</th>\n      <th>CHARTTIME</th>\n      <th>STORETIME</th>\n      <th>CGID</th>\n      <th>VALUE</th>\n      <th>VALUENUM</th>\n      <th>VALUEUOM</th>\n      <th>WARNING</th>\n      <th>ERROR</th>\n      <th>RESULTSTATUS</th>\n      <th>STOPPED</th>\n      <th>VALUENUM_CLEAN</th>\n      <th>CLEANING_FLAG</th>\n      <th>CHUNK_ID_FILLED</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14005075.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 19:06:00</td>\n      <td>2181-11-25 19:17:00</td>\n      <td>20622.0</td>\n      <td>115</td>\n      <td>115.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>115.0</td>\n      <td>None</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14005090.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 19:16:00</td>\n      <td>2181-11-25 19:16:00</td>\n      <td>20622.0</td>\n      <td>114</td>\n      <td>114.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>114.0</td>\n      <td>None</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14005105.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 20:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>113</td>\n      <td>113.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>113.0</td>\n      <td>None</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14005111.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 21:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>108</td>\n      <td>108.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>108.0</td>\n      <td>None</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14005117.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 22:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>110</td>\n      <td>110.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>110.0</td>\n      <td>None</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "chartevents_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ROW_ID  SUBJECT_ID   HADM_ID  ICUSTAY_ID    ITEMID           CHARTTIME  \\\n",
       "0  14005075.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 19:06:00   \n",
       "1  14005090.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 19:16:00   \n",
       "2  14005105.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 20:00:00   \n",
       "3  14005111.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 21:00:00   \n",
       "4  14005117.0     55973.0  152234.0    200001.0  220045.0 2181-11-25 22:00:00   \n",
       "\n",
       "            STORETIME     CGID VALUE  VALUENUM VALUEUOM  WARNING  ERROR  \\\n",
       "0 2181-11-25 19:17:00  20622.0   115     115.0      bpm      0.0    0.0   \n",
       "1 2181-11-25 19:16:00  20622.0   114     114.0      bpm      0.0    0.0   \n",
       "2 2181-11-25 22:02:00  21108.0   113     113.0      bpm      0.0    0.0   \n",
       "3 2181-11-25 22:02:00  21108.0   108     108.0      bpm      0.0    0.0   \n",
       "4 2181-11-25 22:02:00  21108.0   110     110.0      bpm      0.0    0.0   \n",
       "\n",
       "  RESULTSTATUS STOPPED  VALUENUM_CLEAN CLEANING_FLAG  \\\n",
       "0         None    None           115.0          None   \n",
       "1         None    None           114.0          None   \n",
       "2         None    None           113.0          None   \n",
       "3         None    None           108.0          None   \n",
       "4         None    None           110.0          None   \n",
       "\n",
       "                         CHUNK_ID_FILLED  \n",
       "0  200001.0_220045.0_2181-11-25 19:06:00  \n",
       "1  200001.0_220045.0_2181-11-25 19:06:00  \n",
       "2  200001.0_220045.0_2181-11-25 19:06:00  \n",
       "3  200001.0_220045.0_2181-11-25 19:06:00  \n",
       "4  200001.0_220045.0_2181-11-25 19:06:00  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ROW_ID</th>\n      <th>SUBJECT_ID</th>\n      <th>HADM_ID</th>\n      <th>ICUSTAY_ID</th>\n      <th>ITEMID</th>\n      <th>CHARTTIME</th>\n      <th>STORETIME</th>\n      <th>CGID</th>\n      <th>VALUE</th>\n      <th>VALUENUM</th>\n      <th>VALUEUOM</th>\n      <th>WARNING</th>\n      <th>ERROR</th>\n      <th>RESULTSTATUS</th>\n      <th>STOPPED</th>\n      <th>VALUENUM_CLEAN</th>\n      <th>CLEANING_FLAG</th>\n      <th>CHUNK_ID_FILLED</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14005075.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 19:06:00</td>\n      <td>2181-11-25 19:17:00</td>\n      <td>20622.0</td>\n      <td>115</td>\n      <td>115.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>115.0</td>\n      <td>None</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14005090.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 19:16:00</td>\n      <td>2181-11-25 19:16:00</td>\n      <td>20622.0</td>\n      <td>114</td>\n      <td>114.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>114.0</td>\n      <td>None</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14005105.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 20:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>113</td>\n      <td>113.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>113.0</td>\n      <td>None</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14005111.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 21:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>108</td>\n      <td>108.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>108.0</td>\n      <td>None</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14005117.0</td>\n      <td>55973.0</td>\n      <td>152234.0</td>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>2181-11-25 22:00:00</td>\n      <td>2181-11-25 22:02:00</td>\n      <td>21108.0</td>\n      <td>110</td>\n      <td>110.0</td>\n      <td>bpm</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>110.0</td>\n      <td>None</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "chunk_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respective ITEMIDs\n",
    "itemids_for_thresholds_HR = [220046, 220047]\n",
    "itemids_for_thresholds_NBP = [223751, 223752]\n",
    "itemids_for_thresholds_O2 = [223769, 223770]\n",
    "itemids_for_value_HR = [220045]\n",
    "itemids_for_value_NBP = [220179]\n",
    "itemids_for_value_O2 = [220277]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold data\n",
    "threshold_data_HR = chartevents_subset[chartevents_subset.ITEMID.isin(itemids_for_thresholds_HR)].copy()\n",
    "threshold_data_NBP = chartevents_subset[chartevents_subset.ITEMID.isin(itemids_for_thresholds_NBP)].copy()\n",
    "threshold_data_O2 = chartevents_subset[chartevents_subset.ITEMID.isin(itemids_for_thresholds_O2)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vital Parameter data\n",
    "value_chunk_data_HR = chunk_data[chunk_data.ITEMID.isin(itemids_for_value_HR)].copy()\n",
    "value_chunk_data_NBP = chunk_data[chunk_data.ITEMID.isin(itemids_for_value_NBP)].copy()\n",
    "value_chunk_data_O2 = chunk_data[chunk_data.ITEMID.isin(itemids_for_value_O2)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union Threshold and Vital Parameter data\n",
    "threshold_and_value_HR = threshold_data_HR.append(value_chunk_data_HR)\n",
    "threshold_and_value_NBP = threshold_data_NBP.append(value_chunk_data_NBP)\n",
    "threshold_and_value_O2 = threshold_data_O2.append(value_chunk_data_O2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort bei ICUSTAY_ID & CHARTTIME - We do not have to look at ITEMID as we have seperate data frames\n",
    "threshold_and_value_HR = threshold_and_value_HR.sort_values(by=['ICUSTAY_ID','CHARTTIME'])\n",
    "threshold_and_value_NBP = threshold_and_value_NBP.sort_values(by=['ICUSTAY_ID','CHARTTIME'])\n",
    "threshold_and_value_O2 = threshold_and_value_O2.sort_values(by=['ICUSTAY_ID','CHARTTIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example rows of resulting data frame - HR\n",
    "# ICUSTAY_ID  |  ITEMID  | CHARTTIME           | VALUENUM | CHUNK_ID_FILLED\n",
    "# 20221       |   220045 | 2181-11-25T19:06:00 | 115      | 20221_220045_2181-11-25T19:06:00\n",
    "# 20221       |   220046 | 2181-11-25T19:07:00 | 130      | NaN\n",
    "# 20221       |   220047 | 2181-11-25T21:07:00 | 60       | NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can use ffill to fill the correspoding Chunk IDs in -> use seperate columns for better validation\n",
    "# Problem: Cases where the threshold was first set before a value appeared - need to make sure to not write CHUNK_ID of different ICUSTAY in that\n",
    "# Solution: group by ICUSTAYID, first forward fill to fill threshold chunks where value was there before threshold, then backward fill to fill cases where threshold existed before value\n",
    "#For HR\n",
    "threshold_and_value_HR[\"CHUNK_ID_FILLED_TH\"] = threshold_and_value_HR.groupby('ICUSTAY_ID')['CHUNK_ID_FILLED'].transform(lambda x: x.ffill())\n",
    "threshold_and_value_HR[\"CHUNK_ID_FILLED_TH\"] = threshold_and_value_HR.groupby('ICUSTAY_ID')['CHUNK_ID_FILLED_TH'].transform(lambda x: x.bfill())\n",
    "\n",
    "#For NBP\n",
    "threshold_and_value_NBP[\"CHUNK_ID_FILLED_TH\"] = threshold_and_value_NBP.groupby('ICUSTAY_ID')['CHUNK_ID_FILLED'].transform(lambda x: x.ffill())\n",
    "threshold_and_value_NBP[\"CHUNK_ID_FILLED_TH\"] = threshold_and_value_NBP.groupby('ICUSTAY_ID')['CHUNK_ID_FILLED_TH'].transform(lambda x: x.bfill())\n",
    "\n",
    "#For O2\n",
    "threshold_and_value_O2[\"CHUNK_ID_FILLED_TH\"] = threshold_and_value_O2.groupby('ICUSTAY_ID')['CHUNK_ID_FILLED'].transform(lambda x: x.ffill())\n",
    "threshold_and_value_O2[\"CHUNK_ID_FILLED_TH\"] = threshold_and_value_O2.groupby('ICUSTAY_ID')['CHUNK_ID_FILLED_TH'].transform(lambda x: x.bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example rows of resulting data frame - HR\n",
    "# ICUSTAY_ID  |  ITEMID  | CHARTTIME           | VALUENUM | CHUNK_ID_FILLED                  | CHUNK_ID_FILLED_TH\n",
    "# 20221       |   220045 | 2181-11-25T19:06:00 | 115      | 20221_220045_2181-11-25T19:06:00 | 20221_220045_2181-11-25T19:06:00\n",
    "# 20221       |   220046 | 2181-11-25T19:07:00 | 130      | NaN                              | 20221_220045_2181-11-25T19:06:00\n",
    "# 20221       |   220047 | 2181-11-25T21:07:00 | 60       | NaN                              | 20221_220045_2181-11-25T19:06:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_and_value_all = pd.concat([threshold_and_value_HR, threshold_and_value_NBP, threshold_and_value_O2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the rows like they were in chartevents\n",
    "threshold_and_value_all = threshold_and_value_all.sort_values(by=['ICUSTAY_ID', 'CHARTTIME','ITEMID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(threshold_and_value_all).to_parquet('./data/chartevents_clean_values_and_thresholds_with_chunkid_' + str(chunking_dif) + '.parquet', engine='pyarrow')"
   ]
  }
 ]
}