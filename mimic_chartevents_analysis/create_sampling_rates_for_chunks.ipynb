{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0c24247fa39158f46a54dbb99bb8811b81cd84bf3c9aa6e8294d53a41a5837da9",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Creation of Sampling Rate for Vital Parameters in Chunks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Aim: Analyze Sampling Rates by CHUNK ID to generate an overview\n",
    "\n",
    "The sampling rate describes the average of vital parameter measurements obtained in one hour for a specific vital parameter - The threshold values are not analyzed\n",
    "\n",
    "Structure of the new data frame sampling_rates_for_chunkid.parquet:\n",
    "* ICUSTAY_ID\n",
    "* ITEMID\n",
    "* CHUNK_ID\n",
    "* CHARTTIME_MIN -> minimum timestamp for that ICUSTAY_ID - ITEMID. \"When was the first measurement of this parameter conducted for this ICUSTAY_ID?\"\n",
    "* CHARTTIME_MAX -> maximum timestamp for that ICUSTAY_ID - ITEMID. \"When was the last measurement of this parameter conducted for this ICUSTAY_ID?\"\n",
    "* CHUNKID_DURATION(h) -> timedelta between first and last timestamp for that ICUSTAY_ID - ITEMID. \"How much time has passed between the first and the last measurement in hours?\"\n",
    "* VALUENUM_COUNT -> number of measurements for this ICUSTAY_ID - ITEMID. \"How many measurements are available over the entire period for this parameter for this ICUSTAY_ID?\"\n",
    "* SAMPLING_RATE -> number of measurements for this ICUSTAY_ID - ITEMID divided by the timedelta between first and last timestamp for that ICUSTAY_ID - ITEMID in hours. \"How many measurements were obtained on average per hour for this ICUSTAY_ID - ITEMID?\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "First, a filter is being applied that filters on relevant ITEMIDs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chunk data from parquet file to pandas data frame\n",
    "sampling_rate_data = pd.read_parquet('./data/chartevent_subset_values_with_chunkid_65.parquet', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling Rate Analysis is only being conducted on the vital parameters, not thresholds\n",
    "# Filter for ITEMIDs that refer to vital parameters\n",
    "# Heart Rate: 220045 | NBP: 220179 | O2: 220277\n",
    "itemids_for_values_filter = [220045, 220179, 220277]\n",
    "sampling_rate_data = sampling_rate_data[sampling_rate_data.ITEMID.isin(itemids_for_values_filter)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename CHUNK ID column\n",
    "sampling_rate_data = sampling_rate_data.rename(columns={\"CHUNK_ID_FILLED\":\"CHUNK_ID\"})"
   ]
  },
  {
   "source": [
    "## Fill Sampling Rate Data Frame\n",
    "\n",
    "Calculate the relevant columns with groupby statements, as this turned out to be much faster than a for-loop.\n",
    "One row is being generated per CHUNK_ID combination."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "307241"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Calculate CHARTTIME_MIN for each CHUNK_ID\n",
    "sampling_rate_data_min = sampling_rate_data.groupby(['CHUNK_ID'])['CHARTTIME'].min()\n",
    "sampling_rate_data_min_df = sampling_rate_data_min.to_frame()\n",
    "sampling_rate_data_min_df.reset_index(inplace=True)\n",
    "sampling_rate_data_min_df = sampling_rate_data_min_df.rename(columns = {'CHARTTIME':'CHARTTIME_MIN'})\n",
    "len(sampling_rate_data_min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "307241"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Calculate CHARTTIME_MAX for each CHUNK_ID\n",
    "sampling_rate_data_max = sampling_rate_data.groupby(['CHUNK_ID'])['CHARTTIME'].max()\n",
    "sampling_rate_data_max_df = sampling_rate_data_max.to_frame()\n",
    "sampling_rate_data_max_df.reset_index(inplace=True)\n",
    "sampling_rate_data_max_df = sampling_rate_data_max_df.rename(columns = {'CHARTTIME':'CHARTTIME_MAX'})\n",
    "len(sampling_rate_data_max_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VALUENUM_COUNT for each CHUNK_ID\n",
    "sampling_rate_data_count = sampling_rate_data[['CHUNK_ID','VALUENUM']].copy()\n",
    "sampling_rate_data_count = sampling_rate_data_count.groupby(['CHUNK_ID']).count()\n",
    "sampling_rate_data_count = sampling_rate_data_count.rename(columns = {'VALUENUM':'VALUENUM_COUNT'})\n",
    "sampling_rate_data_count = sampling_rate_data_count.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                CHUNK_ID       CHARTTIME_MIN  \\\n",
       "0  200001.0_220045.0_2181-11-25 19:06:00 2181-11-25 19:06:00   \n",
       "1  200001.0_220045.0_2181-11-27 07:00:00 2181-11-27 07:00:00   \n",
       "2  200001.0_220045.0_2181-11-27 18:48:00 2181-11-27 18:48:00   \n",
       "3  200001.0_220179.0_2181-11-25 19:08:00 2181-11-25 19:08:00   \n",
       "4  200001.0_220179.0_2181-11-28 13:10:00 2181-11-28 13:10:00   \n",
       "\n",
       "        CHARTTIME_MAX  VALUENUM_COUNT  \n",
       "0 2181-11-27 05:00:00              36  \n",
       "1 2181-11-27 16:00:00              10  \n",
       "2 2181-11-28 20:00:00              53  \n",
       "3 2181-11-26 15:00:00              21  \n",
       "4 2181-11-28 13:22:00               4  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CHUNK_ID</th>\n      <th>CHARTTIME_MIN</th>\n      <th>CHARTTIME_MAX</th>\n      <th>VALUENUM_COUNT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n      <td>2181-11-25 19:06:00</td>\n      <td>2181-11-27 05:00:00</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>200001.0_220045.0_2181-11-27 07:00:00</td>\n      <td>2181-11-27 07:00:00</td>\n      <td>2181-11-27 16:00:00</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>200001.0_220045.0_2181-11-27 18:48:00</td>\n      <td>2181-11-27 18:48:00</td>\n      <td>2181-11-28 20:00:00</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>200001.0_220179.0_2181-11-25 19:08:00</td>\n      <td>2181-11-25 19:08:00</td>\n      <td>2181-11-26 15:00:00</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200001.0_220179.0_2181-11-28 13:10:00</td>\n      <td>2181-11-28 13:10:00</td>\n      <td>2181-11-28 13:22:00</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Merge together by CHUNKID\n",
    "# Resulting data frame columns: CHUNK_ID, CHARTTIME_MIN, CHARTTIME_MAX, VALUENUM_COUNT\n",
    "sampling_rates_for_chunkid = pd.merge(sampling_rate_data_min_df, sampling_rate_data_max_df,  how='left', on=['CHUNK_ID'])\n",
    "sampling_rates_for_chunkid = pd.merge(sampling_rates_for_chunkid,sampling_rate_data_count,how='left', on=['CHUNK_ID'])\n",
    "len(sampling_rates_for_chunkid)\n",
    "sampling_rates_for_chunkid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "# Calculate ICUSTAY_DURATION(h) for each CHUNK_ID\n",
    "sampling_rates_for_chunkid['CHUNKID_DURATION'] = sampling_rates_for_chunkid['CHARTTIME_MAX']-sampling_rates_for_chunkid['CHARTTIME_MIN']\n",
    "sampling_rates_for_chunkid['CHUNKID_DURATION(s)'] = sampling_rates_for_chunkid['CHUNKID_DURATION'].dt.total_seconds()\n",
    "sampling_rates_for_chunkid['CHUNKID_DURATION(h)'] = divmod(sampling_rates_for_chunkid['CHUNKID_DURATION(s)'], 3600)[0]\n",
    "\n",
    "# Drop helper columns\n",
    "sampling_rates_for_chunkid = sampling_rates_for_chunkid.drop(columns=['CHUNKID_DURATION','CHUNKID_DURATION(s)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Calculate SAMPLING_RATE for each CHUNK_ID\n",
    "# If the ICUSTAY_DURATION(h) is zero, take VALUENUM_COUNT as SAMPLING_RATE to not divide by 0\n",
    "sampling_rates_for_chunkid['SAMPLING_RATE'] = np.where(sampling_rates_for_chunkid['CHUNKID_DURATION(h)'] == 0,sampling_rates_for_chunkid['VALUENUM_COUNT'],(sampling_rates_for_chunkid['VALUENUM_COUNT']/sampling_rates_for_chunkid['CHUNKID_DURATION(h)']))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ICUSTAYID and  ITEMID to sampling_rates_for_chunkid\n",
    "icustay_and_itemid_for_chunk = sampling_rate_data[['ICUSTAY_ID','ITEMID','CHUNK_ID']]\n",
    "icustay_and_itemid_for_chunk=icustay_and_itemid_for_chunk.drop_duplicates()\n",
    "sampling_rates_for_chunkid = pd.merge(icustay_and_itemid_for_chunk,sampling_rates_for_chunkid,how='left', on=['CHUNK_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ICUSTAY_ID    ITEMID                               CHUNK_ID  \\\n",
       "0    200001.0  220045.0  200001.0_220045.0_2181-11-25 19:06:00   \n",
       "1    200001.0  220045.0  200001.0_220045.0_2181-11-27 07:00:00   \n",
       "2    200001.0  220045.0  200001.0_220045.0_2181-11-27 18:48:00   \n",
       "3    200001.0  220179.0  200001.0_220179.0_2181-11-25 19:08:00   \n",
       "4    200001.0  220179.0  200001.0_220179.0_2181-11-28 13:10:00   \n",
       "\n",
       "        CHARTTIME_MIN       CHARTTIME_MAX  VALUENUM_COUNT  \\\n",
       "0 2181-11-25 19:06:00 2181-11-27 05:00:00              36   \n",
       "1 2181-11-27 07:00:00 2181-11-27 16:00:00              10   \n",
       "2 2181-11-27 18:48:00 2181-11-28 20:00:00              53   \n",
       "3 2181-11-25 19:08:00 2181-11-26 15:00:00              21   \n",
       "4 2181-11-28 13:10:00 2181-11-28 13:22:00               4   \n",
       "\n",
       "   CHUNKID_DURATION(h)  SAMPLING_RATE  \n",
       "0                 33.0       1.090909  \n",
       "1                  9.0       1.111111  \n",
       "2                 25.0       2.120000  \n",
       "3                 19.0       1.105263  \n",
       "4                  0.0       4.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ICUSTAY_ID</th>\n      <th>ITEMID</th>\n      <th>CHUNK_ID</th>\n      <th>CHARTTIME_MIN</th>\n      <th>CHARTTIME_MAX</th>\n      <th>VALUENUM_COUNT</th>\n      <th>CHUNKID_DURATION(h)</th>\n      <th>SAMPLING_RATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>200001.0_220045.0_2181-11-25 19:06:00</td>\n      <td>2181-11-25 19:06:00</td>\n      <td>2181-11-27 05:00:00</td>\n      <td>36</td>\n      <td>33.0</td>\n      <td>1.090909</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>200001.0_220045.0_2181-11-27 07:00:00</td>\n      <td>2181-11-27 07:00:00</td>\n      <td>2181-11-27 16:00:00</td>\n      <td>10</td>\n      <td>9.0</td>\n      <td>1.111111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>200001.0</td>\n      <td>220045.0</td>\n      <td>200001.0_220045.0_2181-11-27 18:48:00</td>\n      <td>2181-11-27 18:48:00</td>\n      <td>2181-11-28 20:00:00</td>\n      <td>53</td>\n      <td>25.0</td>\n      <td>2.120000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>200001.0</td>\n      <td>220179.0</td>\n      <td>200001.0_220179.0_2181-11-25 19:08:00</td>\n      <td>2181-11-25 19:08:00</td>\n      <td>2181-11-26 15:00:00</td>\n      <td>21</td>\n      <td>19.0</td>\n      <td>1.105263</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>200001.0</td>\n      <td>220179.0</td>\n      <td>200001.0_220179.0_2181-11-28 13:10:00</td>\n      <td>2181-11-28 13:10:00</td>\n      <td>2181-11-28 13:22:00</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "sampling_rates_for_chunkid.head()"
   ]
  },
  {
   "source": [
    "## Save Data Frame to parquet File"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "# Save sampling_rates_for_icustay_itemid as parquet file\n",
    "pd.DataFrame(sampling_rates_for_chunkid).to_parquet('./data/sampling_rates_for_chunkid.parquet', engine='pyarrow')"
   ]
  }
 ]
}