{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0c24247fa39158f46a54dbb99bb8811b81cd84bf3c9aa6e8294d53a41a5837da9",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Analysis of Sampling Rate for Chunks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Aim: Analyze Sampling Rates by Chunk Id to generate an overview"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Load and Prepare Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "sampling_rate_data = pd.read_parquet('./data/chartevent_subset_values_with_chunkid_65.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling Rate Analysis is only being conducted on the values, not thresholds\n",
    "# Filter for item ids that refer to value - only relevant if chunk data also holds thresholds (not yet in there)\n",
    "itemids_for_values_filter = [220045, 220179, 220277]\n",
    "# chunk data only consits of parameters\n",
    "sampling_rate_data = sampling_rate_data[sampling_rate_data.ITEMID.isin(itemids_for_values_filter)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate_data = sampling_rate_data.rename(columns={\"CHUNK_ID_FILLED\":\"CHUNK_ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate_data['CHUNK_ID'].value_counts()"
   ]
  },
  {
   "source": [
    "## Generate Data Frame with Sampling Rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate min timestamp\n",
    "sampling_rate_data_min = sampling_rate_data.groupby(['CHUNK_ID'])['CHARTTIME'].min()\n",
    "sampling_rate_data_min_df = sampling_rate_data_min.to_frame()\n",
    "sampling_rate_data_min_df.reset_index(inplace=True)\n",
    "sampling_rate_data_min_df = sampling_rate_data_min_df.rename(columns = {'CHARTTIME':'CHARTTIME_MIN'})\n",
    "len(sampling_rate_data_min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate max timestamp\n",
    "sampling_rate_data_max = sampling_rate_data.groupby(['CHUNK_ID'])['CHARTTIME'].max()\n",
    "sampling_rate_data_max_df = sampling_rate_data_max.to_frame()\n",
    "sampling_rate_data_max_df.reset_index(inplace=True)\n",
    "sampling_rate_data_max_df = sampling_rate_data_max_df.rename(columns = {'CHARTTIME':'CHARTTIME_MAX'})\n",
    "len(sampling_rate_data_max_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate N_MEASUREMENTS\n",
    "# For each ICUSTAY_ID-ITEMID combination, compute the number of available values as VALUENUM_COUNT\n",
    "# Reduce to relevant columns\n",
    "sampling_rate_data_count = sampling_rate_data[['CHUNK_ID','VALUENUM']].copy()\n",
    "sampling_rate_data_count = sampling_rate_data_count.groupby(['CHUNK_ID']).count()\n",
    "sampling_rate_data_count = sampling_rate_data_count.rename(columns = {'VALUENUM':'VALUENUM_COUNT'})\n",
    "sampling_rate_data_count = sampling_rate_data_count.reset_index()\n",
    "display(sampling_rate_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge together by ICUSTAYID, ITEMID\n",
    "sampling_rates_for_chunkid = pd.merge(sampling_rate_data_min_df, sampling_rate_data_max_df,  how='left', on=['CHUNK_ID'])\n",
    "sampling_rates_for_chunkid = pd.merge(sampling_rates_for_chunkid,sampling_rate_data_count,how='left', on=['CHUNK_ID'])\n",
    "len(sampling_rates_for_chunkid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "# Calculate ICUSTAY_ID duration\n",
    "sampling_rates_for_chunkid['CHUNKID_DURATION'] = sampling_rates_for_chunkid['CHARTTIME_MAX']-sampling_rates_for_chunkid['CHARTTIME_MIN']\n",
    "sampling_rates_for_chunkid['CHUNKID_DURATION(s)'] = sampling_rates_for_chunkid['CHUNKID_DURATION'].dt.total_seconds()\n",
    "sampling_rates_for_chunkid['CHUNKID_DURATION(h)'] = divmod(sampling_rates_for_chunkid['CHUNKID_DURATION(s)'], 3600)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates_for_chunkid = sampling_rates_for_chunkid.drop(columns=['CHUNKID_DURATION','CHUNKID_DURATION(s)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sampling_rates_for_chunkid['SAMPLING_RATE'] = np.where(sampling_rates_for_chunkid['CHUNKID_DURATION(h)'] == 0,sampling_rates_for_chunkid['VALUENUM_COUNT'],(sampling_rates_for_chunkid['VALUENUM_COUNT']/sampling_rates_for_chunkid['CHUNKID_DURATION(h)']))\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ICUSTAYID and  ITEMID to sampling_rates_for_chunkid\n",
    "icustay_and_itemid_for_chunk = sampling_rate_data[['ICUSTAY_ID','ITEMID','CHUNK_ID']]\n",
    "icustay_and_itemid_for_chunk=icustay_and_itemid_for_chunk.drop_duplicates()\n",
    "sampling_rates_for_chunkid = pd.merge(icustay_and_itemid_for_chunk,sampling_rates_for_chunkid,how='left', on=['CHUNK_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "# Save chartevents_subset as parquet file\n",
    "pd.DataFrame(sampling_rates_for_chunkid).to_parquet('./data/sampling_rates_for_chunkid.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Sampling Rate - Visualizations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "sampling_rates_for_chunkid = pd.read_parquet('./data/sampling_rates_for_chunkid.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subsets for item Ids\n",
    "sampling_rates_for_chunkid_HR = sampling_rates_for_chunkid[sampling_rates_for_chunkid['ITEMID'] == 220045]\n",
    "sampling_rates_for_chunkid_O2 = sampling_rates_for_chunkid[sampling_rates_for_chunkid['ITEMID'] == 220277]\n",
    "sampling_rates_for_chunkid_NBP = sampling_rates_for_chunkid[sampling_rates_for_chunkid['ITEMID'] == 220179]"
   ]
  },
  {
   "source": [
    "## Plot the sampling rate by Item Id"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set variables\n",
    "title = \"Sampling Rate by Chunk Id\"\n",
    "xlabel = \"Item Id\"\n",
    "ylabel = \"Avg. # of samples obtained in 1 hour\"\n",
    "plotdata = sampling_rates_for_chunkid\n",
    "xvalue = \"ITEMID\"\n",
    "yvalue = \"SAMPLING_RATE\"\n",
    "\n",
    "# Config figure\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(\n",
    "    figsize = (10, 5), \n",
    "    dpi = 72 # e.g. 72 for screen, 300 for print\n",
    "    )\n",
    "ax = sns.boxplot( # Insert on of: sns.stripplot , sns.boxplot , sns.violinplot\n",
    "    data = plotdata, \n",
    "    x = xvalue,\n",
    "    y = yvalue, # Comment out if no stratification is to be performed based on yvalue\n",
    "    palette = sns.color_palette(\"colorblind\")\n",
    "    )\n",
    "ax.set_title(title, fontweight='bold', color= 'black', fontsize=14, y=1.05)\n",
    "ax.set_xlabel(xlabel, fontsize=12, labelpad=15)\n",
    "ax.set_ylabel(ylabel, fontsize=12, labelpad=15) # Comment out if no stratification is to be performed based on yvalue\n",
    "ax.grid(b=True, which='both')\n",
    "ax.margins(.1)\n",
    "\n",
    "# Plot figure\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates_for_chunkid_HR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates_for_chunkid_NBP.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates_for_chunkid_O2.describe()"
   ]
  },
  {
   "source": [
    "## Further Analysis\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Analyze # of Chunk Ids per ICUSTAY_ID"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "chunk_analysis_data = pd.read_parquet('./data/chartevent_subset_values_with_chunkid_65.parquet', engine='pyarrow')\n",
    "chunk_analysis_data = chunk_analysis_data.rename(columns={\"CHUNK_ID_FILLED\":\"CHUNK_ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_count_by_icustay = chunk_analysis_data[['ICUSTAY_ID','CHUNK_ID']]\n",
    "chunk_count_by_icustay=chunk_count_by_icustay.drop_duplicates()\n",
    "chunk_count_by_icustay = chunk_count_by_icustay.groupby(['ICUSTAY_ID']).count()\n",
    "\n",
    "chunk_count_by_icustay = chunk_count_by_icustay.rename(columns = {'CHUNK_ID':'CHUNK_ID_COUNT'})\n",
    "chunk_count_by_icustay = chunk_count_by_icustay.reset_index()\n",
    "display(chunk_count_by_icustay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_count_by_icustay.describe()"
   ]
  },
  {
   "source": [
    "### Analyze # of Chunk Ids per ICUSTAY_ID, stratified by ITEMID"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_count_by_icustay_itemid = chunk_analysis_data[['ICUSTAY_ID','ITEMID','CHUNK_ID']]\n",
    "chunk_count_by_icustay_itemid = chunk_count_by_icustay_itemid.drop_duplicates()\n",
    "chunk_count_by_icustay_itemid = chunk_count_by_icustay_itemid.groupby(['ICUSTAY_ID','ITEMID']).count()\n",
    "\n",
    "chunk_count_by_icustay_itemid = chunk_count_by_icustay_itemid.rename(columns = {'CHUNK_ID':'CHUNK_ID_COUNT'})\n",
    "chunk_count_by_icustay_itemid = chunk_count_by_icustay_itemid.reset_index()\n",
    "display(chunk_count_by_icustay_itemid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_count_by_icustay_itemid['ITEMID'] = chunk_count_by_icustay_itemid['ITEMID'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set variables\n",
    "title = \"Chunk Analysis by ICUSTAY and ITEMID\"\n",
    "xlabel = \"Count of Chunks per ICUSTAY\"\n",
    "ylabel = \"Item Id\"\n",
    "plotdata = chunk_count_by_icustay_itemid\n",
    "xvalue = \"CHUNK_ID_COUNT\"\n",
    "yvalue = \"ITEMID\"\n",
    "\n",
    "# Config figure\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(\n",
    "    figsize = (10, 5), \n",
    "    dpi = 72 # e.g. 72 for screen, 300 for print\n",
    "    )\n",
    "ax = sns.boxplot( # Insert on of: sns.stripplot , sns.boxplot , sns.violinplot\n",
    "    data = plotdata, \n",
    "    x = xvalue,\n",
    "    y = yvalue, # Comment out if no stratification is to be performed based on yvalue\n",
    "    palette = sns.color_palette(\"colorblind\")\n",
    "    )\n",
    "ax.set_title(title, fontweight='bold', color= 'black', fontsize=14, y=1.05)\n",
    "ax.set_xlabel(xlabel, fontsize=12, labelpad=15)\n",
    "ax.set_ylabel(ylabel, fontsize=12, labelpad=15) # Comment out if no stratification is to be performed based on yvalue\n",
    "ax.grid(b=True, which='both')\n",
    "ax.margins(.1)\n",
    "\n",
    "# Plot figure\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_count_by_icustay_itemid_avg = chunk_count_by_icustay_itemid.groupby(['ITEMID'])['CHUNK_ID_COUNT'].mean()\n",
    "chunk_count_by_icustay_itemid_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_count_by_icustay_itemid_median = chunk_count_by_icustay_itemid.groupby(['ITEMID'])['CHUNK_ID_COUNT'].median()\n",
    "chunk_count_by_icustay_itemid_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_count_by_icustay_itemid_describe = chunk_count_by_icustay_itemid.groupby(['ITEMID'])['CHUNK_ID_COUNT'].describe()\n",
    "chunk_count_by_icustay_itemid_describe"
   ]
  }
 ]
}