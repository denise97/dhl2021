{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis of Predictions Produced on Model Level with RNNModel Class by Darts\n",
    "\n",
    "This script analyzes all pickle files in `./data/{approach}/{n_chunks}_chunks/{style}/`, starting with `confusion_matrix_models`, i.e. all model results. At the moment, the paths are adapted for local execution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge and Adjust Model Results\n",
    "\n",
    "### Define Variables to Adjust"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define approach\n",
    "approach = 'RNNModel'\n",
    "\n",
    "# Define number of chunks (1000, 2000 or 15000)\n",
    "n_chunks = 2000\n",
    "\n",
    "# Define how many chunks were taken for prediction ('all' or '20_percent')\n",
    "style = 'all'\n",
    "\n",
    "# Defines if scaled values should be read and if yes, which scaled values\n",
    "# '': read non-scaled results\n",
    "# '_v1': read results produced with z-scaled series (same mean and same standard deviation)\n",
    "# '_v2': read results produced with series scaled separately with several MinMaxScalers\n",
    "scaling_version = '_v1'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract All Generated Model Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "\n",
    "# Define path to all model matrices produced by prediction\n",
    "path_to_model_matrices = f'../../data/{approach}/{n_chunks}_chunks/{style}'\n",
    "\n",
    "# Concat all found matrices into result matrix\n",
    "result_matrix_models = pd.DataFrame(columns=['ID', 'PARAMETER', 'RUNTIME', 'MODEL', 'SCALED', 'LIBRARY', 'ENDOGENOUS',\n",
    "                                             'EXOGENOUS', 'FIRST_FORECAST', 'ALARM_TYPE', 'FP', 'TP', 'FN', 'TN',\n",
    "                                             'N_HIGH_ALARMS', 'N_LOW_ALARMS', 'N_CHUNKS', 'N_ITERATIONS'])\n",
    "\n",
    "for file in os.listdir(path_to_model_matrices):\n",
    "    if os.path.isfile(os.path.join(path_to_model_matrices, file)) and \\\n",
    "            file.startswith('confusion_matrix_models') and file.endswith(f'{scaling_version}.pickle'):\n",
    "\n",
    "        # Read file\n",
    "        current_matrix_f = open(f'{path_to_model_matrices}/{file}', 'rb')\n",
    "        current_matrix = pickle.load(current_matrix_f)\n",
    "        current_matrix_f.close()\n",
    "\n",
    "        # Append current matrix to result matrix\n",
    "        result_matrix_models = pd.concat([result_matrix_models, current_matrix])\n",
    "\n",
    "# Align IDs\n",
    "# Note: This is only needed for old 1000-20% runs were model numbers have ranged from '01' to '18'\n",
    "if result_matrix_models['ID'].str.contains('18').any():\n",
    "\n",
    "    # Remove additionally calculated rows\n",
    "    result_matrix_models = result_matrix_models[~((result_matrix_models['ENDOGENOUS'] == 'MAX')\n",
    "                                                  & (result_matrix_models['ALARM_TYPE'] == 'Low') |\n",
    "                                                  (result_matrix_models['ENDOGENOUS'] == 'MIN')\n",
    "                                                  & (result_matrix_models['ALARM_TYPE'] == 'High'))]\n",
    "\n",
    "    # Update rows IDs of scaled results\n",
    "    # RNN (min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('03', '02')\n",
    "    # LSTM (median, max, min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('04', '03')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('05', '04')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('06', '04')\n",
    "    # GRU (median, max, min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('07', '05')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('08', '06')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('09', '06')\n",
    "\n",
    "    # Update rows IDs of non-scaled results\n",
    "    # RNN (median, max, min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('10', '07')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('11', '08')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('12', '08')\n",
    "    # LSTM (median, max, min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('13', '09')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('14', '10')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('15', '10')\n",
    "    # GRU (median, max, min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('16', '11')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('17', '12')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('18', '12')\n",
    "\n",
    "# Reset index\n",
    "result_matrix_models.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Add missing runtimes\n",
    "# Note: This is only needed for old 2000-all runs where script was incomplete\n",
    "if result_matrix_models['RUNTIME'].isnull().values.any():\n",
    "    ids_with_missing_runtimes = result_matrix_models[result_matrix_models['RUNTIME'].isna()].ID\n",
    "\n",
    "    for i, id_high in enumerate(ids_with_missing_runtimes):\n",
    "        id_low = id_high.replace('H_', 'L_')\n",
    "        new_runtime = result_matrix_models.loc[result_matrix_models['ID'] == id_low].RUNTIME\n",
    "        result_matrix_models.at[ids_with_missing_runtimes.index[i], 'RUNTIME'] = new_runtime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add Metrics\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Sensitivity_and_specificity for more information."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add confusion matrix ratios\n",
    "result_matrix_models['FPR'] = result_matrix_models['FP'] / (result_matrix_models['FP'] + result_matrix_models['TN'])\n",
    "result_matrix_models['TPR'] = result_matrix_models['TP'] / (result_matrix_models['TP'] + result_matrix_models['FN'])\n",
    "result_matrix_models['FNR'] = result_matrix_models['FN'] / (result_matrix_models['TP'] + result_matrix_models['FN'])\n",
    "result_matrix_models['TNR'] = result_matrix_models['TN'] / (result_matrix_models['FP'] + result_matrix_models['TN'])\n",
    "\n",
    "# Add accuracy\n",
    "result_matrix_models['ACC'] = (result_matrix_models['TP'] + result_matrix_models['TN']) / \\\n",
    "                              (result_matrix_models['TP'] + result_matrix_models['FN']\n",
    "                               + result_matrix_models['FP'] + result_matrix_models['TN'])\n",
    "\n",
    "# Add F1 score (harmonic mean of precision/PPV and sensitivity/TPR)\n",
    "result_matrix_models['F1S'] = result_matrix_models['TP'] / \\\n",
    "                              (result_matrix_models['TP'] +\n",
    "                               0.5 * (result_matrix_models['FP'] + result_matrix_models['FN']))\n",
    "\n",
    "# Add threat score\n",
    "result_matrix_models['TS'] = result_matrix_models['TP'] / (result_matrix_models['TP'] + result_matrix_models['FN'] + result_matrix_models['FP'])\n",
    "\n",
    "# Add Matthews correlation coefficient\n",
    "result_matrix_models['MCC_divident'] = result_matrix_models['TP'] * result_matrix_models['TN'] - \\\n",
    "                                       result_matrix_models['FP'] * result_matrix_models['FN']\n",
    "result_matrix_models['MCC_divisor'] = ((result_matrix_models['TP'] + result_matrix_models['FP']) *\n",
    "                                              (result_matrix_models['TP'] + result_matrix_models['FN']) *\n",
    "                                              (result_matrix_models['TN'] + result_matrix_models['FP']) *\n",
    "                                              (result_matrix_models['TN'] + result_matrix_models['FN']))**(1/2)\n",
    "result_matrix_models['MCC'] = result_matrix_models['MCC_divident'] / result_matrix_models['MCC_divisor']\n",
    "\n",
    "# Add weighted score from https://physionet.org/content/challenge-2015/1.0.0/\n",
    "# Original: (TP + TN) / (TP + TN + FP + 5*FN)\n",
    "# Adapted: (TP) / (TP + FN + 5*FP)\n",
    "result_matrix_models['WEIGHTED_SCORE_AA'] = result_matrix_models['TP'] / \\\n",
    "                                            (result_matrix_models['TP'] + result_matrix_models['FN'] +\n",
    "                                             (5 * result_matrix_models['FP']))\n",
    "\n",
    "# Round all floats to 4 decimal places\n",
    "# Note: round() does not work for floats with many decimal places\n",
    "decimals = 4\n",
    "for col in ['FPR', 'TPR', 'FNR', 'TNR', 'ACC', 'F1S', 'TS', 'MCC', 'WEIGHTED_SCORE_AA']:\n",
    "    result_matrix_models[col] = result_matrix_models[col].apply(lambda x: round(x, decimals))\n",
    "\n",
    "# Move cols to end for similarity with ARIMA results and drop columns (alarm counts and MCC helper columns)\n",
    "result_matrix_models = result_matrix_models[['ID', 'PARAMETER', 'RUNTIME', 'MODEL', 'SCALED', 'LIBRARY', 'ENDOGENOUS',\n",
    "                                             'EXOGENOUS', 'FIRST_FORECAST', 'ALARM_TYPE', 'TP', 'FN', 'FP', 'TN',\n",
    "                                             'FPR', 'TPR', 'FNR', 'TNR', 'ACC', 'F1S', 'MCC', 'TS', 'WEIGHTED_SCORE_AA',\n",
    "                                             'N_CHUNKS', 'N_ITERATIONS']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add Temporary Missing Rows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get missing IDs\n",
    "if scaling_version == '':\n",
    "    range_min = 6\n",
    "    range_max = 12\n",
    "    id_suffix = ''\n",
    "else:\n",
    "    range_min = 0\n",
    "    range_max = 6\n",
    "    id_suffix = scaling_version\n",
    "\n",
    "id_prefixes = [param + '_R_' + str(nr + 1) if nr >= 9 else param + '_R_0' + str(nr + 1)\n",
    "               for nr in list(range(12))[range_min:range_max] for param in ['BP', 'HR', 'O2']]\n",
    "\n",
    "all_ids = [id_prefix + '_H' + id_suffix for id_prefix in id_prefixes] + [id_prefix + '_L' + id_suffix for id_prefix in id_prefixes]\n",
    "\n",
    "missing_ids = list(set(all_ids).difference(set(pd.unique(result_matrix_models.ID))))\n",
    "print(f'Missing IDs: {missing_ids}')\n",
    "\n",
    "if len(missing_ids) > 0:\n",
    "\n",
    "    # Add missing rows with columns that are not row-specific\n",
    "    missing_rows = pd.DataFrame(data={'ID': list(missing_ids),\n",
    "                                      'LIBRARY' : ['darts'] * len(missing_ids),\n",
    "                                      'FIRST_FORECAST' : [12] * len(missing_ids)})\n",
    "\n",
    "    # Add row-specific columns\n",
    "    missing_rows['PARAMETER'] = missing_rows['ID'].str[:2]\n",
    "    missing_rows['ALARM_TYPE'] = ['Low' if model_id[-1] == 'L' else 'High' for model_id in missing_rows['ID'] ]\n",
    "\n",
    "    scaled_model_numbers = ['0' + str(nr) for nr in list(range(7))][1:]\n",
    "    missing_rows['SCALED'] = [True if model_id.split('_')[2] in scaled_model_numbers else False for model_id in missing_rows['ID']]\n",
    "\n",
    "    missing_rows['MODEL'] = ['RNN' if model_id.split('_')[2] in ['01', '02', '07', '08']\n",
    "                             else 'LSTM' if model_id.split('_')[2] in ['03', '04', '09', '10']\n",
    "                             else 'GRU' for model_id in missing_rows['ID']]\n",
    "\n",
    "    missing_rows['ENDOGENOUS'] = ['Median' if model_id.split('_')[2] in ['01', '07', '03', '09', '05', '11']\n",
    "                                  else 'Max' if model_id[-1] == 'H'\n",
    "                                  else 'Min' for model_id in missing_rows['ID']]\n",
    "\n",
    "    missing_rows['EXOGENOUS'] = [np.nan if model_id.split('_')[2] in ['01', '07', '03', '09', '05', '11']\n",
    "                                 else 'Median' for model_id in missing_rows['ID']]\n",
    "\n",
    "    # Add missing rows (and fill missing columns with NaN by default)\n",
    "    result_matrix_models = pd.concat([result_matrix_models, missing_rows], axis=0, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finalize and Save as Parquet File"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Adjust data types\n",
    "result_matrix_models['SCALED'] = result_matrix_models['SCALED'].astype(bool)\n",
    "result_matrix_models['FIRST_FORECAST'] = result_matrix_models['FIRST_FORECAST'].astype(int)\n",
    "\n",
    "if len(missing_ids) == 0:\n",
    "    result_matrix_models['RUNTIME'] = result_matrix_models['RUNTIME'].astype(int)\n",
    "    result_matrix_models['TP'] = result_matrix_models['TP'].astype(int)\n",
    "    result_matrix_models['TN'] = result_matrix_models['TN'].astype(int)\n",
    "    result_matrix_models['FP'] = result_matrix_models['FP'].astype(int)\n",
    "    result_matrix_models['FN'] = result_matrix_models['FN'].astype(int)\n",
    "\n",
    "# Sort result matrix for better readability\n",
    "result_matrix_models.sort_values(by=['ID'], inplace=True)\n",
    "\n",
    "# Reset index\n",
    "result_matrix_models.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Show result matrix per parameter\n",
    "display(result_matrix_models[result_matrix_models['PARAMETER'] == 'BP'])\n",
    "display(result_matrix_models[result_matrix_models['PARAMETER'] == 'HR'])\n",
    "display(result_matrix_models[result_matrix_models['PARAMETER'] == 'O2'])\n",
    "\n",
    "# Save as parquet file\n",
    "result_matrix_models.to_parquet(f'../../data/{approach}/{n_chunks}_chunks/{style}/rnn_model_results_{n_chunks}_{style}'\n",
    "                                f'{scaling_version}.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine Different Result Matrices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read non-scaled results\n",
    "results_normal = pd.read_parquet(f'../../data/{approach}/{n_chunks}_chunks/{style}/rnn_model_results_{n_chunks}_{style}'\n",
    "                                 f'.parquet', engine='pyarrow')\n",
    "\n",
    "# Remove wrong 01 to 06 entries\n",
    "results_normal = results_normal[results_normal['ID'].str.contains('07|08|09|10|11|12')]\n",
    "\n",
    "\n",
    "# Read z-scaled results\n",
    "results_z_scaled = pd.read_parquet(f'../../data/{approach}/{n_chunks}_chunks/{style}/rnn_model_results_{n_chunks}_'\n",
    "                                   f'{style}_v1.parquet', engine='pyarrow')\n",
    "\n",
    "# Read min-max-scaled results\n",
    "results_min_max_scaled = pd.read_parquet(f'../../data/{approach}/{n_chunks}_chunks/{style}/rnn_model_results_{n_chunks}_'\n",
    "                                         f'{style}_v2.parquet', engine='pyarrow')\n",
    "\n",
    "# Remove IDs 07 to 12\n",
    "results_z_scaled = results_z_scaled[results_z_scaled['ID'].str.contains('01|02|03|04|05|06')]\n",
    "results_min_max_scaled = results_min_max_scaled[results_min_max_scaled['ID'].str.contains('01|02|03|04|05|06')]\n",
    "\n",
    "\n",
    "# Concat both result matrices\n",
    "rnn_model_results = pd.concat([results_normal, results_z_scaled, results_min_max_scaled], axis=0, ignore_index=True)\n",
    "\n",
    "# Sort result matrix for better readability\n",
    "rnn_model_results.sort_values(by=['ID'], inplace=True)\n",
    "\n",
    "# Reset index\n",
    "rnn_model_results.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Show result matrix per parameter\n",
    "display(rnn_model_results[rnn_model_results['PARAMETER'] == 'BP'])\n",
    "display(rnn_model_results[rnn_model_results['PARAMETER'] == 'HR'])\n",
    "display(rnn_model_results[rnn_model_results['PARAMETER'] == 'O2'])\n",
    "\n",
    "# Save as parquet file\n",
    "rnn_model_results.to_parquet(f'../../data/{approach}/{n_chunks}_chunks/{style}/rnn_model_results_{n_chunks}_{style}_'\n",
    "                             f'final.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization of Model Level Results\n",
    "\n",
    "### Setup Variables for All Model Level Plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "approach = 'RNNModel'\n",
    "n_chunks = 2000\n",
    "style = 'all'\n",
    "\n",
    "# Suffix can be '', '_v1, '_v2' or '_final'\n",
    "suffix = '_final'\n",
    "\n",
    "# Avoid error because of non-found values\n",
    "available_parameters = pd.unique(result_matrix_models.PARAMETER)\n",
    "\n",
    "# Only plot columns for available parameters\n",
    "n_cols = len(available_parameters)\n",
    "\n",
    "result_matrix_models = pd.read_parquet(f'../../data/{approach}/{n_chunks}_chunks/{style}/rnn_model_results_{n_chunks}_'\n",
    "                                       f'{style}{suffix}.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Accuracy, TPR, FNR, and TNR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# \"Group\" result matrix by prefix of ID\n",
    "plotdata = result_matrix_models.replace(['_H', '_L'], ['', ''], regex=True)\n",
    "\n",
    "# Create subplots\n",
    "sns.set_style('whitegrid')\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=4,\n",
    "    ncols=n_cols,\n",
    "    figsize=(15, 13),\n",
    "    dpi=72\n",
    "    )\n",
    "\n",
    "#plt.suptitle(f'Accuracy, TPR, FNR, and TNR of {n_chunks} Chunks ({style.replace(\"_\", \" \").upper()})', fontsize=22)\n",
    "\n",
    "# Define y-limits\n",
    "acc_ylimits = [0, result_matrix_models.ACC.max(skipna=True)]\n",
    "tpr_ylimits = [0, result_matrix_models.TPR.max(skipna=True)]\n",
    "fnr_ylimits = [0, result_matrix_models.FNR.max(skipna=True)]\n",
    "tnr_ylimits = [0, result_matrix_models.TNR.max(skipna=True)]\n",
    "\n",
    "# Actual plots\n",
    "for i, parameter in enumerate(available_parameters):\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axs[0, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='ACC',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None,\n",
    "        hue_order=['Low', 'High'])\n",
    "    axs[0, i].set_title(str(parameter), fontweight='bold', color='black', fontsize=20)\n",
    "    axs[0, i].set_ylim(acc_ylimits)\n",
    "    axs[0, i].set_xticklabels(axs[0, i].get_xticklabels(), rotation=90)\n",
    "    axs[0, i].legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axs[1, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='TPR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None,\n",
    "        hue_order=['Low', 'High'])\n",
    "    axs[1, i].set_ylim(tpr_ylimits)\n",
    "    axs[1, i].set_xticklabels(axs[1, i].get_xticklabels(), rotation=90)\n",
    "    axs[1, i].legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axs[2, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='FNR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None,\n",
    "        hue_order=['Low', 'High'])\n",
    "    axs[2, i].set_ylim(fnr_ylimits)\n",
    "    axs[2, i].set_xticklabels(axs[2, i].get_xticklabels(), rotation=90)\n",
    "    axs[2, i].legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax = axs[3, i],\n",
    "        data = plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='TNR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None,\n",
    "        hue_order=['Low', 'High'])\n",
    "    axs[3, i].set_ylim(tnr_ylimits)\n",
    "    axs[3, i].set_xticklabels(axs[3, i].get_xticklabels(), rotation=90)\n",
    "    axs[3, i].legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "# Improve layout and save figure\n",
    "fig.tight_layout()\n",
    "plt.show(fig)\n",
    "fig.savefig(f'../../plots/{approach}/{n_chunks}_chunks/{style}/rnn_results_tpr_fnr_tnr_acc.png', dpi=72)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot False Positive Ratio and F1 Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# \"Group\" result matrix by prefix of ID\n",
    "plotdata = result_matrix_models.replace(['_H', '_L'], ['', ''], regex=True)\n",
    "\n",
    "# Create subplots\n",
    "sns.set_style('whitegrid')\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=n_cols,\n",
    "    figsize=(15, 7),\n",
    "    dpi=72\n",
    "    )\n",
    "\n",
    "#yplt.suptitle(f'FPR and F1S of {n_chunks} Chunks ({style.replace(\"_\", \" \").upper()})', fontsize=22)\n",
    "\n",
    "# Define y-limits\n",
    "fpr_ylimits = [0, result_matrix_models.FPR.max(skipna=True)]\n",
    "f1s_ylimits = [0, result_matrix_models.F1S.max(skipna=True)]\n",
    "\n",
    "# Actual plot\n",
    "for i, parameter in enumerate(available_parameters):\n",
    "\n",
    "    print(f'\\n##### {parameter} #####')\n",
    "\n",
    "    g_fpr = sns.barplot(\n",
    "        ax=axs[0, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='FPR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None,\n",
    "        hue_order=['Low', 'High'])\n",
    "    axs[0, i].set_title(str(parameter), fontweight='bold', color='black', fontsize=14)\n",
    "    axs[0, i].set_ylim(fpr_ylimits)\n",
    "    axs[0, i].set_xticklabels(axs[0, i].get_xticklabels(), rotation=90)\n",
    "    axs[0, i].legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    # Show models with best FPR\n",
    "    best_fpr_low = plotdata[plotdata.FPR == plotdata[(plotdata.PARAMETER == parameter) & (plotdata.ALARM_TYPE == 'Low')].FPR.min()]['FPR'].unique()\n",
    "    print(f'Best low FPR: {best_fpr_low}')\n",
    "    best_fpr_high = plotdata[plotdata.FPR == plotdata[(plotdata.PARAMETER == parameter) & (plotdata.ALARM_TYPE == 'High')].FPR.min()]['FPR'].unique()\n",
    "    print(f'Best high FPR: {best_fpr_high}')\n",
    "\n",
    "    # Add red rectangle around models with best F1 score\n",
    "    for bar in g_fpr.patches:\n",
    "        if bar.get_height() == best_fpr_low or bar.get_height() == best_fpr_high:\n",
    "            bar.set_edgecolor('red')\n",
    "            bar.set_linewidth(2)\n",
    "\n",
    "    g_f1s = sns.barplot(\n",
    "        ax=axs[1, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='F1S',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None,\n",
    "        hue_order=['Low', 'High'])\n",
    "    axs[1, i].set_ylim(f1s_ylimits)\n",
    "    axs[1, i].set_xticklabels(axs[1, i].get_xticklabels(), rotation=90)\n",
    "    axs[1, i].legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    # Show models with best F1 scores\n",
    "    best_f1s_low = plotdata[plotdata.F1S == plotdata[(plotdata.PARAMETER == parameter) & (plotdata.ALARM_TYPE == 'Low')].F1S.max()]['F1S'].unique()\n",
    "    print(f'Best low F1S: {best_f1s_low}')\n",
    "    best_f1s_high = plotdata[plotdata.F1S == plotdata[(plotdata.PARAMETER == parameter) & (plotdata.ALARM_TYPE == 'High')].F1S.max()]['F1S'].unique()\n",
    "    print(f'Best high F1S: {best_f1s_high}')\n",
    "\n",
    "    # Add red rectangle around models with best F1 score\n",
    "    for bar in g_f1s.patches:\n",
    "        if bar.get_height() == best_f1s_low or bar.get_height() == best_f1s_high:\n",
    "            bar.set_edgecolor('red')\n",
    "            bar.set_linewidth(2)\n",
    "\n",
    "# Improve layout and save figure\n",
    "fig.tight_layout()\n",
    "plt.show(fig)\n",
    "fig.savefig(f'../../plots/{approach}/{n_chunks}_chunks/{style}/rnn_results_fpr_f1s.png', dpi=72)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot TS, Weighted Score & MCC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plotdata = result_matrix_models.replace(['_H', '_L'], ['', ''], regex=True)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=3,\n",
    "    ncols=n_cols,\n",
    "    figsize=(20, 12),\n",
    "    dpi=72\n",
    "    )\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.4)\n",
    "\n",
    "ts_ylimits = [0, result_matrix_models.TS.max(skipna=True)]\n",
    "weighted_aa_score_ylimits = [0, result_matrix_models.WEIGHTED_SCORE_AA.max(skipna=True)]\n",
    "mcc_ylimits = [0, result_matrix_models.MCC.max(skipna=True)]\n",
    "\n",
    "for i, parameter in enumerate(available_parameters):\n",
    "\n",
    "    print(f'\\n##### {parameter} #####')\n",
    "\n",
    "    g_ts = sns.barplot(\n",
    "        ax=axs[0, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='TS',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None,\n",
    "        hue_order=['Low', 'High'])\n",
    "    axs[0, i].set_title(str(parameter), fontweight='bold', color='black', fontsize=14)\n",
    "    axs[0, i].set_ylim(ts_ylimits)\n",
    "    axs[0, i].tick_params(axis='x', rotation=90)\n",
    "    axs[0, i].legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    # Show models with best TS\n",
    "    best_ts_low = plotdata[plotdata.TS == plotdata[(plotdata.PARAMETER == parameter) & (plotdata.ALARM_TYPE == 'Low')].TS.max()]['TS'].unique()\n",
    "    print(f'Best low TS: {best_ts_low}')\n",
    "    best_ts_high = plotdata[plotdata.TS == plotdata[(plotdata.PARAMETER == parameter) & (plotdata.ALARM_TYPE == 'High')].TS.max()]['TS'].unique()\n",
    "    print(f'Best high TS: {best_ts_high}')\n",
    "\n",
    "    # Add red rectangle around models with best TS\n",
    "    for bar in g_ts.patches:\n",
    "        if bar.get_height() == best_ts_low or bar.get_height() == best_ts_high :\n",
    "            bar.set_edgecolor('red')\n",
    "            bar.set_linewidth(2)\n",
    "\n",
    "    g_ws_aa = sns.barplot(\n",
    "        ax=axs[1, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='WEIGHTED_SCORE_AA',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None,\n",
    "        hue_order=['Low', 'High'])\n",
    "    axs[1, i].set_ylim(weighted_aa_score_ylimits)\n",
    "    axs[1, i].tick_params(axis='x', rotation=90)\n",
    "    axs[1, i].legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    # Show models with best WS_AA\n",
    "    best_weighted_aa_score_low = plotdata[plotdata.WEIGHTED_SCORE_AA == plotdata[(plotdata.PARAMETER == parameter) & (plotdata.ALARM_TYPE == 'Low')].WEIGHTED_SCORE_AA.max()]['WEIGHTED_SCORE_AA'].unique()\n",
    "    print(f'Best low WS_AA: {best_weighted_aa_score_low}')\n",
    "    best_weighted_aa_score_high = plotdata[plotdata.WEIGHTED_SCORE_AA == plotdata[(plotdata.PARAMETER == parameter) & (plotdata.ALARM_TYPE == 'High')].WEIGHTED_SCORE_AA.max()]['WEIGHTED_SCORE_AA'].unique()\n",
    "    print(f'Best high WS_AA: {best_weighted_aa_score_high}')\n",
    "\n",
    "    # Add red rectangle around models with best WS_AA\n",
    "    for bar in g_ws_aa.patches:\n",
    "        if bar.get_height() == best_weighted_aa_score_low or bar.get_height() == best_weighted_aa_score_high :\n",
    "            bar.set_edgecolor('red')\n",
    "            bar.set_linewidth(2)\n",
    "\n",
    "    g_mcc = sns.barplot(\n",
    "        ax=axs[2, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='MCC',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None,\n",
    "        hue_order=['Low', 'High'])\n",
    "    axs[2, i].set_ylim(mcc_ylimits)\n",
    "    axs[2, i].tick_params(axis='x', rotation=90)\n",
    "    axs[2, i].legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    # Show models with best MCC\n",
    "    best_mcc_low = plotdata[plotdata.MCC == plotdata[(plotdata.PARAMETER == parameter) & (plotdata.ALARM_TYPE == 'Low')].MCC.max()]['MCC'].unique()\n",
    "    print(f'Best low MCC: {best_mcc_low}')\n",
    "    best_mcc_high = plotdata[plotdata.MCC == plotdata[(plotdata.PARAMETER == parameter) & (plotdata.ALARM_TYPE == 'High')].MCC.max()]['MCC'].unique()\n",
    "    print(f'Best high MCC: {best_mcc_high}')\n",
    "\n",
    "    # Add red rectangle around models with best MCC\n",
    "    for bar in g_mcc.patches:\n",
    "        if bar.get_height() == best_mcc_low or bar.get_height() == best_mcc_high :\n",
    "            bar.set_edgecolor('red')\n",
    "            bar.set_linewidth(2)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(f'../../plots/{approach}/{n_chunks}_chunks/{style}/rnn_results_ts_ws_mcc.png', dpi=72, bbox_inches='tight')\n",
    "plt.show(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Add plots comparing model types and scaling influence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Runtimes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plotdata = result_matrix_models.replace(['_H', '_L'], ['', ''], regex=True)\n",
    "\n",
    "# Create subplots\n",
    "sns.set_style('whitegrid')\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=n_cols,\n",
    "    figsize=(15, 7),\n",
    "    dpi=72\n",
    "    )\n",
    "\n",
    "# Add main title\n",
    "plt.suptitle(f'Runtime of Predictions with {n_chunks} Chunks ({style.replace(\"_\", \" \").upper()})', fontsize=22)\n",
    "\n",
    "# Add actual plot and adjust texts\n",
    "for i, parameter in enumerate(available_parameters):\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axs[i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='RUNTIME',\n",
    "        color=sns.color_palette('colorblind')[0],\n",
    "        ci=None)\n",
    "    axs[i].set_title(str(parameter), fontweight='bold', color='black', fontsize=14)\n",
    "    axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=90)\n",
    "    axs[i].set_yticklabels(pd.to_datetime(axs[i].get_yticks(), unit='s').strftime('%d Days %H:%M:%S'))\n",
    "\n",
    "# Improve layout and save figure\n",
    "fig.tight_layout()\n",
    "plt.show(fig)\n",
    "fig.savefig(f'../../plots/{approach}/{n_chunks}_chunks/{style}/rnn_results_runtimes.png', dpi=72)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}