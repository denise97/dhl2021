{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis of Predictions Produced with Chunks and RNNModel by Darts\n",
    "\n",
    "This script analyzes all pickle files in `./data/darts/{n_chunks}_chunks/{style}/`, starting with `confusion_matrix`, i.e. all model-level and all chunk-level matrices. At the moment, the paths are adapted for local execution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis of Model-level Matrices\n",
    "\n",
    "### Define Variables to Adjust for Model-level Analyses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define number of chunks\n",
    "n_chunks = 1000\n",
    "\n",
    "# Define how many chunks were taken for prediction ('all' or '20_percent')\n",
    "style = 'all'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract All Generated Model-level Matrices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "\n",
    "# Define path to all model-level matrices produced by prediction\n",
    "path_to_model_matrices = f'../../data/darts/{n_chunks}_chunks/{style}'\n",
    "\n",
    "# Concat all found matrices into result matrix\n",
    "result_matrix_models = pd.DataFrame(columns=['ID', 'PARAMETER', 'MODEL', 'ENDOGENOUS', 'EXOGENOUS', 'FIRST_FORECAST',\n",
    "                                             'ALARM_TYPE', 'FP', 'TP', 'FN', 'TN', 'N_CHUNKS', 'N_ITERATIONS'])\n",
    "\n",
    "for file in os.listdir(path_to_model_matrices):\n",
    "    if os.path.isfile(os.path.join(path_to_model_matrices, file)) and \\\n",
    "            file.startswith('confusion_matrix_models') and file.endswith('.pickle'):\n",
    "\n",
    "        # Read file\n",
    "        current_matrix_f = open(f'{path_to_model_matrices}/{file}', 'rb')\n",
    "        current_matrix = pickle.load(current_matrix_f)\n",
    "        current_matrix_f.close()\n",
    "\n",
    "        # Append current matrix to result matrix\n",
    "        result_matrix_models = pd.concat([result_matrix_models, current_matrix])\n",
    "\n",
    "# Align IDs of both styles\n",
    "# Note: Needed as long as scripts are not executed again! (current execution use model numbers from 01 to 18)\n",
    "if style == '20_percent' and n_chunks == 1000:\n",
    "\n",
    "    # Remove additionally calculated rows\n",
    "    result_matrix_models = result_matrix_models[~((result_matrix_models['ENDOGENOUS'] == 'MAX') & (result_matrix_models['ALARM_TYPE'] == 'Low') |\n",
    "                                                  (result_matrix_models['ENDOGENOUS'] == 'MIN') & (result_matrix_models['ALARM_TYPE'] == 'High'))]\n",
    "\n",
    "    # Update rows IDs of scaled results\n",
    "    # RNN (min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('03', '02')\n",
    "    # LSTM (median, max, min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('04', '03')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('05', '04')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('06', '04')\n",
    "    # GRU (median, max, min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('07', '05')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('08', '06')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('09', '06')\n",
    "\n",
    "    # Update rows IDs of non-scaled results\n",
    "    # RNN (median, max, min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('10', '07')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('11', '08')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('12', '08')\n",
    "    # LSTM (median, max, min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('13', '09')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('14', '10')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('15', '10')\n",
    "    # GRU (median, max, min)\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('16', '11')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('17', '12')\n",
    "    result_matrix_models['ID'] = result_matrix_models['ID'].str.replace('18', '12')\n",
    "\n",
    "# Sort result matrix for better readability\n",
    "result_matrix_models.sort_values(by=['ID'], inplace=True)\n",
    "\n",
    "# Reset index\n",
    "result_matrix_models.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Show result matrix per parameter\n",
    "display(result_matrix_models[result_matrix_models['PARAMETER'] == 'HR'])\n",
    "display(result_matrix_models[result_matrix_models['PARAMETER'] == 'BP'])\n",
    "display(result_matrix_models[result_matrix_models['PARAMETER'] == 'O2'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add Accuracy Metrics and Save as Parquet Files (Normal + Scaled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate metrics (see https://en.wikipedia.org/wiki/Sensitivity_and_specificity for more information)\n",
    "result_matrix_models['FPR'] = result_matrix_models['FP'] / (result_matrix_models['FP'] + result_matrix_models['TN'])\n",
    "result_matrix_models['TPR'] = result_matrix_models['TP'] / (result_matrix_models['TP'] + result_matrix_models['FN'])\n",
    "result_matrix_models['FNR'] = result_matrix_models['FN'] / (result_matrix_models['TP'] + result_matrix_models['FN'])\n",
    "result_matrix_models['TNR'] = result_matrix_models['TN'] / (result_matrix_models['FP'] + result_matrix_models['TN'])\n",
    "\n",
    "result_matrix_models['ACC'] = (result_matrix_models['TP'] + result_matrix_models['TN']) / \\\n",
    "                              (result_matrix_models['TP'] + result_matrix_models['FN'] + result_matrix_models['FP'] + result_matrix_models['TN'])\n",
    "result_matrix_models['F1S'] = result_matrix_models['TP'] / \\\n",
    "                              (result_matrix_models['TP'] + 0.5 * (result_matrix_models['FP'] + result_matrix_models['FN']))\n",
    "\n",
    "# Round all floats to 4 decimal places\n",
    "# Note: round() does not work for floats with many decimal places\n",
    "decimals = 4\n",
    "for col in ['FPR', 'TPR', 'FNR', 'TNR', 'ACC', 'F1S']:\n",
    "    result_matrix_models[col] = result_matrix_models[col].apply(lambda x: round(x, decimals))\n",
    "\n",
    "# Move cols to end for similarity with ARIMA results\n",
    "result_matrix_models = result_matrix_models[['ID', 'PARAMETER', 'MODEL', 'ENDOGENOUS', 'EXOGENOUS', 'FIRST_FORECAST',\n",
    "                                             'ALARM_TYPE', 'FP', 'TP', 'FN', 'TN', 'FPR', 'TPR', 'FNR', 'TNR', 'ACC',\n",
    "                                             'F1S', 'N_HIGH_ALARMS', 'N_LOW_ALARMS', 'N_CHUNKS', 'N_ITERATIONS']]\n",
    "\n",
    "# Generate list with model numbers from 07 to 12\n",
    "normal_model_numbers = ['0' + str(nr) if nr < 10 else str(nr) for nr in list(range(13))][7:]\n",
    "# Generate list with model numbers from 01 to 06\n",
    "scaled_model_numbers = ['0' + str(nr) for nr in list(range(7))][1:]\n",
    "\n",
    "# Extract normal and scaled rows (see model number in comment below)\n",
    "normal_rows, scaled_rows = list(), list()\n",
    "for i, row in result_matrix_models.iterrows():\n",
    "    if row['ID'].split('_')[2] in normal_model_numbers:\n",
    "        normal_rows.append(row.values)\n",
    "    elif row['ID'].split('_')[2] in scaled_model_numbers:\n",
    "        scaled_rows.append(row.values)\n",
    "\n",
    "# Add extracted rows to final matrices\n",
    "result_matrix_models_normal = (pd.DataFrame(normal_rows, columns=result_matrix_models.columns)).reset_index(drop=True)\n",
    "result_matrix_models_scaled = (pd.DataFrame(scaled_rows, columns=result_matrix_models.columns)).reset_index(drop=True)\n",
    "\n",
    "# Show complemented result matrices per parameter\n",
    "display(result_matrix_models_normal[result_matrix_models_normal['PARAMETER'] == 'HR'])\n",
    "display(result_matrix_models_scaled[result_matrix_models_scaled['PARAMETER'] == 'HR'])\n",
    "\n",
    "display(result_matrix_models_normal[result_matrix_models_normal['PARAMETER'] == 'BP'])\n",
    "display(result_matrix_models_scaled[result_matrix_models_scaled['PARAMETER'] == 'BP'])\n",
    "\n",
    "display(result_matrix_models_normal[result_matrix_models_normal['PARAMETER'] == 'O2'])\n",
    "display(result_matrix_models_scaled[result_matrix_models_scaled['PARAMETER'] == 'O2'])\n",
    "\n",
    "# Save result matrices as parquet\n",
    "result_matrix_models_normal.to_parquet(f'../../data/darts/{n_chunks}_chunks/{style}/result_matrix_models_normal.parquet',\n",
    "                                       engine='pyarrow')\n",
    "result_matrix_models_scaled.to_parquet(f'../../data/darts/{n_chunks}_chunks/{style}/result_matrix_models_scaled.parquet',\n",
    "                                       engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining Variables for All Model-level Plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Avoid error because of non-found values\n",
    "available_parameters = pd.unique(result_matrix_models.PARAMETER)\n",
    "\n",
    "# Only plot columns for available parameters\n",
    "n_cols = len(available_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Accuracy, TPR, FNR, and TNR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# \"Group\" result matrix by prefix of ID\n",
    "plotdata = result_matrix_models.replace(['_H', '_L'], ['', ''], regex=True)\n",
    "\n",
    "# Create subplots\n",
    "sns.set_style('whitegrid')\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=4,\n",
    "    ncols=n_cols,\n",
    "    figsize=(15, 13),\n",
    "    dpi=72\n",
    "    )\n",
    "\n",
    "plt.suptitle(f'Accuracy, TPR, FNR, and TNR of {n_chunks} Chunks ({style.replace(\"_\", \" \").upper()})', fontsize=22)\n",
    "\n",
    "# Define y-limits\n",
    "acc_ylimits = [0, max(result_matrix_models.ACC)]\n",
    "tpr_ylimits = [0, max(result_matrix_models.TPR)]\n",
    "fnr_ylimits = [0, max(result_matrix_models.FNR)]\n",
    "tnr_ylimits = [0, max(result_matrix_models.TNR)]\n",
    "\n",
    "# Actual plots\n",
    "for i, parameter in enumerate(available_parameters):\n",
    "\n",
    "    if n_cols == 1:\n",
    "        axes_acc = axs[0]\n",
    "        axes_tpr = axs[1]\n",
    "        axes_fnr = axs[2]\n",
    "        axes_tnr = axs[3]\n",
    "    else:\n",
    "        axes_acc = axs[0, i]\n",
    "        axes_tpr = axs[1, i]\n",
    "        axes_fnr = axs[2, i]\n",
    "        axes_tnr = axs[3, i]\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axes_acc,\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='ACC',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axes_acc.set_title(str(parameter), fontweight='bold', color= 'black', fontsize=20)\n",
    "    axes_acc.set_ylim(acc_ylimits)\n",
    "    axes_acc.set_xticklabels(axes_acc.get_xticklabels(), rotation=90)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axes_tpr,\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='TPR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axes_tpr.set_ylim(tpr_ylimits)\n",
    "    axes_tpr.set_xticklabels(axes_tpr.get_xticklabels(), rotation=90)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axes_fnr,\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='FNR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axes_fnr.set_ylim(fnr_ylimits)\n",
    "    axes_fnr.set_xticklabels(axes_fnr.get_xticklabels(), rotation=90)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax = axes_tnr,\n",
    "        data = plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='TNR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axes_tnr.set_ylim(tnr_ylimits)\n",
    "    axes_tnr.set_xticklabels(axes_tnr.get_xticklabels(), rotation=90)\n",
    "\n",
    "# Improve layout and save figure\n",
    "fig.tight_layout()\n",
    "plt.show(fig)\n",
    "#fig.savefig(f'../../plots/darts/{n_chunks}_chunks/{style}/tpr_fnr_tnr_acc_model_result_matrix.png', dpi=1200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot False Positive Ratio and F1 Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# \"Group\" result matrix by prefix of ID\n",
    "plotdata = result_matrix_models.replace(['_H', '_L'], ['', ''], regex=True)\n",
    "\n",
    "# Create subplots\n",
    "sns.set_style('whitegrid')\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=n_cols,\n",
    "    figsize=(15, 7),\n",
    "    dpi=72\n",
    "    )\n",
    "\n",
    "plt.suptitle(f'FPR and F1S of {n_chunks} Chunks ({style.replace(\"_\", \" \").upper()})', fontsize=22)\n",
    "\n",
    "# Define y-limits\n",
    "fpr_ylimits = [0, max(result_matrix_models.FPR)]\n",
    "f1s_ylimits = [0, max(result_matrix_models.F1S)]\n",
    "\n",
    "# Actual plot\n",
    "for i, parameter in enumerate(available_parameters):\n",
    "\n",
    "    if n_cols == 1:\n",
    "        axes_fpr = axs[0]\n",
    "        axes_fs1 = axs[1]\n",
    "    else:\n",
    "        axes_fpr = axs[0, i]\n",
    "        axes_fs1 = axs[1, i]\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axes_fpr,\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='FPR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axes_fpr.set_title(str(parameter), fontweight='bold', color= 'black', fontsize=14)\n",
    "    axes_fpr.set_ylim(fpr_ylimits)\n",
    "    axes_fpr.set_xticklabels(axes_fpr.get_xticklabels(), rotation=90)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axes_fs1,\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='F1S',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axes_fs1.set_ylim(f1s_ylimits)\n",
    "    axes_fs1.set_xticklabels(axes_fs1.get_xticklabels(), rotation=90)\n",
    "\n",
    "# Improve layout and save figure\n",
    "fig.tight_layout()\n",
    "plt.show(fig)\n",
    "#fig.savefig(f'../../plots/darts/{n_chunks}_chunks/{style}/fpr_f1s_model_result_matrix.png', dpi=1200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BEST MODELS\n",
    "\n",
    "Scaled:\n",
    "    RNN,     MEDIAN:  01\n",
    "    RNN,     COV:     02\n",
    "    LSTM,    MEDIAN:  03\n",
    "    LSTM,    COV:     04\n",
    "    GRU,     MEDIAN:  05\n",
    "    GRU,     COV:     06\n",
    "\n",
    "Normal:\n",
    "    RNN,     MEDIAN:  07 -> best for HR & BP\n",
    "    RNN,     COV:     08\n",
    "    LSTM,    MEDIAN:  09\n",
    "    LSTM,    COV:     10\n",
    "    GRU,     MEDIAN:  11 -> best for O2\n",
    "    GRU,     COV:     12\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis of Chunk-level Matrices\n",
    "\n",
    "The following analysis steps are only performed for one chunk-specific matrix file.\n",
    "\n",
    "### Define Variables to Adjust for Model-level Analyses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Adjust variables defining path\n",
    "n_chunks = 1000\n",
    "style = 'all'\n",
    "\n",
    "# Adjust variables defining model\n",
    "version = 'normal'\n",
    "model_type = 'LSTM'\n",
    "parameter = 'o2'\n",
    "endogenous_input = 'MEDIAN'\n",
    "\n",
    "# Adjust variable defining selected window of chunks to predict\n",
    "window_idx = 0\n",
    "\n",
    "# Adjust variable for correlation plot\n",
    "input_length = 12"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print One Chunk-level Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "\n",
    "# Define path to all chunk-level matrices produced by prediction\n",
    "path_to_chunk_matrices = f'../../data/darts/{n_chunks}_chunks/{style}'\n",
    "\n",
    "# Read chunk-specific matrix\n",
    "chunks_matrix_f = open(f'{path_to_chunk_matrices}/confusion_matrix_chunks_{model_type}_{parameter}_{endogenous_input}_'\n",
    "                       f'{version}_window{window_idx}.pickle', 'rb')\n",
    "chunks_matrix = pickle.load(chunks_matrix_f)\n",
    "chunks_matrix_f.close()\n",
    "\n",
    "# Show chunk-specific matrix\n",
    "display(chunks_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add Metrics to Each Chunk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Note: To avoid dividing by zero, zeros are converted to NaN before division (since any value divided by NaN gives NaN)\n",
    "\n",
    "chunks_matrix['fp_tn_divisor'] = chunks_matrix['FP'] + chunks_matrix['TN']\n",
    "chunks_matrix['TNR'] = chunks_matrix.TN.div(chunks_matrix.fp_tn_divisor.where(chunks_matrix.fp_tn_divisor != 0, np.nan))\n",
    "chunks_matrix['FPR'] = chunks_matrix.FP.div(chunks_matrix.fp_tn_divisor.where(chunks_matrix.fp_tn_divisor != 0, np.nan)) # 1 - TNR\n",
    "\n",
    "chunks_matrix['fn_tp_divisor'] = chunks_matrix['FN'] + chunks_matrix['TP']\n",
    "chunks_matrix['TPR'] = chunks_matrix.TP.div(chunks_matrix.fn_tp_divisor.where(chunks_matrix.fn_tp_divisor != 0, np.nan))\n",
    "chunks_matrix['FNR'] = chunks_matrix.FN.div(chunks_matrix.fn_tp_divisor.where(chunks_matrix.fn_tp_divisor != 0, np.nan)) # 1 - TPR\n",
    "\n",
    "chunks_matrix['F1S_divisor'] = chunks_matrix['TP'] + 0.5 * (chunks_matrix['FP'] + chunks_matrix['FN'])\n",
    "chunks_matrix['F1S'] = chunks_matrix.TP.div(chunks_matrix.F1S_divisor.where(chunks_matrix.F1S_divisor != 0, np.nan))\n",
    "\n",
    "chunks_matrix['ACC_dividend'] = chunks_matrix['TN'] + chunks_matrix['TP']\n",
    "chunks_matrix['ACC_divisor'] = chunks_matrix['fp_tn_divisor'] + chunks_matrix['fn_tp_divisor']\n",
    "chunks_matrix['ACC'] = chunks_matrix.ACC_dividend.div(chunks_matrix.ACC_divisor.where(chunks_matrix.ACC_divisor != 0,\n",
    "                                                                                      np.nan))\n",
    "\n",
    "# Round all floats to 4 decimal places\n",
    "# Note: round() does not work for floats with many decimal places\n",
    "decimals = 4\n",
    "for col in ['FPR', 'TPR', 'FNR', 'TNR', 'ACC', 'F1S']:\n",
    "    chunks_matrix[col] = chunks_matrix[col].apply(lambda x: round(x, decimals))\n",
    "\n",
    "# Sort and remove helper columns for similarity with model-level matrices\n",
    "chunks_matrix = chunks_matrix[['CHUNK_ID', 'PARAMETER', 'MODEL', 'ENDOGENOUS', 'EXOGENOUS', 'FIRST_FORECAST',\n",
    "                               'ALARM_TYPE', 'FP', 'TP', 'FN', 'TN', 'FPR', 'TPR', 'FNR', 'TNR', 'ACC', 'F1S',\n",
    "                               'N_HIGH_ALARMS', 'N_LOW_ALARMS', 'N_ITERATIONS']]\n",
    "\n",
    "# Show complemented chunk-level matrix for one chunk\n",
    "display(chunks_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Correlation Between Chunk Length and F1 Score/ Specificity (TNR) of Chunk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add column for chunk length to all chunks of matrix\n",
    "chunks_matrix['LENGTH'] = chunks_matrix['N_ITERATIONS'] + input_length\n",
    "\n",
    "for metric in ['F1S', 'TNR']:\n",
    "\n",
    "    # Define background color, subplots and suptitle\n",
    "    sns.set_style('whitegrid')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    fig.suptitle(f'Correlation of Chunk Length and {metric} of Chunk ({style.replace(\"_\", \" \").upper()})', fontsize=14)\n",
    "\n",
    "    if endogenous_input == 'MIN':\n",
    "        ax1.set_visible(False)\n",
    "        ax2.set_position([1, 0.2, 0.05, 0.2])\n",
    "    else:\n",
    "        # Extract chunks for high and low analysis plot\n",
    "        high_chunks = chunks_matrix[chunks_matrix['ALARM_TYPE'] == 'High'][[metric, 'LENGTH']]\n",
    "\n",
    "        # Introduce mean value for each length\n",
    "        # Note: If mean value of metric is used, lines can be drawn again (with default of linestyle parameter)\n",
    "        #high_chunks = high_chunks.astype(float)\n",
    "        #high_chunks = high_chunks.groupby('LENGTH').mean()\n",
    "\n",
    "        # Reset indices to make access via column names possible again\n",
    "        high_chunks.reset_index(level=0, inplace=True, drop=True)\n",
    "\n",
    "        # Add left plot (high threshold analysis)\n",
    "        ax1.plot('LENGTH', metric, data=high_chunks, marker='o', color=sns.color_palette('colorblind')[0],\n",
    "                 linestyle='None')\n",
    "        ax1.set_title(f'{metric} Regarding High Thresholds', fontsize=10)\n",
    "        ax1.set_xlabel('Chunk Length', fontsize=8)\n",
    "        ax1.set_ylabel(f'{metric} of Chunk', fontsize=8)\n",
    "        ax1.set_ylim(bottom=0, top=1.1)\n",
    "\n",
    "    if endogenous_input == 'MAX':\n",
    "        ax2.set_visible(False)\n",
    "        ax1.set_position([0, 0.2, 0.05, 0.2])\n",
    "    else:\n",
    "        # Extract chunks for high and low analysis plot\n",
    "        low_chunks = chunks_matrix[chunks_matrix['ALARM_TYPE'] == 'Low'][[metric, 'LENGTH']]\n",
    "\n",
    "        # Introduce mean value for each length\n",
    "        # Note: If mean value of metric is used, lines can be drawn again (with default of linestyle parameter)\n",
    "        #low_chunks = vlow_chunks.astype(float)\n",
    "        #low_chunks = low_chunks.groupby('LENGTH').mean()\n",
    "\n",
    "        # Reset indices to make access via column names possible again\n",
    "        low_chunks.reset_index(level=0, inplace=True, drop=True)\n",
    "\n",
    "        # Add right plot (low threshold analysis)\n",
    "        ax2.plot('LENGTH', metric, data=low_chunks, marker='o', color=sns.color_palette('colorblind')[1],\n",
    "                 linestyle='None')\n",
    "        ax2.set_title(f'{metric} Regarding Low Thresholds', fontsize=10)\n",
    "        ax2.set_xlabel('Chunk Length', fontsize=8)\n",
    "        ax2.set_ylabel(f'{metric} of Chunk', fontsize=8)\n",
    "        ax2.set_ylim(bottom=0, top=1.1)\n",
    "\n",
    "    # Improve layout and save figure\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    #fig.savefig(f'../../plots/darts/{n_chunks}_chunks/{style}/correlation_chunk_length_and_{metric}_{model_type}_{parameter}_'\n",
    "    #            f'{endogenous_input}_{version}.png', dpi=1200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Time-Series Plot of Chunk with Prediction\n",
    "\n",
    "Note: `chunks_ids_plotting` have to be adjusted manually."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Original amount of chunks: {len(chunks_matrix)}\\n')\n",
    "\n",
    "interesting_chunks = chunks_matrix[chunks_matrix.FPR.notnull() & chunks_matrix.F1S.notnull()]\n",
    "print(f'Amount of interesting chunks: {len(interesting_chunks)}\\n')\n",
    "\n",
    "print(interesting_chunks[['CHUNK_ID', 'FPR', 'TPR', 'FNR', 'TNR', 'ACC', 'F1S', 'N_HIGH_ALARMS', 'N_LOW_ALARMS']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "import pandas as pd\n",
    "\n",
    "chunks_ids_plotting = ['200098.0_220277.0_2136-03-27 12:00:00', '200061.0_220277.0_2134-01-24 14:15:00']\n",
    "\n",
    "for chunk_id in chunks_ids_plotting:\n",
    "\n",
    "    # Format chunk IDs into Windows format that have to be used when loading from or saving to Windows machine\n",
    "    chunk_id_win10 = chunk_id.replace(':', '%3A')\n",
    "\n",
    "    # Extract predicted series of chunk\n",
    "    prediction_chunk_f = open(f'../../data/darts/{n_chunks}_chunks/{style}/{model_type}/{parameter}/{endogenous_input}/'\n",
    "                              f'05_prediction_{chunk_id_win10}_{version}_window{window_idx}.pickle', 'rb')\n",
    "    prediction_chunk = pickle.load(prediction_chunk_f)\n",
    "    prediction_chunk_f.close()\n",
    "\n",
    "    # Convert predicted series of chunk to TimeSeries object\n",
    "    prediction_chunk = TimeSeries.from_dataframe(\n",
    "        df=prediction_chunk,\n",
    "        time_col='Time',\n",
    "        value_cols=['Value'],\n",
    "        freq='H')\n",
    "\n",
    "    # Extract original series of chunk\n",
    "    resampled_chunks = pd.read_parquet(f'../../data/resampling/resample_output_{parameter}_first{n_chunks}.parquet',\n",
    "                                       engine='pyarrow')\n",
    "    original_chunk = resampled_chunks[resampled_chunks['CHUNK_ID_FILLED_TH'] == chunk_id]\n",
    "\n",
    "    # Convert original series of chunk to TimeSeries object\n",
    "    original_chunk = TimeSeries.from_dataframe(\n",
    "        df=original_chunk,\n",
    "        time_col='CHARTTIME',\n",
    "        value_cols=[f'VITAL_PARAMTER_VALUE_{endogenous_input}_RESAMPLING'],\n",
    "        freq='H')\n",
    "\n",
    "    # Actual plot\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    original_chunk.plot(label=f'{parameter.upper()} - actual')\n",
    "    prediction_chunk.plot(label=f'{parameter.upper()} - predicted')\n",
    "\n",
    "    # Adjust texts of plot\n",
    "    plt.legend()\n",
    "    plt.suptitle(f'Prediction of {parameter.upper()} with {n_chunks} Chunks, {endogenous_input} Input, and {model_type} \\n({style.replace(\"_\", \" \").upper()})'\n",
    "                 f' Model', fontweight='bold')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "\n",
    "    plt.show()\n",
    "    #plt.savefig(f'../../plots/darts/{n_chunks}_chunks/{style}/prediction_{model_type}_{parameter}_{endogenous_input}_'\n",
    "    #            f'{chunk_id_win10}_{version}.png', dpi=1200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Investigate Runtime\n",
    "\n",
    "Note: To read an Excel file, you first need to install `openpyxl` with `pip install openpyxl`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Define variable identifying path\n",
    "n_chunks = 1000\n",
    "style = 'all'\n",
    "\n",
    "# Convert excel table into pandas data frame\n",
    "runtimes = pd.read_excel(f'../../data/darts/{n_chunks}_chunks/{style}/runtimes.xlsx', usecols='A:H')\n",
    "\n",
    "# Add column for model number\n",
    "def get_model_nr(current_row):\n",
    "    model_numbers = {\n",
    "        ('s',   'RNN',      'median'):  '01',\n",
    "        ('s',   'RNN',      'cov'):     '02',\n",
    "        ('s',   'LSTM',     'median'):  '03',\n",
    "        ('s',   'LSTM',     'cov'):     '04',\n",
    "        ('s',   'GRU',      'median'):  '05',\n",
    "        ('s',   'GRU',      'cov'):     '06',\n",
    "        ('n',   'RNN',      'median'):  '07',\n",
    "        ('n',   'RNN',      'cov'):     '08',\n",
    "        ('n',   'LSTM',     'median'):  '09',\n",
    "        ('n',   'LSTM',     'cov'):     '10',\n",
    "        ('n',   'GRU',      'median'):  '11',\n",
    "        ('n',   'GRU',      'cov'):     '12'\n",
    "    }\n",
    "    return model_numbers[current_row['VERSION'], current_row['MODEL'], current_row['ENDOGENOUS']]\n",
    "\n",
    "runtimes['MODEL_NR'] = runtimes.apply(lambda row: get_model_nr(row), axis=1)\n",
    "runtimes.sort_values(by=['MODEL_NR'], inplace=True)\n",
    "\n",
    "# Convert runtime into seconds\n",
    "def get_sec(current_row):\n",
    "    h, m, s = str(current_row['RUNTIME']).split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "runtimes['RUNTIME_SEC'] = runtimes.apply(lambda row: get_sec(row), axis=1)\n",
    "\n",
    "# Set parameters\n",
    "available_parameters = pd.unique(runtimes.PARAMETER)\n",
    "n_cols = len(available_parameters)\n",
    "\n",
    "# Create subplots\n",
    "sns.set_style('whitegrid')\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=n_cols,\n",
    "    figsize=(15, 7),\n",
    "    dpi=72\n",
    "    )\n",
    "\n",
    "# Add main title\n",
    "plt.suptitle(f'Runtime of Predictions with {n_chunks} Chunks ({style.replace(\"_\", \" \").upper()})', fontsize=22)\n",
    "\n",
    "# Add actual plot and adjust texts\n",
    "for i, parameter in enumerate(available_parameters):\n",
    "\n",
    "    if n_cols == 1:\n",
    "        axes_runtime = axs\n",
    "    else:\n",
    "        axes_runtime = axs[i]\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axes_runtime,\n",
    "        data=runtimes[runtimes.PARAMETER == parameter],\n",
    "        x='MODEL_NR',\n",
    "        y='RUNTIME_SEC',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axes_runtime.set_title(str(parameter), fontweight='bold', color= 'black', fontsize=14)\n",
    "    axes_runtime.set_xlabel('MODEL NUMBER')\n",
    "    axes_runtime.set_ylabel('RUNTIME (sec)')\n",
    "    axes_runtime.set_xticklabels(axes_runtime.get_xticklabels(), rotation=90)\n",
    "\n",
    "# Improve layout and save figure\n",
    "fig.tight_layout()\n",
    "plt.show(fig)\n",
    "#fig.savefig(f'../../plots/darts/{n_chunks}_chunks/{style}/runtimes.png', dpi=1200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}