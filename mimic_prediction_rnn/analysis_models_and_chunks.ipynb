{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis of Predictions Produced with Chunks and RNNModel by Darts\n",
    "\n",
    "This script analyzes all pickle files in `./data/darts/{n_chunks}_chunks/`, starting with `confusion_matrix`, i.e. all model-level and all chunk-level matrices. At the moment, the paths are adapted for local execution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis of Model-level Matrices\n",
    "\n",
    "### Extract All Generated Model-level Matrices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "\n",
    "# Define number of chunks taken to adjust\n",
    "n_chunks = 1000\n",
    "\n",
    "# Define path to all model-level matrices produced by prediction\n",
    "path_to_model_matrices = f'../../data/darts/{n_chunks}_chunks'\n",
    "\n",
    "# Collect pickle file names of model-level matrices\n",
    "model_matrix_filenames = list()\n",
    "\n",
    "for file in os.listdir(path_to_model_matrices):\n",
    "    if os.path.isfile(os.path.join(path_to_model_matrices, file)) and \\\n",
    "            file.startswith('confusion_matrix_models') and file.endswith('.pickle'):\n",
    "        model_matrix_filenames.append(file)\n",
    "\n",
    "# Concat all found matrices into result matrix\n",
    "result_matrix_models = pd.DataFrame(columns=['ID', 'PARAMETER', 'MODEL', 'ENDOGENOUS', 'EXOGENOUS', 'FIRST_FORECAST',\n",
    "                                             'ALARM_TYPE', 'FP', 'TP', 'FN', 'TN', 'N_CHUNKS', 'N_ITERATIONS'])\n",
    "\n",
    "for filename in model_matrix_filenames:\n",
    "    # Read file\n",
    "    current_matrix_f = open(f'{path_to_model_matrices}/{filename}', 'rb')\n",
    "    current_matrix = pickle.load(current_matrix_f)\n",
    "    current_matrix_f.close()\n",
    "\n",
    "    # Append current matrix to result matrix\n",
    "    result_matrix_models = pd.concat([result_matrix_models, current_matrix])\n",
    "\n",
    "# Sort result matrix for better readability\n",
    "result_matrix_models.sort_values(by=['ID'], inplace=True)\n",
    "\n",
    "# Reset index\n",
    "result_matrix_models.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Show result matrix per parameter\n",
    "display(result_matrix_models[result_matrix_models['PARAMETER'] == 'HR'])\n",
    "display(result_matrix_models[result_matrix_models['PARAMETER'] == 'BP'])\n",
    "display(result_matrix_models[result_matrix_models['PARAMETER'] == 'O2'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add Accuracy Metrics and Save as Parquet Files (Normal + Scaled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate metrics (see https://en.wikipedia.org/wiki/Sensitivity_and_specificity for more information)\n",
    "result_matrix_models['FPR'] = result_matrix_models['FP'] / (result_matrix_models['FP'] + result_matrix_models['TN'])\n",
    "result_matrix_models['TPR'] = result_matrix_models['TP'] / (result_matrix_models['TP'] + result_matrix_models['FN'])\n",
    "result_matrix_models['FNR'] = result_matrix_models['FN'] / (result_matrix_models['TP'] + result_matrix_models['FN'])\n",
    "result_matrix_models['TNR'] = result_matrix_models['TN'] / (result_matrix_models['FP'] + result_matrix_models['TN'])\n",
    "\n",
    "result_matrix_models['ACC'] = (result_matrix_models['TP'] + result_matrix_models['TN']) / \\\n",
    "                              (result_matrix_models['TP'] + result_matrix_models['FN'] + result_matrix_models['FP'] + result_matrix_models['TN'])\n",
    "result_matrix_models['F1S'] = result_matrix_models['TP'] / \\\n",
    "                              (result_matrix_models['TP'] + 0.5 * (result_matrix_models['FP'] + result_matrix_models['FN']))\n",
    "\n",
    "# Round all floats to 4 decimal places\n",
    "# Note: round() does not work for floats with many decimal places\n",
    "decimals = 4\n",
    "for col in ['FPR', 'TPR', 'FNR', 'TNR', 'ACC', 'F1S']:\n",
    "    result_matrix_models[col] = result_matrix_models[col].apply(lambda x: round(x, decimals))\n",
    "\n",
    "# Move cols to end for similarity with ARIMA results\n",
    "result_matrix_models = result_matrix_models[['ID', 'PARAMETER', 'MODEL', 'ENDOGENOUS', 'EXOGENOUS', 'FIRST_FORECAST',\n",
    "                                             'ALARM_TYPE', 'FP', 'TP', 'FN', 'TN', 'FPR', 'TPR', 'FNR', 'TNR', 'ACC',\n",
    "                                             'F1S', 'N_HIGH_ALARMS', 'N_LOW_ALARMS', 'N_CHUNKS', 'N_ITERATIONS']]\n",
    "\n",
    "# Extract normal and scaled rows (see model number in comment below)\n",
    "normal_model_numbers = [str(nr) for nr in list(range(20))][10:]\n",
    "scaled_model_numbers = ['0' + str(nr) for nr in list(range(10))]\n",
    "normal_rows, scaled_rows = list(), list()\n",
    "\n",
    "\"\"\"\n",
    "Normal:\n",
    "    RNN,     MEDIAN:  10\n",
    "    RNN,     MAX:     11 -> best for BP\n",
    "    RNN,     MIN:     12 -> best for HR\n",
    "    LSTM,    MEDIAN:  13\n",
    "    LSTM,    MAX:     14\n",
    "    LSTM,    MIN:     15\n",
    "    GRU,     MEDIAN:  16\n",
    "    GRU,     MAX:     17 -> best for O2\n",
    "    GRU,     MIN:     18\n",
    "\n",
    "Scaled:\n",
    "    RNN,     MEDIAN:  01\n",
    "    RNN,     MAX:     02\n",
    "    RNN,     MIN:     03\n",
    "    LSTM,    MEDIAN:  04\n",
    "    LSTM,    MAX:     05\n",
    "    LSTM,    MIN:     06\n",
    "    GRU,     MEDIAN:  07\n",
    "    GRU,     MAX:     08\n",
    "    GRU,     MIN:     09\n",
    "\"\"\"\n",
    "\n",
    "for i, row in result_matrix_models.iterrows():\n",
    "    if row['ID'].split('_')[2] in normal_model_numbers:\n",
    "        normal_rows.append(row.values)\n",
    "    elif row['ID'].split('_')[2] in scaled_model_numbers:\n",
    "        scaled_rows.append(row.values)\n",
    "\n",
    "# Add extracted rows to final matrices\n",
    "result_matrix_models_normal = (pd.DataFrame(normal_rows, columns=result_matrix_models.columns)).reset_index(drop=True)\n",
    "result_matrix_models_scaled = (pd.DataFrame(scaled_rows, columns=result_matrix_models.columns)).reset_index(drop=True)\n",
    "\n",
    "# Show complemented result matrices per parameter\n",
    "display(result_matrix_models_normal[result_matrix_models_normal['PARAMETER'] == 'HR'])\n",
    "display(result_matrix_models_scaled[result_matrix_models_scaled['PARAMETER'] == 'HR'])\n",
    "\n",
    "display(result_matrix_models_normal[result_matrix_models_normal['PARAMETER'] == 'BP'])\n",
    "display(result_matrix_models_scaled[result_matrix_models_scaled['PARAMETER'] == 'BP'])\n",
    "\n",
    "display(result_matrix_models_normal[result_matrix_models_normal['PARAMETER'] == 'O2'])\n",
    "display(result_matrix_models_scaled[result_matrix_models_scaled['PARAMETER'] == 'O2'])\n",
    "\n",
    "# Save result matrices as parquet\n",
    "result_matrix_models_normal.to_parquet(f'../../data/darts/{n_chunks}_chunks/result_matrix_models_normal.parquet',\n",
    "                                       engine='pyarrow')\n",
    "result_matrix_models_scaled.to_parquet(f'../../data/darts/{n_chunks}_chunks/result_matrix_models_scaled.parquet',\n",
    "                                       engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Accuracy, TPR, FNR, and TNR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# \"Group\" result matrix by prefix of ID\n",
    "plotdata = result_matrix_models.replace(['_H', '_L'], ['', ''], regex=True)\n",
    "\n",
    "# Create subplots\n",
    "sns.set_style('whitegrid')\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=4,\n",
    "    ncols=3,\n",
    "    figsize=(15, 13),\n",
    "    dpi=72\n",
    "    )\n",
    "\n",
    "plt.suptitle(f'Accuracy, TPR, FNR, and TNR of {n_chunks} Chunks', fontsize=22)\n",
    "\n",
    "# Define y-limits\n",
    "acc_ylimits = [0, max(result_matrix_models.ACC)]\n",
    "tpr_ylimits = [0, max(result_matrix_models.TPR)]\n",
    "fnr_ylimits = [0, max(result_matrix_models.FNR)]\n",
    "tnr_ylimits = [0, max(result_matrix_models.TNR)]\n",
    "\n",
    "# Actual plots\n",
    "for i, parameter in enumerate(['HR', 'BP', 'O2']):\n",
    "    sns.barplot(\n",
    "        ax=axs[0, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='ACC',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axs[0, i].set_title(str(parameter), fontweight='bold', color= 'black', fontsize=20)\n",
    "    axs[0, i].set_ylim(acc_ylimits)\n",
    "    axs[0, i].set_xticklabels(axs[0, i].get_xticklabels(), rotation=90)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axs[1, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='TPR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axs[1, i].set_ylim(tpr_ylimits)\n",
    "    axs[1, i].set_xticklabels(axs[1, i].get_xticklabels(), rotation=90)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axs[2, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='FNR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axs[2, i].set_ylim(fnr_ylimits)\n",
    "    axs[2, i].set_xticklabels(axs[2, i].get_xticklabels(), rotation=90)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax = axs[3, i],\n",
    "        data = plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='TNR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axs[3, i].set_ylim(tnr_ylimits)\n",
    "    axs[3, i].set_xticklabels(axs[3, i].get_xticklabels(), rotation=90)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show(fig)\n",
    "#fig.savefig(f'../../plots/darts/{n_chunks}_chunks/tpr_fnr_tnr_acc_model_result_matrix.png', dpi=1200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot False Positive Ratio and F1 Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# \"Group\" result matrix by prefix of ID\n",
    "plotdata = result_matrix_models.replace(['_H', '_L'], ['', ''], regex=True)\n",
    "\n",
    "# Create subplots\n",
    "sns.set_style('whitegrid')\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=3,\n",
    "    figsize=(15, 7),\n",
    "    dpi=72\n",
    "    )\n",
    "\n",
    "plt.suptitle(f'FPR and F1S of {n_chunks} Chunks', fontsize=22)\n",
    "\n",
    "# Define y-limits\n",
    "fpr_ylimits = [0, max(result_matrix_models.FPR)]\n",
    "f1s_ylimits = [0, max(result_matrix_models.F1S)]\n",
    "\n",
    "# Actual plot\n",
    "for i, parameter in enumerate(['HR', 'BP', 'O2']):\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axs[0, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='FPR',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axs[0, i].set_title(str(parameter), fontweight='bold', color= 'black', fontsize=14)\n",
    "    axs[0, i].set_ylim(fpr_ylimits)\n",
    "    axs[0, i].set_xticklabels(axs[0, i].get_xticklabels(), rotation=90)\n",
    "\n",
    "    sns.barplot(\n",
    "        ax=axs[1, i],\n",
    "        data=plotdata[plotdata.PARAMETER == parameter],\n",
    "        x='ID',\n",
    "        y='F1S',\n",
    "        hue='ALARM_TYPE',\n",
    "        palette=sns.color_palette('colorblind'),\n",
    "        ci=None)\n",
    "    axs[1, i].set_ylim(f1s_ylimits)\n",
    "    axs[1, i].set_xticklabels(axs[1, i].get_xticklabels(), rotation=90)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show(fig)\n",
    "#fig.savefig(f'../../plots/darts/{n_chunks}_chunks/fpr_f1s_model_result_matrix.png', dpi=1200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis of Chunk-level Matrices\n",
    "\n",
    "### Print One Chunk-level Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "\n",
    "# Define parameters to adjust\n",
    "# Note: At the moment, the following analysis steps are only performed for one chunk-specific matrix file\n",
    "n_chunks = 1000\n",
    "model_type = 'LSTM'\n",
    "parameter = 'o2'\n",
    "endogenous_input = 'MEDIAN'\n",
    "version = 'normal'\n",
    "window_idx = 0\n",
    "\n",
    "# Define path to all chunk-level matrices produced by prediction\n",
    "path_to_chunk_matrices = f'../../data/darts/{n_chunks}_chunks'\n",
    "\n",
    "# Read chunk-specific matrix\n",
    "chunks_matrix_f = open(f'{path_to_chunk_matrices}/confusion_matrix_chunks_{model_type}_{parameter}_{endogenous_input}_'\n",
    "                       f'{version}_window{window_idx}.pickle', 'rb')\n",
    "chunks_matrix = pickle.load(chunks_matrix_f)\n",
    "chunks_matrix_f.close()\n",
    "\n",
    "# Show chunk-specific matrix\n",
    "display(chunks_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add Metrics (and Other Remaining Columns) to Each Chunk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Note: To avoid dividing by zero, zeros are converted to NaN before division (since any value divided by NaN gives NaN)\n",
    "\n",
    "chunks_matrix['fp_tn_divisor'] = chunks_matrix['FP'] + chunks_matrix['TN']\n",
    "chunks_matrix['TNR'] = chunks_matrix.TN.div(chunks_matrix.fp_tn_divisor.where(chunks_matrix.fp_tn_divisor != 0, np.nan))\n",
    "chunks_matrix['FPR'] = chunks_matrix.FP.div(chunks_matrix.fp_tn_divisor.where(chunks_matrix.fp_tn_divisor != 0, np.nan)) # 1 - TNR\n",
    "\n",
    "chunks_matrix['fn_tp_divisor'] = chunks_matrix['FN'] + chunks_matrix['TP']\n",
    "chunks_matrix['TPR'] = chunks_matrix.TP.div(chunks_matrix.fn_tp_divisor.where(chunks_matrix.fn_tp_divisor != 0, np.nan))\n",
    "chunks_matrix['FNR'] = chunks_matrix.FN.div(chunks_matrix.fn_tp_divisor.where(chunks_matrix.fn_tp_divisor != 0, np.nan)) # 1 - TPR\n",
    "\n",
    "chunks_matrix['F1S_divisor'] = chunks_matrix['TP'] + 0.5 * (chunks_matrix['FP'] + chunks_matrix['FN'])\n",
    "chunks_matrix['F1S'] = chunks_matrix.TP.div(chunks_matrix.F1S_divisor.where(chunks_matrix.F1S_divisor != 0, np.nan))\n",
    "\n",
    "chunks_matrix['ACC_dividend'] = chunks_matrix['TN'] + chunks_matrix['TP']\n",
    "chunks_matrix['ACC_divisor'] = chunks_matrix['fp_tn_divisor'] + chunks_matrix['fn_tp_divisor']\n",
    "chunks_matrix['ACC'] = chunks_matrix.ACC_dividend.div(chunks_matrix.ACC_divisor.where(chunks_matrix.ACC_divisor != 0,\n",
    "                                                                                      np.nan))\n",
    "\n",
    "# Round all floats to 4 decimal places\n",
    "# Note: round() does not work for floats with many decimal places\n",
    "decimals = 4\n",
    "for col in ['FPR', 'TPR', 'FNR', 'TNR', 'ACC', 'F1S']:\n",
    "    chunks_matrix[col] = chunks_matrix[col].apply(lambda x: round(x, decimals))\n",
    "\n",
    "# Sort and remove helper columns for similarity with model-level matrices\n",
    "chunks_matrix = chunks_matrix[['CHUNK_ID', 'PARAMETER', 'MODEL', 'ENDOGENOUS', 'EXOGENOUS', 'FIRST_FORECAST',\n",
    "                               'ALARM_TYPE', 'FP', 'TP', 'FN', 'TN', 'FPR', 'TPR', 'FNR', 'TNR', 'ACC', 'F1S',\n",
    "                               'N_HIGH_ALARMS', 'N_LOW_ALARMS', 'N_ITERATIONS']]\n",
    "\n",
    "# Show complemented chunk-level matrix for one chunk\n",
    "display(chunks_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Correlation Between Chunk Length and F1 Score/ Specificity (TNR) of Chunk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define input length to adjust\n",
    "input_length = 12\n",
    "\n",
    "# Add column for chunk length to all chunks of matrix\n",
    "chunks_matrix['LENGTH'] = chunks_matrix['N_ITERATIONS'] + input_length\n",
    "\n",
    "for metric in ['F1S', 'TNR']:\n",
    "\n",
    "    # Define background color, subplots and suptitle\n",
    "    sns.set_style('whitegrid')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    fig.suptitle(f'Correlation of Chunk Length and {metric} of Chunk', fontsize=14)\n",
    "\n",
    "    if endogenous_input == 'MIN':\n",
    "        ax1.set_visible(False)\n",
    "        ax2.set_position([1, 0.2, 0.05, 0.2])\n",
    "    else:\n",
    "        # Extract chunks for high and low analysis plot\n",
    "        high_chunks = chunks_matrix[chunks_matrix['ALARM_TYPE'] == 'High'][[metric, 'LENGTH']]\n",
    "\n",
    "        # Introduce mean value for each length\n",
    "        # Note: If mean value of metric is used, lines can be drawn again (with default of linestyle parameter)\n",
    "        #high_chunks = high_chunks.astype(float)\n",
    "        #high_chunks = high_chunks.groupby('LENGTH').mean()\n",
    "\n",
    "        # Reset indices to make access via column names possible again\n",
    "        high_chunks.reset_index(level=0, inplace=True, drop=True)\n",
    "\n",
    "        # Add left plot (high threshold analysis)\n",
    "        ax1.plot('LENGTH', metric, data=high_chunks, marker='o', color=sns.color_palette('colorblind')[0],\n",
    "                 linestyle='None')\n",
    "        ax1.set_title(f'{metric} Regarding High Thresholds', fontsize=10)\n",
    "        ax1.set_xlabel('Chunk Length', fontsize=8)\n",
    "        ax1.set_ylabel(f'{metric} of Chunk', fontsize=8)\n",
    "        ax1.set_ylim(bottom=0, top=1.1)\n",
    "\n",
    "    if endogenous_input == 'MAX':\n",
    "        ax2.set_visible(False)\n",
    "        ax1.set_position([0, 0.2, 0.05, 0.2])\n",
    "    else:\n",
    "        # Extract chunks for high and low analysis plot\n",
    "        low_chunks = chunks_matrix[chunks_matrix['ALARM_TYPE'] == 'Low'][[metric, 'LENGTH']]\n",
    "\n",
    "        # Introduce mean value for each length\n",
    "        # Note: If mean value of metric is used, lines can be drawn again (with default of linestyle parameter)\n",
    "        #low_chunks = vlow_chunks.astype(float)\n",
    "        #low_chunks = low_chunks.groupby('LENGTH').mean()\n",
    "\n",
    "        # Reset indices to make access via column names possible again\n",
    "        low_chunks.reset_index(level=0, inplace=True, drop=True)\n",
    "\n",
    "        # Add right plot (low threshold analysis)\n",
    "        ax2.plot('LENGTH', metric, data=low_chunks, marker='o', color=sns.color_palette('colorblind')[1],\n",
    "                 linestyle='None')\n",
    "        ax2.set_title(f'{metric} Regarding Low Thresholds', fontsize=10)\n",
    "        ax2.set_xlabel('Chunk Length', fontsize=8)\n",
    "        ax2.set_ylabel(f'{metric} of Chunk', fontsize=8)\n",
    "        ax2.set_ylim(bottom=0, top=1.1)\n",
    "\n",
    "    # Improve layout and save figure\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    #fig.savefig(f'../../plots/darts/{n_chunks}_chunks/correlation_chunk_length_and_{metric}_{model_type}_{parameter}_'\n",
    "    #            f'{endogenous_input}_{version}.png', dpi=1200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Time-Series Plot of Chunk with Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Original amount of chunks: {len(chunks_matrix)}\\n')\n",
    "\n",
    "interesting_chunks = chunks_matrix[chunks_matrix.FPR.notnull() & chunks_matrix.F1S.notnull()]\n",
    "print(f'Amount of interesting chunks: {len(interesting_chunks)}\\n')\n",
    "\n",
    "print(interesting_chunks[['CHUNK_ID', 'FPR', 'TPR', 'FNR', 'TNR', 'ACC', 'F1S', 'N_HIGH_ALARMS', 'N_LOW_ALARMS']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "import pandas as pd\n",
    "\n",
    "chunks_ids_plotting = ['200098.0_220277.0_2136-03-27 12:00:00', '200061.0_220277.0_2134-01-24 14:15:00']\n",
    "\n",
    "for chunk_id in chunks_ids_plotting:\n",
    "\n",
    "    # Format chunk IDs into Windows format that have to be used when loading from or saving to Windows machine\n",
    "    chunk_id_win10 = chunk_id.replace(':', '%3A')\n",
    "\n",
    "    # Extract predicted series of chunk\n",
    "    prediction_chunk_f = open(f'../../data/darts/{n_chunks}_chunks/{model_type}/{parameter}/{endogenous_input}/'\n",
    "                              f'05_prediction_{chunk_id_win10}_{version}_window{window_idx}.pickle', 'rb')\n",
    "    prediction_chunk = pickle.load(prediction_chunk_f)\n",
    "    prediction_chunk_f.close()\n",
    "\n",
    "    # Convert predicted series of chunk to TimeSeries object\n",
    "    prediction_chunk = TimeSeries.from_dataframe(\n",
    "        df=prediction_chunk,\n",
    "        time_col='Time',\n",
    "        value_cols=['Value'],\n",
    "        freq='H')\n",
    "\n",
    "    # Extract original series of chunk\n",
    "    resampled_chunks = pd.read_parquet(f'../../data/resampling/resample_output_{parameter}_first{n_chunks}.parquet',\n",
    "                                       engine='pyarrow')\n",
    "    original_chunk = resampled_chunks[resampled_chunks['CHUNK_ID_FILLED_TH'] == chunk_id]\n",
    "\n",
    "    # Convert original series of chunk to TimeSeries object\n",
    "    original_chunk = TimeSeries.from_dataframe(\n",
    "        df=original_chunk,\n",
    "        time_col='CHARTTIME',\n",
    "        value_cols=[f'VITAL_PARAMTER_VALUE_{endogenous_input}_RESAMPLING'],\n",
    "        freq='H')\n",
    "\n",
    "    # Actual plot\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    original_chunk.plot(label=f'{parameter.upper()} - actual')\n",
    "    prediction_chunk.plot(label=f'{parameter.upper()} - predicted')\n",
    "\n",
    "    # Adjust texts of plot\n",
    "    plt.legend()\n",
    "    plt.suptitle(f'Prediction of {parameter.upper()} with {n_chunks} Chunks, {endogenous_input} Input, and {model_type}'\n",
    "                 f' Model', fontweight='bold')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "\n",
    "    plt.show()\n",
    "    #plt.savefig(f'../../plots/darts/{n_chunks}_chunks/prediction_{model_type}_{parameter}_{endogenous_input}_'\n",
    "    #            f'{chunk_id_win10}_{version}.png', dpi=1200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}