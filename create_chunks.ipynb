{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0c24247fa39158f46a54dbb99bb8811b81cd84bf3c9aa6e8294d53a41a5837da9",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Perform Chunking\n",
    "Based on the visual analysis, we derived two possible chunking options:\n",
    "* Chunk after 60 min difference to previous timestamp\n",
    "* Chunk after 120 min difference to previous timestamp\n",
    "\n",
    "After the discussion with the teaching team, we decided to **chunk after 65 min difference to the previous timestamp** with the possibility to adapt that in future"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Add Timestamp of previous measurement and difference between timestamps to dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "chartevents_subset = pd.read_parquet('./data/chartevents_subset.parquet', engine='pyarrow')\n",
    "unique_icu_stays = pd.read_parquet('./data/unique_icustays_in_chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select ICU_stay ids for analysis\n",
    "icustayid_filter = unique_icu_stays.ICUSTAY_ID\n",
    "\n",
    "# Filter by ICU_stay\n",
    "chunk_analysis_data = chartevents_subset[chartevents_subset.ICUSTAY_ID.isin(icustayid_filter)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling Rate Analysis is only being conducted on the values, not thresholds\n",
    "# Filter for item ids that refer to value\n",
    "itemids_for_values_filter = [220045, 220179, 220277]\n",
    "chunk_analysis_data = chunk_analysis_data[chunk_analysis_data.ITEMID.isin(itemids_for_values_filter)].copy()\n",
    "len(chunk_analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: Keep chunk_analysis_data as is, only add a new column that holds the previous timestamp, the difference can then be performed outside the loop\n",
    "# Prerequisite: Sorted Data by ICUSTAY_ID,ITEMID,CHARTTIME\n",
    "chunk_analysis_data['CHARTTIME_PREV'] = chunk_analysis_data.groupby(['ICUSTAY_ID','ITEMID'])['CHARTTIME'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference between timestamps\n",
    "chunk_analysis_data['DIF_CHARTTIME_PREV'] = chunk_analysis_data['CHARTTIME']-chunk_analysis_data['CHARTTIME_PREV']\n",
    "chunk_analysis_data['DIF_CHARTTIME_PREV_S'] = chunk_analysis_data['DIF_CHARTTIME_PREV'].dt.total_seconds()\n",
    "chunk_analysis_data['DIF_CHARTTIME_PREV_MIN'] = divmod(chunk_analysis_data['DIF_CHARTTIME_PREV_S'], 60)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_analysis_data.head()"
   ]
  },
  {
   "source": [
    "## Apply Chunking Rule\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "#chunk_analysis_data = pd.read_parquet('./data/chunk_analysis_data.parquet', engine='pyarrow')\n",
    "chunking_dif = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce data to relevant columns to make validation easier\n",
    "#chunk_analysis_data = chunk_analysis_data[['ICUSTAY_ID','ITEMID','CHARTTIME','VALUENUM','VALUEUOM','CHARTTIME_PREV','DIF_CHARTTIME_PREV_MIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all rows where dif to prev measurement is >chunking dif\n",
    "chunk_data = chunk_analysis_data[chunk_analysis_data[\"DIF_CHARTTIME_PREV_MIN\"] > chunking_dif]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a unique chunking ID to these rows\n",
    "chunk_data[\"CHUNK_ID\"] = chunk_data.ICUSTAY_ID.map(str) + \"_\" + chunk_data.ITEMID.map(str) + \"_\" + chunk_data.CHARTTIME.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check uniqueness - can only be violated if multiple measurements for that itemid/icustayid occured at the same charttime\n",
    "print(len(chunk_data[\"CHUNK_ID\"].value_counts()))\n",
    "print(len(chunk_data))\n",
    "# uiqueness for this data set is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep chunkid and index\n",
    "chunk_data_subset = chunk_data[\"CHUNK_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge back to all rows via index\n",
    "#no we have a data set that has a chunk_id at the beginning of each measurement that was conducted later than the chunking rule allows\n",
    "chunk_data_merged = pd.merge(chunk_analysis_data, chunk_data_subset,  how='left', left_index=True, right_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change sorting structure -  turn ITEMID and CHARTTIME around\n",
    "chunk_data_merged = chunk_data_merged.sort_values(by=['ICUSTAY_ID', 'ITEMID','CHARTTIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Chunk ID to first measurement of   ICUSTAY_ID/TEMID in case it does not already exist\n",
    "# Calculate min timestamp\n",
    "chunk_data_min = chunk_data_merged.groupby(['ICUSTAY_ID','ITEMID'])['CHARTTIME'].min()\n",
    "chunk_data_min_df = chunk_data_min.to_frame()\n",
    "chunk_data_min_df.reset_index(inplace=True)\n",
    "\n",
    "# for each first charttime (by ICUSTAYID/ITEEMID) create a chunk ID\n",
    "chunk_data_min_df[\"CHUNK_ID_MIN\"] = chunk_data_min_df.ICUSTAY_ID.map(str) + \"_\" + chunk_data_min_df.ITEMID.map(str) + \"_\" + chunk_data_min_df.CHARTTIME.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge that back so we have a chunk id for each first Measurement (by ICUSTAYID/TEMID)\n",
    "chunk_data_merged_2 = pd.merge(chunk_data_merged, chunk_data_min_df,  how='left', on=['ICUSTAY_ID','ITEMID','CHARTTIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# if chunkIdMin not Nan,write chunk_id_min in chunk_id\n",
    "# #no we have a data set that has a chunk_id at the beginning of each measurement that was conducted later than the chunking rule allows as well as an initial chunk id\n",
    "chunk_data_merged_2['CHUNK_ID'] = np.where(chunk_data_merged_2['CHUNK_ID_MIN'].notnull(), chunk_data_merged_2['CHUNK_ID_MIN'], chunk_data_merged_2['CHUNK_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data_merged_2 = chunk_data_merged_2.drop(columns='CHUNK_ID_MIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all cells with previous chunk id, until new chunk idea occurs\n",
    "#pre-requisite: data is sorted by ICUSTAY_ID & ITEMID\n",
    "chunk_data_merged_2['CHUNK_ID_FILLED'] = chunk_data_merged_2['CHUNK_ID'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns that are obsolete now - only kept for validation purpose in previous steps\n",
    "chunk_data_merged_2 = chunk_data_merged_2.drop(columns='CHUNK_ID')\n",
    "chunk_data_merged_2.rename(columns={\"CHUNK_ID_FILLED\":\"CHUNK_ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as parquet file\n",
    "\n",
    "pd.DataFrame(chunk_data_merged_2).to_parquet('./data/chartevent_subset_values_with_chunkid_' + str(chunking_dif) + '.parquet', engine='pyarrow')"
   ]
  }
 ]
}