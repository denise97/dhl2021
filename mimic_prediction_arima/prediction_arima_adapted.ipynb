{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0c24247fa39158f46a54dbb99bb8811b81cd84bf3c9aa6e8294d53a41a5837da9",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ARIMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data Preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "chartevents_subset = pd.read_parquet('./data/chartevents_clean_values_and_thresholds_with_chunkid_65_resampled.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETER = 220045\n",
    "CHUNKS = ['296490.0_220045.0_2192-09-26 23:51:00']\n",
    "\n",
    "# Sampling rate of 1 data point per hour - Test for different values in the future - e.g. longer training set\n",
    "TRAIN = 12 # 12 * 1 h = 12 hour training period\n",
    "TEST = 2 # 2 * 1 h = 2 hours testing period\n",
    "STEP = 1 # move 1 * 1 h = 1 hour per step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                            CHUNK_ID_FILLED_TH           CHARTTIME    ITEMID  \\\n4918097  296490.0_220045.0_2192-09-26 23:51:00 2192-09-26 23:00:00  220045.0   \n4918098  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 00:00:00  220045.0   \n4918099  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 01:00:00  220045.0   \n4918100  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 02:00:00  220045.0   \n4918101  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 03:00:00  220045.0   \n...                                        ...                 ...       ...   \n4918829  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 11:00:00  220045.0   \n4918830  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 12:00:00  220045.0   \n4918831  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 13:00:00  220045.0   \n4918832  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 14:00:00  220045.0   \n4918833  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 15:00:00  220045.0   \n\n         VALUENUM_CLEAN  \n4918097            95.0  \n4918098            90.5  \n4918099            91.0  \n4918100            91.0  \n4918101            85.0  \n...                 ...  \n4918829            97.0  \n4918830            90.0  \n4918831            88.0  \n4918832            88.0  \n4918833            40.0  \n\n[737 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CHUNK_ID_FILLED_TH</th>\n      <th>CHARTTIME</th>\n      <th>ITEMID</th>\n      <th>VALUENUM_CLEAN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4918097</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-26 23:00:00</td>\n      <td>220045.0</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>4918098</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 00:00:00</td>\n      <td>220045.0</td>\n      <td>90.5</td>\n    </tr>\n    <tr>\n      <th>4918099</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 01:00:00</td>\n      <td>220045.0</td>\n      <td>91.0</td>\n    </tr>\n    <tr>\n      <th>4918100</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 02:00:00</td>\n      <td>220045.0</td>\n      <td>91.0</td>\n    </tr>\n    <tr>\n      <th>4918101</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 03:00:00</td>\n      <td>220045.0</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4918829</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 11:00:00</td>\n      <td>220045.0</td>\n      <td>97.0</td>\n    </tr>\n    <tr>\n      <th>4918830</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 12:00:00</td>\n      <td>220045.0</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>4918831</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 13:00:00</td>\n      <td>220045.0</td>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <th>4918832</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 14:00:00</td>\n      <td>220045.0</td>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <th>4918833</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 15:00:00</td>\n      <td>220045.0</td>\n      <td>40.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>737 rows × 4 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Subset data based on PARAMETER & CHUNKS\n",
    "arima_data = chartevents_subset[\n",
    "    (chartevents_subset[\"ITEMID\"] == PARAMETER) & \n",
    "    (chartevents_subset.CHUNK_ID_FILLED_TH.isin(CHUNKS))\n",
    "    ][['CHUNK_ID_FILLED_TH','CHARTTIME','ITEMID','VALUENUM_CLEAN']]\n",
    "display(arima_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                            CHUNK_ID_FILLED_TH           CHARTTIME    ITEMID  \\\n4918097  296490.0_220045.0_2192-09-26 23:51:00 2192-09-26 23:00:00  220045.0   \n4918098  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 00:00:00  220045.0   \n4918099  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 01:00:00  220045.0   \n4918100  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 02:00:00  220045.0   \n4918101  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 03:00:00  220045.0   \n...                                        ...                 ...       ...   \n4918829  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 11:00:00  220045.0   \n4918830  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 12:00:00  220045.0   \n4918831  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 13:00:00  220045.0   \n4918832  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 14:00:00  220045.0   \n4918833  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 15:00:00  220045.0   \n\n         VALUENUM_CLEAN  \n4918097            95.0  \n4918098            90.5  \n4918099            91.0  \n4918100            91.0  \n4918101            85.0  \n...                 ...  \n4918829            97.0  \n4918830            90.0  \n4918831            88.0  \n4918832            88.0  \n4918833            40.0  \n\n[737 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CHUNK_ID_FILLED_TH</th>\n      <th>CHARTTIME</th>\n      <th>ITEMID</th>\n      <th>VALUENUM_CLEAN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4918097</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-26 23:00:00</td>\n      <td>220045.0</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>4918098</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 00:00:00</td>\n      <td>220045.0</td>\n      <td>90.5</td>\n    </tr>\n    <tr>\n      <th>4918099</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 01:00:00</td>\n      <td>220045.0</td>\n      <td>91.0</td>\n    </tr>\n    <tr>\n      <th>4918100</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 02:00:00</td>\n      <td>220045.0</td>\n      <td>91.0</td>\n    </tr>\n    <tr>\n      <th>4918101</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 03:00:00</td>\n      <td>220045.0</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4918829</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 11:00:00</td>\n      <td>220045.0</td>\n      <td>97.0</td>\n    </tr>\n    <tr>\n      <th>4918830</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 12:00:00</td>\n      <td>220045.0</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>4918831</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 13:00:00</td>\n      <td>220045.0</td>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <th>4918832</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 14:00:00</td>\n      <td>220045.0</td>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <th>4918833</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 15:00:00</td>\n      <td>220045.0</td>\n      <td>40.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>737 rows × 4 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Filter for chunks that have sufficient values to be used for training and testing the model\n",
    "all_chunks_value_count = arima_data.CHUNK_ID_FILLED_TH.value_counts()\n",
    "chunkid_filter = all_chunks_value_count[all_chunks_value_count >= (TRAIN + TEST)].index\n",
    "arima_data = arima_data[arima_data.CHUNK_ID_FILLED_TH.isin(chunkid_filter)]\n",
    "display(arima_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                            CHUNK_ID_FILLED_TH           CHARTTIME    ITEMID  \\\n4918097  296490.0_220045.0_2192-09-26 23:51:00 2192-09-26 23:00:00  220045.0   \n4918098  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 00:00:00  220045.0   \n4918099  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 01:00:00  220045.0   \n4918100  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 02:00:00  220045.0   \n4918101  296490.0_220045.0_2192-09-26 23:51:00 2192-09-27 03:00:00  220045.0   \n...                                        ...                 ...       ...   \n4918829  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 11:00:00  220045.0   \n4918830  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 12:00:00  220045.0   \n4918831  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 13:00:00  220045.0   \n4918832  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 14:00:00  220045.0   \n4918833  296490.0_220045.0_2192-09-26 23:51:00 2192-10-27 15:00:00  220045.0   \n\n         VALUENUM_CLEAN  MINUTES_SINCE_FIRST_RECORD  \n4918097            95.0                         0.0  \n4918098            90.5                        60.0  \n4918099            91.0                       120.0  \n4918100            91.0                       180.0  \n4918101            85.0                       240.0  \n...                 ...                         ...  \n4918829            97.0                     43920.0  \n4918830            90.0                     43980.0  \n4918831            88.0                     44040.0  \n4918832            88.0                     44100.0  \n4918833            40.0                     44160.0  \n\n[737 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CHUNK_ID_FILLED_TH</th>\n      <th>CHARTTIME</th>\n      <th>ITEMID</th>\n      <th>VALUENUM_CLEAN</th>\n      <th>MINUTES_SINCE_FIRST_RECORD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4918097</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-26 23:00:00</td>\n      <td>220045.0</td>\n      <td>95.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4918098</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 00:00:00</td>\n      <td>220045.0</td>\n      <td>90.5</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>4918099</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 01:00:00</td>\n      <td>220045.0</td>\n      <td>91.0</td>\n      <td>120.0</td>\n    </tr>\n    <tr>\n      <th>4918100</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 02:00:00</td>\n      <td>220045.0</td>\n      <td>91.0</td>\n      <td>180.0</td>\n    </tr>\n    <tr>\n      <th>4918101</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-09-27 03:00:00</td>\n      <td>220045.0</td>\n      <td>85.0</td>\n      <td>240.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4918829</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 11:00:00</td>\n      <td>220045.0</td>\n      <td>97.0</td>\n      <td>43920.0</td>\n    </tr>\n    <tr>\n      <th>4918830</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 12:00:00</td>\n      <td>220045.0</td>\n      <td>90.0</td>\n      <td>43980.0</td>\n    </tr>\n    <tr>\n      <th>4918831</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 13:00:00</td>\n      <td>220045.0</td>\n      <td>88.0</td>\n      <td>44040.0</td>\n    </tr>\n    <tr>\n      <th>4918832</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 14:00:00</td>\n      <td>220045.0</td>\n      <td>88.0</td>\n      <td>44100.0</td>\n    </tr>\n    <tr>\n      <th>4918833</th>\n      <td>296490.0_220045.0_2192-09-26 23:51:00</td>\n      <td>2192-10-27 15:00:00</td>\n      <td>220045.0</td>\n      <td>40.0</td>\n      <td>44160.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>737 rows × 5 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Create new MINUTES_SINCE_FIRST_RECORD column containing the time difference that has passed since the first timestamp of the measurement series.\n",
    "import numpy as np\n",
    "#arima_data['MINUTES_SINCE_FIRST_RECORD'] = arima_data.groupby('CHUNK_ID_FILLED_TH')#['CHARTTIME'].transform(lambda x: (x - x.min())/np.timedelta64(1,'m'))\n",
    "# Alternative for hours instead of minutes\n",
    "arima_data['HOURS_SINCE_FIRST_RECORD'] = arima_data.groupby('CHUNK_ID_FILLED_TH')['CHARTTIME'].transform(lambda x: (x - x.min())/np.timedelta64(1,'h'))\n",
    "display(arima_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dataset to small amount in order to first test script\n",
    "# Now we have 15 measurements for that chunk; With a TRAIN of 12, a TEST of 2 and a STEP of 1 we expect to receive two training sets and two test sets - looking at row ids they would look like the following:\n",
    "# first train = 0:11 ; first test= 12:13\n",
    "# second train = 1:12 ; second test= 13:14\n",
    "arima_data = arima_data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "** Old Coding** - Change cell type to Code when needed\n",
    "### Change data structure\n",
    "### Create a list containing one element for each chunk, which are of type pandas series.\n",
    "### Each of these series includes the measured values of the chunk with the MINUTES_SINCE_FIRST_RECORD as index.\n",
    "### The data structure is transposed, so to speak, so that the MINUTES_SINCE_FIRST_RECORD that were previously in rows now serve as 'columns' (not literally; they are in the index of the series).\n",
    "\n",
    "### MINUTES_SINCE_FIRST_RECORD  |     0 |    60 |   120 | ...\n",
    "### ----------------------------------------------------- ...\n",
    "### firstChunk                  |  95.0 |  90.5 |  91.0 | ...\n",
    "### secondChunk                 | 110.5 | 108.0 | 110.0 | ...\n",
    "### ...\n",
    "\n",
    "### Set up list that will contain the chunk value series transformed as described above.\n",
    "list_of_chunk_value_series = []\n",
    "\n",
    "for chunkid in chunkid_filter:\n",
    "\n",
    "    chunk_value_series = arima_data[arima_data.CHUNK_ID_FILLED_TH == chunkid].copy()\n",
    "    chunk_value_series.set_index('MINUTES_SINCE_FIRST_RECORD', inplace=True)\n",
    "    chunk_value_series.sort_index(inplace=True)    \n",
    "    list_of_chunk_value_series.append(chunk_value_series['VALUENUM_CLEAN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Adaption for following cell:\n",
    "# Change list_of_chunk_value_series from List to Dictionary\n",
    "# The CHUNK_ID is used as key and in this step one key holds three series: the vital parameter series, the low threshold series and the high threshold series. They need the same \"sampling rate\" - so that the high threshold with index 0 is the high threshold that applies at the time of the vital parameter with index 0 \n",
    "\n",
    "# Vital parameter Series:\n",
    "# index                       |     0 |    1  |   2   | ...\n",
    "# ----------------------------------------------------- ...\n",
    "# firstChunk - Vital Parameter|  95.0 |  90.5 |  91.0 | ...\n",
    "\n",
    "# Threshold High Series:\n",
    "# index                       |     0 |    1  |   2   | ...\n",
    "# ----------------------------------------------------- ...\n",
    "# firstChunk - Th. High       |  120.0 |  120.0 |  110.0 | ...\n",
    "\n",
    "# Threshold Low Series:\n",
    "# index                       |     0 |    1  |   2   | ...\n",
    "# ----------------------------------------------------- ...\n",
    "# firstChunk - Th. High       |  70.0 |  70.0 |  60.0 | ..."
   ]
  },
  {
   "source": [
    "# Create a list containing one element for each chunk, which are of type pandas series.\n",
    "# Each of these series includes the measured values of the chunk.\n",
    "# The index can be used to regain the HOURS_SINCE_FIRST_RECORD information when the step sampling rate is known - As we know have 1 measureemnt per hour we can use the index to derive that info.\n",
    "# The data structure is transposed, so to speak, so that the index serves as 'column' (not literally; they are in the index of the series).\n",
    "\n",
    "# index                       |     0 |    1  |   2   | ...\n",
    "# ----------------------------------------------------- ...\n",
    "# firstChunk                  |  95.0 |  90.5 |  91.0 | ...\n",
    "# secondChunk                 | 110.5 | 108.0 | 110.0 | ...\n",
    "# ...\n",
    "\n",
    "# Set up list that will contain the chunk value series transformed as described above.\n",
    "list_of_chunk_value_series = []\n",
    "\n",
    "for chunkid in chunkid_filter:\n",
    "\n",
    "    chunk_value_data = arima_data[arima_data.CHUNK_ID_FILLED_TH == chunkid].copy()\n",
    "    chunk_value_series = chunk_value_data['VALUENUM_CLEAN']\n",
    "    chunk_value_series = chunk_value_series.reset_index(drop=True)    \n",
    "    list_of_chunk_value_series.append(chunk_value_series)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Adaption for following cell:\n",
    "# Change chunk_value_series_with_test_and_train from List to Dictionary\n",
    "# The CHUNK_ID is used as key and in this step one key holds two series: The train_list and the test_list. As long as the index in train and test list is kept, we can still refer to the difference to the first measurement (as long as sampling rate is one hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   SUB_CHUNK_ID                                         TRAIN_LIST  \\\n00           00  0     95.0\n1     90.5\n2     91.0\n3     91.0\n4 ...   \n01           01  1     90.5\n2     91.0\n3     91.0\n4     85.0\n5 ...   \n\n                                            TEST_LIST  \n00  12    75.0\n13    75.5\nName: VALUENUM_CLEAN, dt...  \n01  13    75.5\n14    74.0\nName: VALUENUM_CLEAN, dt...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SUB_CHUNK_ID</th>\n      <th>TRAIN_LIST</th>\n      <th>TEST_LIST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00</th>\n      <td>00</td>\n      <td>0     95.0\n1     90.5\n2     91.0\n3     91.0\n4 ...</td>\n      <td>12    75.0\n13    75.5\nName: VALUENUM_CLEAN, dt...</td>\n    </tr>\n    <tr>\n      <th>01</th>\n      <td>01</td>\n      <td>1     90.5\n2     91.0\n3     91.0\n4     85.0\n5 ...</td>\n      <td>13    75.5\n14    74.0\nName: VALUENUM_CLEAN, dt...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Create multiple test & train sets for each chunk to iteratively predict the next x measurements\n",
    "chunk_value_series_with_test_and_train = pd.DataFrame(columns=[\"SUB_CHUNK_ID\", \"TRAIN_LIST\",\"TEST_LIST\"])\n",
    "for i, chunk_value_series in enumerate(list_of_chunk_value_series):\n",
    "    for start in range(0, len(chunk_value_series) - (TRAIN + TEST)+1, STEP):\n",
    "\n",
    "        sub_chunk_id = str(i)+str(start)\n",
    "        train_list = chunk_value_series[start : start+TRAIN]\n",
    "        test_list = chunk_value_series[start+TRAIN : start+TRAIN+TEST]\n",
    "        a_new_row= {\"SUB_CHUNK_ID\":sub_chunk_id,\"TRAIN_LIST\":train_list,\"TEST_LIST\":test_list}\n",
    "        a_new_row_series = pd.Series(a_new_row, name=sub_chunk_id)\n",
    "        chunk_value_series_with_test_and_train = chunk_value_series_with_test_and_train.append(a_new_row_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Adaption for following cell:\n",
    "# Currently we only have a true values list and a predictions list. But we are not interested in whether the prediction is exactly the true value. We want to see if the prediction value also triggers an alarm if the true value does. Therefore we need the threshold values that apply at the time of the respective prediction/true value.\n",
    "# A Final version should hold the following informations that can be traced back to a specific Chunk ID:\n",
    "# * List of true values (vital parameters in test list)\n",
    "# * List of Threshold High (for the time at which the predictions take place)\n",
    "# * List of Threshold Low (for the time at which the predictions take place)\n",
    "# * Arima Predictions (the predictions for the true values based on the train values)\n",
    "\n",
    "# Our thoughts:\n",
    "# Currently prediction looks as follows (two colums as TRAIN is 2; two rows as two chunk_value_series are created for our chunk (containing 15 values)):\n",
    "\n",
    "#   | 0                                         | 1\n",
    "# 0 | first prediction for chunk_value_series 1 | second prediction for chunk_value_series 1\n",
    "# 1 | first prediction for chunk_value_series 2 | second prediction for chunk_value_series 2\n",
    "\n",
    "# We wanted to add the last index of the train_list and the CHUNK_ID in a nested way to these predictions so that we can trace them back to the thresholds that apply at the time of the prediction\n",
    "\n",
    "#   | CHUNK_ID | Time ref. | 0                                 | 1\n",
    "# 0 |  xxxx    | 11        | 1st pred. for chunk_value_series 1| 2nd pred. for chunk_value_series 1 \n",
    "# 1 |  xxxx    | 12        | 1st pred. for chunk_value_series 2| 2nd pred. for chunk_value_series 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct Arima\n",
    "from progressbar import progressbar\n",
    "import pmdarima as pm\n",
    "\n",
    "true_values = []\n",
    "prediction = []\n",
    "all_sub_chunk_ids = chunk_value_series_with_test_and_train.SUB_CHUNK_ID.value_counts()\n",
    "\n",
    "for i, sub_chunk_id in enumerate(all_sub_chunk_ids):\n",
    "    arima = pm.auto_arima(chunk_value_series_with_test_and_train['TRAIN_LIST'][i])\n",
    "    forecast = arima.predict(TEST)\n",
    "    \n",
    "    test_list = chunk_value_series_with_test_and_train[\"TEST_LIST\"][i]\n",
    "    test_list = test_list.reset_index(drop=True)\n",
    "    test_list = test_list.to_numpy()\n",
    "\n",
    "    true_values.append(test_list)\n",
    "    prediction.append(forecast)"
   ]
  },
  {
   "source": [
    "Arima from previous version:\n",
    "auto_arima_model = auto_arima(data, start_p=1, start_q=1,\n",
    "                            max_p=3, max_q=3, m=1,\n",
    "                            start_P=0, seasonal=False,\n",
    "                            d=1, D=1, trace=True,\n",
    "                            error_action='ignore',  \n",
    "                            suppress_warnings=True, \n",
    "                            stepwise=True)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}