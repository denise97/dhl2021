{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of one example chunk that throws a value error\r\n",
    "\r\n",
    "The chunk with the id: '201358.0_220045.0_2151-11-05 15:52:00' throws a value error for iteration with id 28 in the arima configuration (train size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dict that holds this chunk with all preprocessed iterations\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import pmdarima as pm\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "import pyarrow as pa\r\n",
    "import pickle\r\n",
    "\r\n",
    "path_to_data = '../data/'\r\n",
    "\r\n",
    "starttime = time.time()\r\n",
    "print('Start reading the input file.')\r\n",
    "\r\n",
    "TRAIN=12\r\n",
    "input_file = open(str(path_to_data) + 'dict_of_chunk_steady_train_12_error_chunk_example.pickle', 'rb')\r\n",
    "dict_of_chunk_series_with_test_and_train_error = pickle.load(input_file)\r\n",
    "input_file.close()\r\n",
    "\r\n",
    "endtime = round(((time.time() - starttime) / 60), 5)\r\n",
    "print('Reading of the input file completed after '+str(endtime)+' minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of retrieving all iterations of this chunk:\r\n",
    "dict_of_chunk_series_with_test_and_train_error['201358.0_220045.0_2151-11-05 15:52:00'].keys()\r\n",
    "# As the train size = 12, the first iteration key is 11 (we choose the last index of the train set as dictionary key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of accessing one iteration of this chunk\r\n",
    "dict_of_chunk_series_with_test_and_train_error['201358.0_220045.0_2151-11-05 15:52:00'][11]\r\n",
    "# we retrieve all Train and Tests lists for all available resampling methods (Median,Mean,Min,Max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform ARIMA for all iterations of this chunk\r\n",
    "\r\n",
    "Will run into Value Error in iteration 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import pmdarima as pm\r\n",
    "import numpy as np\r\n",
    "import copy\r\n",
    "import time\r\n",
    "import warnings\r\n",
    "\r\n",
    "TRAIN = 12\r\n",
    "starttime = time.time()\r\n",
    "\r\n",
    "# Expand the previously created dictionary (dict_of_chunk_series_with_test_and_train) to also hold the prediction series next to the train and the test series (and threshold values for test)\r\n",
    "\r\n",
    "runningtime = round(((time.time() - starttime) / 60), 5)\r\n",
    "print('Starting setting up dictionaries. Running time '+str(runningtime)+' min.')\r\n",
    "\r\n",
    "dict_of_chunk_series_with_test_and_train_and_forecast = copy.deepcopy(dict_of_chunk_series_with_test_and_train_error)\r\n",
    "dict_of_chunk_series_with_forecast_df = {}\r\n",
    "accuracy_dict_for_chunk_iterations = {}\r\n",
    "chunk_iterations_with_value_error = pd.DataFrame(columns=[\"CHUNK_ID_FILLED_TH\",\"ITERATION\",\"ERROR_MSG\"])\r\n",
    "\r\n",
    "np.seterr(all='ignore')\r\n",
    "\r\n",
    "\r\n",
    "runningtime = round(((time.time() - starttime) / 60), 5)\r\n",
    "print('Completed setting up dictionaries. Running time '+str(runningtime)+' min.')\r\n",
    "\r\n",
    "for j, chunk in enumerate(dict_of_chunk_series_with_test_and_train_and_forecast):\r\n",
    "    dict_of_chunk_series_with_forecast_df[chunk] = {}\r\n",
    "    accuracy_dict_for_chunk_iterations[chunk] = {}\r\n",
    "\r\n",
    "    runningtime = round(((time.time() - starttime) / 60), 5)\r\n",
    "    print('CHUNK '+str(j)+': START. Running time '+str(runningtime)+' min.')\r\n",
    "    \r\n",
    "    for i, chunk_iteration in enumerate(dict_of_chunk_series_with_test_and_train_and_forecast[chunk]):\r\n",
    "        \r\n",
    "        TEST = dict_of_chunk_series_with_test_and_train_and_forecast[chunk][chunk_iteration][\"TEST_LIST_MEDIAN\"].size\r\n",
    "        tp, tn, fp, fn = 0, 0, 0, 0\r\n",
    "        accurracy_matrix_df_for_chunk_iteration = pd.DataFrame(columns=[\"TP\",\"FN\",\"FP\",\"TN\"])\r\n",
    "\r\n",
    "        ########################\r\n",
    "        # ARIMA\r\n",
    "        ########################\r\n",
    "\r\n",
    "        current_train_list = dict_of_chunk_series_with_test_and_train_and_forecast[chunk][chunk_iteration][\"TRAIN_LIST_MEDIAN\"] \r\n",
    "        current_test_list = dict_of_chunk_series_with_test_and_train_and_forecast[chunk][chunk_iteration][\"TEST_LIST_MEDIAN\"]\r\n",
    "        \r\n",
    "        try:\r\n",
    "            arima = pm.auto_arima(current_train_list, seasonal = False, error_action='ignore')\r\n",
    "            forecast_arima = pd.Series(arima.predict(TEST), index=[*range(i+TRAIN,i+TRAIN+TEST,1)], name=\"forecast_list_arima\")\r\n",
    "            dict_of_chunk_series_with_test_and_train_and_forecast[chunk][chunk_iteration][\"FORECAST_LIST_ARIMA\"] = forecast_arima\r\n",
    "            \r\n",
    "            runningtime = round(((time.time() - starttime) / 60), 5)\r\n",
    "            print('Chunk '+str(j)+' (ID: '+str(chunk)+') iteration '+str(chunk_iteration)+': Completed ARIMA. Running time '+str(runningtime)+' min.')\r\n",
    "\r\n",
    "            # extract threshold series \r\n",
    "            threshold_high_for_test_list = dict_of_chunk_series_with_test_and_train_and_forecast[chunk][chunk_iteration][\"THRESHOLD_HIGH_FOR_TEST_LIST\"]\r\n",
    "            threshold_low_for_test_list = dict_of_chunk_series_with_test_and_train_and_forecast[chunk][chunk_iteration][\"THRESHOLD_LOW_FOR_TEST_LIST\"]\r\n",
    "            \r\n",
    "            # write to dict_of_chunk_series_with_forecast_df dataframe\r\n",
    "            all_dict_lists_as_df = pd.concat([current_test_list,threshold_high_for_test_list,threshold_low_for_test_list,forecast_arima],axis=1)\r\n",
    "            dict_of_chunk_series_with_forecast_df[chunk][chunk_iteration] = all_dict_lists_as_df\r\n",
    "\r\n",
    "            ##############################################\r\n",
    "            # Add information whether alarm was triggered\r\n",
    "            ##############################################\r\n",
    "\r\n",
    "            df_for_chunk_iteration = dict_of_chunk_series_with_forecast_df[chunk][chunk_iteration]\r\n",
    "            \r\n",
    "            # True alarms\r\n",
    "            df_for_chunk_iteration['high_alarm_triggered'] = np.where(df_for_chunk_iteration['test_list_median'] > df_for_chunk_iteration['threshold_high_for_test_list'] ,1,0)\r\n",
    "            df_for_chunk_iteration['low_alarm_triggered'] = np.where(df_for_chunk_iteration['test_list_median'] < df_for_chunk_iteration['threshold_low_for_test_list'] ,1,0)\r\n",
    "                    \r\n",
    "            # ARIMA forecast\r\n",
    "            df_for_chunk_iteration['high_alarm_triggered_forecast_arima'] = np.where(df_for_chunk_iteration['forecast_list_arima'] > df_for_chunk_iteration['threshold_high_for_test_list'],1,0)\r\n",
    "            df_for_chunk_iteration['low_alarm_triggered_forecast_arima'] = np.where(df_for_chunk_iteration['forecast_list_arima'] < df_for_chunk_iteration['threshold_low_for_test_list'],1,0)\r\n",
    "            # write to dict_of_chunk_series_with_forecast_and_alarm_df dataframe\r\n",
    "            dict_of_chunk_series_with_forecast_df[chunk][chunk_iteration] = df_for_chunk_iteration\r\n",
    "            \r\n",
    "            runningtime = round(((time.time() - starttime) / 60), 5)\r\n",
    "            print('Chunk '+str(j)+' (ID: '+str(chunk)+') iteration '+str(chunk_iteration)+': Completed Alarm Identification. Running time '+str(runningtime)+' min.')\r\n",
    "\r\n",
    "            ##########################################\r\n",
    "            # Calculate Confusion Matrix - High Alarms\r\n",
    "            ##########################################\r\n",
    "\r\n",
    "            # select true high alarms triggered\r\n",
    "            column_index_of_high_alarm_triggered = df_for_chunk_iteration.columns.get_loc(\"high_alarm_triggered\")\r\n",
    "\r\n",
    "            # select predicted high alarms\r\n",
    "            column_index_of_high_alarm_triggered_forecast_arima = df_for_chunk_iteration.columns.get_loc(\"high_alarm_triggered_forecast_arima\")\r\n",
    "            \r\n",
    "            # create df with bot as column\r\n",
    "            high_alarms = df_for_chunk_iteration.iloc[0:,[column_index_of_high_alarm_triggered,column_index_of_high_alarm_triggered_forecast_arima]]\r\n",
    "            \r\n",
    "            for row_in_high_alarms in high_alarms.iterrows():\r\n",
    "\r\n",
    "                if row_in_high_alarms[1][0] and row_in_high_alarms[1][1]:\r\n",
    "                    tp +=1\r\n",
    "                    # print(\"tp\", tp)\r\n",
    "                if row_in_high_alarms[1][0] and not row_in_high_alarms[1][1]:\r\n",
    "                    fn +=1\r\n",
    "                    # print(\"fn\", fn)\r\n",
    "                if not row_in_high_alarms[1][0] and row_in_high_alarms[1][1]:\r\n",
    "                    fp +=1\r\n",
    "                    # print(\"fp\", fp)\r\n",
    "                if not row_in_high_alarms[1][0] and not row_in_high_alarms[1][1]:\r\n",
    "                    tn +=1\r\n",
    "                    # print(\"tn\",tn)\r\n",
    "            \r\n",
    "            a_new_row = {\"TP\":tp,\"FN\":fn,\"FP\":fp,\"TN\":tn}\r\n",
    "            a_new_row_series = pd.Series(a_new_row,name=\"accuracy_high_alarms_arima\")\r\n",
    "\r\n",
    "            accurracy_matrix_df_for_chunk_iteration = accurracy_matrix_df_for_chunk_iteration.append(a_new_row_series)\r\n",
    "\r\n",
    "            runningtime = round(((time.time() - starttime) / 60), 5)\r\n",
    "            print('Chunk '+str(j)+' (ID: '+str(chunk)+') iteration '+str(chunk_iteration)+': Completed Confusion Matrix - High Alarms. Running time '+str(runningtime)+' min.')\r\n",
    "\r\n",
    "            #########################################\r\n",
    "            # Calculate Confusion Matrix - Low Alarms\r\n",
    "            ##########################################\r\n",
    "\r\n",
    "            # Reset tp, tn, fp, fn\r\n",
    "            tp, tn, fp, fn = 0, 0, 0, 0\r\n",
    "\r\n",
    "            # select true low alarms triggered\r\n",
    "            column_index_of_low_alarm_triggered = df_for_chunk_iteration.columns.get_loc(\"low_alarm_triggered\")\r\n",
    "            \r\n",
    "            # select predicted low alarms\r\n",
    "            column_index_of_low_alarm_triggered_forecast_arima = df_for_chunk_iteration.columns.get_loc(\"low_alarm_triggered_forecast_arima\")\r\n",
    "            \r\n",
    "            # create df with bot as column \r\n",
    "            low_alarms = df_for_chunk_iteration.iloc[0:,[column_index_of_low_alarm_triggered,column_index_of_low_alarm_triggered_forecast_arima]]\r\n",
    "            \r\n",
    "            for row_in_low_alarms in low_alarms.iterrows():\r\n",
    "\r\n",
    "                if row_in_low_alarms[1][0] and row_in_low_alarms[1][1]:\r\n",
    "                    tp +=1\r\n",
    "                    # print(\"tp\", tp)\r\n",
    "                if row_in_low_alarms[1][0] and not row_in_low_alarms[1][1]:\r\n",
    "                    fn +=1\r\n",
    "                    # print(\"fn\", fn)\r\n",
    "                if not row_in_low_alarms[1][0] and row_in_low_alarms[1][1]:\r\n",
    "                    fp +=1\r\n",
    "                    # print(\"fp\", fp)\r\n",
    "                if not row_in_low_alarms[1][0] and not row_in_low_alarms[1][1]:\r\n",
    "                    tn +=1\r\n",
    "                    # print(\"tn\",tn)\r\n",
    "            \r\n",
    "            a_new_row = {\"TP\":tp,\"FN\":fn,\"FP\":fp,\"TN\":tn}\r\n",
    "            a_new_row_series = pd.Series(a_new_row,name=\"accuracy_low_alarms_arima\")\r\n",
    "            \r\n",
    "            accurracy_matrix_df_for_chunk_iteration = accurracy_matrix_df_for_chunk_iteration.append(a_new_row_series)\r\n",
    "\r\n",
    "            runningtime = round(((time.time() - starttime) / 60), 5)\r\n",
    "            print('Chunk '+str(j)+' (ID: '+str(chunk)+') iteration '+str(chunk_iteration)+': Completed Confusion Matrix - Low Alarms. Running time '+str(runningtime)+' min.')\r\n",
    "            \r\n",
    "            # Write confusion matrix into dictionary\r\n",
    "            accuracy_dict_for_chunk_iterations[chunk][chunk_iteration] = accurracy_matrix_df_for_chunk_iteration\r\n",
    "\r\n",
    "        except ValueError as ve:\r\n",
    "\r\n",
    "            ve_string = str(ve)\r\n",
    "            a_new_row = {\"CHUNK_ID_FILLED_TH\":chunk,\"ITERATION\":chunk_iteration,\"ERROR_MSG\":ve_string}\r\n",
    "            a_new_row_series = pd.Series(a_new_row)\r\n",
    "            chunk_iterations_with_value_error = chunk_iterations_with_value_error.append(a_new_row_series, ignore_index = True)\r\n",
    "            print(\"VALUE ERROR DETECTED\")\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    runningtime = round(((time.time() - starttime) / 60), 5)\r\n",
    "    print('Chunk '+str(j)+' (ID: '+str(chunk)+' ) : Completed chunk. Running time '+str(runningtime)+' min.')\r\n",
    "    print('--------------------')\r\n",
    "\r\n",
    "endtime = round(((time.time() - starttime) / 60), 5)\r\n",
    "print('DONE')\r\n",
    "print('Completed in '+str(endtime)+' minutes.')\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze iteration with value error independently\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract relevant train list\r\n",
    "train_list_iteration_28= dict_of_chunk_series_with_test_and_train_error['201358.0_220045.0_2151-11-05 15:52:00'][28][\"TRAIN_LIST_MEDIAN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform arima model fit\r\n",
    "arima_iteration_28 = pm.auto_arima(train_list_iteration_28, seasonal = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect arima model\r\n",
    "arima_iteration_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform prediction of the next step -> leads to ValueError in _assert_all_finite(X, allow_nan, msg_dtype)\r\n",
    "forecast_arima_iteration_28 = pd.Series(arima_iteration_28.predict(1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c24247fa39158f46a54dbb99bb8811b81cd84bf3c9aa6e8294d53a41a5837da9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}