{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd0e2bfb1b1dd0bcdebdb315279aa118b1f834444d4ba3ba6d660e9f6ce7703f6a2",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e2bfb1b1dd0bcdebdb315279aa118b1f834444d4ba3ba6d660e9f6ce7703f6a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Create clean CAHRTEVENTS data set\n",
    "\n",
    "1. Create chartevents_subset by filtering for relevant ITEMIDs\n",
    "2. Compute unique ICUSTAY_IDs in chartevents_subset\n",
    "3. Remove rows with insufficient measurements from chartevents_subset\n",
    "4. Mark parameter values outside clinically valid ranges\n",
    "5. Threshold cleaning\n",
    "  - Identify potential candidates for local threshold swap\n",
    "  - Prepare data set for local threshold swap\n",
    "  - Perform local threshold swap\n",
    "6. Combine cleaned values and thresholds to chartevents_clean"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Create chartevents_subset by filtering for relevant ITEMIDs\n",
    "\n",
    "* Create subset of MIMIC-III data set called `CHARTEVENTS.csv` (see also respective [MIMIC schema website](https://mit-lcp.github.io/mimic-schema-spy/tables/chartevents.html))\n",
    "* No change in columns, keep all of them.\n",
    "* Reduce number of rows by filtering for specific ITEMIDs and removing rows without ICUSTAY_ID"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import pyarrow as pa\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Read CHARTEVENTS.csv as Dask DataFrame\n",
    "# Data types based on MIMIC schema specification https://mit-lcp.github.io/mimic-schema-spy/tables/chartevents.html\n",
    "# Problem: Complicated use of intger data types with NaNs in Pandas, see https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#nan-integer-na-values-and-na-type-promotions\n",
    "# Decision: Floats and integers are read in as 'float64', strings as 'object', and timestamps via Dask's parse_dates provided for this purpose.\n",
    "chartevents = dd.read_csv('../mimic/CHARTEVENTS.csv', parse_dates=['CHARTTIME','STORETIME'], dtype={\n",
    "    'ROW_ID': 'float64', # int4 according to specification\n",
    "    'SUBJECT_ID': 'float64', # int4 according to specification\n",
    "    'HADM_ID': 'float64', # int4 according to specification\n",
    "    'ICUSTAY_ID': 'float64', # int4 according to specification\n",
    "    'ITEMID': 'float64', # int4 according to specification\n",
    "    'CGID': 'float64', # int4 according to specification\n",
    "    'VALUE': 'object',\n",
    "    'VALUENUM': 'float64', # float8 according to specification\n",
    "    'VALUEUOM': 'object',\n",
    "    'WARNING': 'float64', # int4 according to specification\n",
    "    'ERROR': 'float64', # int4 according to specification\n",
    "    'RESULTSTATUS': 'object',\n",
    "    'STOPPED': 'object'})\n",
    "\n",
    "# Create set of relevant ITEMIDs to filter by\n",
    "itemid_filter = [220045, 220046, 220047, 220179, 223751, 223752, 220180, 220277, 223769, 223770]\n",
    "# 220045 Heart Rate\n",
    "# 220046 Heart rate Alarm - High\n",
    "# 220047 Heart Rate Alarm - Low\n",
    "# 220179 Non Invasive Blood Pressure systolic\n",
    "# 223751 Non-Invasive Blood Pressure Alarm - High\n",
    "# 223752 Non-Invasive Blood Pressure Alarm - Low\n",
    "# 220180 Non Invasive Blood Pressure diastolic\n",
    "# 220277 O2 saturation pulseoxymetry\n",
    "# 223769 O2 Saturation Pulseoxymetry Alarm - High\n",
    "# 223770 O2 Saturation Pulseoxymetry Alarm - Low\n",
    "\n",
    "with ProgressBar():\n",
    "    # Filter by ITEMIDs\n",
    "    chartevents_subset = chartevents[chartevents.ITEMID.isin(itemid_filter)]\n",
    "    # Drop rows without ICUSTAY_ID (The ICUSTAY_ID is missing in 1811 rows, so these are removed.)\n",
    "    chartevents_subset = chartevents_subset.dropna(how='any', subset=['ICUSTAY_ID'])\n",
    "    # Keep only the rows for which no error occurred, which is coded by a 0. (5584 rows are dropped because the boolean ERROR column equals 1, indicating an error.)\n",
    "    chartevents_subset = chartevents_subset[chartevents_subset.ERROR.isin([0])]\n",
    "    # Apply the previously defined commands to the Dask DataFrame, resulting in the desired Pandas DataFrame.\n",
    "    chartevents_subset = chartevents_subset.compute()\n",
    "    # Computing duration on Marius' laptop (Intel i5-5200U CPU @ 2.20GHz): 21min\n",
    "\n",
    "# Sort the rows (not essential, but gives a better overview)\n",
    "chartevents_subset = chartevents_subset.sort_values(by=['ICUSTAY_ID', 'CHARTTIME','ITEMID'])\n",
    "\n",
    "# Rest index\n",
    "chartevents_subset = chartevents_subset.reset_index(drop=True)\n",
    "\n",
    "# Save as parquet file\n",
    "pd.DataFrame(chartevents_subset).to_parquet('../data/chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Compute unique ICUSTAY_IDs in chartevents_subset\n",
    "\n",
    "Create DataFrame that contains only the `ICUSTAY_ID` column, which contains all unique ICUSTAY_IDs contained in `chartevents_subset.parquet`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "chartevents_subset = pd.read_parquet('../data/chartevents_subset.parquet', engine='pyarrow')\n",
    "\n",
    "# Compute unqiue ICU stays in chartevents_subset \n",
    "unique_icustays_in_chartevents_subset = pd.Series(chartevents_subset.ICUSTAY_ID.unique()).rename('ICUSTAY_ID')\n",
    "\n",
    "# Save as parquet file (To do this, the Pandas Series must be converted to a Pandas DataFrame.)\n",
    "pd.DataFrame(unique_icustays_in_chartevents_subset).to_parquet('../data/unique_icustays_in_chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Remove rows with insufficient measurements from chartevents_subset\n",
    "\n",
    "Keep only those ICU stay/ parameter combinations for which more than one vital parameter measurement is available."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "chartevents_subset = pd.read_parquet('../data/chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider only those ITEMIDs for the analysis which refer to vital parameter values; threshold values are intentionally not included.\n",
    "itemids = [220045, 220179, 220180, 220277]\n",
    "# 220045 Heart Rate\n",
    "# 220179 Non Invasive Blood Pressure systolic\n",
    "# 220180 Non Invasive Blood Pressure diastolic\n",
    "# 220277 O2 saturation pulseoxymetry\n",
    "\n",
    "# Create subset of chartevents_subset for measurement analysis\n",
    "chartevents_subset_measurement_analysis = chartevents_subset[['ICUSTAY_ID','ITEMID','VALUENUM']].copy()\n",
    "chartevents_subset_measurement_analysis = chartevents_subset_measurement_analysis[chartevents_subset_measurement_analysis.ITEMID.isin(itemids)]\n",
    "\n",
    "# For each ICUSTAY_ID-ITEMID combination, compute the number of available values as VALUENUM_COUNT\n",
    "chartevents_subset_measurement_count = chartevents_subset_measurement_analysis.groupby(['ICUSTAY_ID','ITEMID']).count()\n",
    "chartevents_subset_measurement_count = chartevents_subset_measurement_count.rename(columns = {'VALUENUM':'VALUENUM_COUNT'})\n",
    "chartevents_subset_measurement_count = chartevents_subset_measurement_count.reset_index()\n",
    "display(chartevents_subset_measurement_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_subset_measurement_count as parquet file\n",
    "chartevents_subset_measurement_count.to_parquet('../data/chartevents_subset_measurement_count.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file\n",
    "chartevents_subset = pd.read_parquet('../data/chartevents_subset.parquet', engine='pyarrow')\n",
    "\n",
    "# Read chartevents_subset_measurement_count from parquet file\n",
    "chartevents_subset_measurement_count = pd.read_parquet('../data/chartevents_subset_measurement_count.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ICU stay/ parameter combinations for which more than one measurement is available\n",
    "multimeasurement_icustayid_itemid_value = chartevents_subset_measurement_count[chartevents_subset_measurement_count['VALUENUM_COUNT'] > 1][['ICUSTAY_ID','ITEMID']].reset_index(drop=True)\n",
    "\n",
    "display(multimeasurement_icustayid_itemid_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to keep not only the vital parameter values but also the associated threshold values, the value ITEMIDs must be supplemented by the ITEMIDs of the respective thresholds.\n",
    "# This step is solved in an unnecessarily complicated way. As of now, there is no time for optimization.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "multimeasurement_icustayid_itemids = multimeasurement_icustayid_itemid_value.rename(columns = {'ITEMID':'ITEMID_VALUE'}).copy()\n",
    "# Create empty columns for ITEMID_THRESHOLD_HIGH and ITEMID_THRESHOLD_LOW\n",
    "multimeasurement_icustayid_itemids.insert(loc=len(multimeasurement_icustayid_itemids.columns), column='ITEMID_THRESHOLD_HIGH', value=np.nan)\n",
    "multimeasurement_icustayid_itemids.insert(loc=len(multimeasurement_icustayid_itemids.columns), column='ITEMID_THRESHOLD_LOW', value=np.nan)\n",
    "\n",
    "# Add threshold ITEMIDs to the corresponding value ITEMIDs\n",
    "for i, parameter in parameters.iterrows():\n",
    "\n",
    "    multimeasurement_icustayid_itemids.loc[\n",
    "        multimeasurement_icustayid_itemids.ITEMID_VALUE == parameter['VALUE'],\n",
    "        'ITEMID_THRESHOLD_HIGH'] = parameter['THRESHOLD_HIGH']\n",
    "    \n",
    "    multimeasurement_icustayid_itemids.loc[\n",
    "        multimeasurement_icustayid_itemids.ITEMID_VALUE == parameter['VALUE'], \n",
    "        'ITEMID_THRESHOLD_LOW'] = parameter['THRESHOLD_LOW']\n",
    "\n",
    "display(multimeasurement_icustayid_itemids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame, which will be used as filter.\n",
    "# This data frame must consist of two columns ICUSTAY_ID and ITEMID.\n",
    "\n",
    "multimeasurement_icustayid_itemid_threshold_high = multimeasurement_icustayid_itemids[\n",
    "    ['ICUSTAY_ID','ITEMID_THRESHOLD_HIGH']\n",
    "    ].rename(columns = {'ITEMID_THRESHOLD_HIGH':'ITEMID'})[['ICUSTAY_ID','ITEMID']].dropna()\n",
    "    # dropna() because there are no thresholds available for Non Invasive Blood Pressure diastolic (220180)\n",
    "\n",
    "multimeasurement_icustayid_itemid_threshold_low = multimeasurement_icustayid_itemids[\n",
    "    ['ICUSTAY_ID','ITEMID_THRESHOLD_LOW']\n",
    "    ].rename(columns = {'ITEMID_THRESHOLD_LOW':'ITEMID'})[['ICUSTAY_ID','ITEMID']].dropna()\n",
    "    # dropna() because there are no thresholds available for Non Invasive Blood Pressure diastolic (220180)\n",
    "\n",
    "# Concatenate data frames into filter_multiple_measurements\n",
    "filter_multiple_measurements = pd.concat(\n",
    "    [multimeasurement_icustayid_itemid_value, multimeasurement_icustayid_itemid_threshold_high, multimeasurement_icustayid_itemid_threshold_low], axis=0)\n",
    "\n",
    "display(filter_multiple_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the chartevents_subset based on icustayid_and_itemid_with_multiple_measurements\n",
    "chartevents_cleaning_02_multiple_measurements_only = pd.merge(chartevents_subset,filter_multiple_measurements)\n",
    "\n",
    "display(chartevents_cleaning_02_multiple_measurements_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before = chartevents_subset\n",
    "df_after = chartevents_cleaning_02_multiple_measurements_only\n",
    "\n",
    "row_count_before = len(df_before)\n",
    "row_count_after = len(df_after)\n",
    "row_count_dif = row_count_before - row_count_after\n",
    "\n",
    "icustay_count_before = len(df_before.ICUSTAY_ID.unique())\n",
    "icustay_count_after = len(df_after.ICUSTAY_ID.unique())\n",
    "icustay_count_dif = icustay_count_before - icustay_count_after\n",
    "\n",
    "icustay_itemid_count_before = len(df_before.groupby(['ICUSTAY_ID','ITEMID']).size())\n",
    "icustay_itemid_count_after = len(df_after.groupby(['ICUSTAY_ID','ITEMID']).size())\n",
    "icustay_itemid_count_dif = icustay_itemid_count_before - icustay_itemid_count_after\n",
    "\n",
    "print(\"The length of the data frame is reduced by\",f'{row_count_dif:,}',\"rows from\",f'{row_count_before:,}',\"rows to\",f'{row_count_after:,}',\"rows.\")\n",
    "print(\"The number of ICUSTAY_IDs is reduced by\",f'{icustay_count_dif:,}',\"from\",f'{icustay_count_before:,}',\"to\",f'{icustay_count_after:,}',\"ICUSTAY_IDs.\")\n",
    "print(\"The number of ICUSTAY_ID-ITEMID combinations is reduced by\",f'{icustay_itemid_count_dif:,}',\"from\",f'{icustay_itemid_count_before:,}',\"to\",f'{icustay_itemid_count_after:,}',\"ICUSTAY_ID-ITEMID combinations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_subset_multiple_values as parquet file\n",
    "chartevents_cleaning_02_multiple_measurements_only.to_parquet('../data/chartevents_cleaning_02_multiple_measurements_only.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Mark parameter values outside clinically valid ranges\n",
    "\n",
    "Values outside the clinically valid ranges are flagged in a new column, not deleted."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_02_multiple_measurements_only from parquet file\n",
    "chartevents_cleaning_02_multiple_measurements_only = pd.read_parquet('../data/chartevents_cleaning_02_multiple_measurements_only.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinically valid value ranges\n",
    "# Heart Rate (220045): 0-350\n",
    "# Non Invasive Blood Pressure systolic (220179): 0-375\n",
    "# Non Invasive Blood Pressure diastolic (220180): 0-375\n",
    "# O2 saturation pulseoxymetry (220277): 0-100\n",
    "\n",
    "# Add new column CLEANING_FLAG, which is used to mark values outside the respective clinically valid range as \"Below valid value range\" or \"Above valid value range\".\n",
    "import numpy as np\n",
    "flagged_values = chartevents_cleaning_02_multiple_measurements_only[['ROW_ID','ITEMID','VALUENUM']].copy()\n",
    "flagged_values.insert(loc=len(flagged_values.columns), column='CLEANING_FLAG', value=np.nan)\n",
    "\n",
    "flagged_values.loc[\n",
    "    ((flagged_values['ITEMID'] == 220045) & (flagged_values['VALUENUM'] < 0)) | \n",
    "    ((flagged_values['ITEMID'] == 220179) & (flagged_values['VALUENUM'] < 0)) | \n",
    "    ((flagged_values['ITEMID'] == 220180) & (flagged_values['VALUENUM'] < 0)) |\n",
    "    ((flagged_values['ITEMID'] == 220277) & (flagged_values['VALUENUM'] < 0)),\n",
    "    'CLEANING_FLAG'] = \"Below valid value range\"\n",
    "\n",
    "flagged_values.loc[\n",
    "    ((flagged_values['ITEMID'] == 220045) & (flagged_values['VALUENUM'] > 350)) | \n",
    "    ((flagged_values['ITEMID'] == 220179) & (flagged_values['VALUENUM'] > 375)) | \n",
    "    ((flagged_values['ITEMID'] == 220180) & (flagged_values['VALUENUM'] > 375)) |\n",
    "    ((flagged_values['ITEMID'] == 220277) & (flagged_values['VALUENUM'] > 100)),\n",
    "    'CLEANING_FLAG'] = \"Above valid value range\"\n",
    "\n",
    "# Reduce to relevant columns and rows (only those needed for merging with chartevents_cleaning_02_multiple_measurements_only data frame) \n",
    "flagged_values = flagged_values.drop(['ITEMID','VALUENUM'], axis = 1).dropna().reset_index(drop=True)\n",
    "\n",
    "display(flagged_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_affected_count = len(flagged_values)\n",
    "value_affected_above_count = len(flagged_values[flagged_values.CLEANING_FLAG == \"Above valid value range\"])\n",
    "value_affected_below_count = len(flagged_values[flagged_values.CLEANING_FLAG == \"Below valid value range\"])\n",
    "\n",
    "print(f'{value_affected_count:,}',\"values are outside the clinically valid range,\",f'{value_affected_above_count:,}',\"above and\",f'{value_affected_below_count:,}',\"below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save flagged_values as parquet file\n",
    "flagged_values.to_parquet('../data/flagged_values.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_02_multiple_measurements_only from parquet file\n",
    "chartevents_cleaning_02_multiple_measurements_only = pd.read_parquet('../data/chartevents_cleaning_02_multiple_measurements_only.parquet', engine='pyarrow')\n",
    "\n",
    "# Read flagged_values from parquet file\n",
    "flagged_values = pd.read_parquet('../data/flagged_values.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the next step, data frames chartevents_cleaning_02_multiple_measurements_only and flagged_values are merged to form a new data frame chartevents_cleaning_03_values_in_valid_range. The latter will be extended/modified again in the next cleaning step and so on.\n",
    "\n",
    "chartevents_cleaning_03_values_in_valid_range = chartevents_cleaning_02_multiple_measurements_only.copy()\n",
    "# Create new column 'VALUENUM_CLEAN' that equals 'VALUENUM' values\n",
    "chartevents_cleaning_03_values_in_valid_range['VALUENUM_CLEAN'] = chartevents_cleaning_03_values_in_valid_range['VALUENUM']\n",
    "\n",
    "# Set all 'VALUENUM_CLEAN' cells to NaN, where we identified a cleaning flag (above or below valid range) in the value cleaning step\n",
    "chartevents_cleaning_03_values_in_valid_range = chartevents_cleaning_03_values_in_valid_range.merge(flagged_values, how='left', on=['ROW_ID'])\n",
    "chartevents_cleaning_03_values_in_valid_range.loc[\n",
    "    (chartevents_cleaning_03_values_in_valid_range.CLEANING_FLAG == \"Below valid value range\") | \n",
    "    (chartevents_cleaning_03_values_in_valid_range.CLEANING_FLAG == \"Above valid value range\"),\n",
    "    'VALUENUM_CLEAN'] = None\n",
    "\n",
    "display(chartevents_cleaning_03_values_in_valid_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demo purposes, show rows with cleaning flag (selected columns)\n",
    "chartevents_cleaning_03_values_in_valid_range[\n",
    "    chartevents_cleaning_03_values_in_valid_range.CLEANING_FLAG.notnull()\n",
    "    ][['ROW_ID','ICUSTAY_ID','ITEMID','CHARTTIME','VALUENUM','VALUENUM_CLEAN','CLEANING_FLAG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_cleaning_03_values_in_valid_range as parquet file\n",
    "chartevents_cleaning_03_values_in_valid_range.to_parquet('../data/chartevents_cleaning_03_values_in_valid_range.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Threshold cleaning\n",
    "\n",
    "In the data of some ICU stays, the high and low thresholds overlap at certain points. For example, during a certain period of time, the threshold for a heart rate that is too high may be below the threshold for a heart rate that is too low, and vice versa.\n",
    "\n",
    "According to the medical experts consulted, there is no plausible reason for this. In fact, medical devices should not allow the setting of such overlapping alarm thresholds in the first place.\n",
    "\n",
    "The overlap can show up in different ways. Roughly speaking, we have observed three variants looking at time series plots:\n",
    "\n",
    "1. The low threshold temporarily exceeds the high threshold, while the latter continues 'normally'.\n",
    "2. The high threshold value temporarily falls below the low threshold value, while the latter continues 'normally'.\n",
    "3. Both thresholds temporarily overlap so that they appear swapped, which is 'abnormal' for both.\n",
    "\n",
    "There are two sub-variants for variant (3):\n",
    "\n",
    "- 3a The threshold values are swapped, but do not decrease/increase to the same extent, so it is not an exact swap.\n",
    "- 3b The thresholds are swapped, decreasing/increasing  to the same extent, so it looks like an exact swap.\n",
    "\n",
    "According to the agreement with medical experts, the two threshold values for case 3b (exact swap) are swapped back for the time period affected.\n",
    "\n",
    "Possibly this would also be possible for case 3a. However, this seems very complex as this case is difficult for us to distinguish from cases 1 and 2."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Identify potential candidates for local threshold swap\n",
    "\n",
    "Coarse detection of the ICU stay/parameter combinations for which the local swapping of thresholds is a possible option. Purpose of this preliminary step is to reduce the computational effort. The aim is to reduce the relatively complex threshold swap step to potentially affected cases.\n",
    "\n",
    "The coarse detection is done by comparing the minimum high threshold to the maximum low threshold for each ICU stay/parameter combination. If the minimum high threshold is below the maximum low threshold, the ICU stay/parameter combination is considered for threshold swapping.\n",
    "\n",
    "The output of this section is a data frame that includes the ICU stay/parameter combinations that are possible candidates for swapping. It is to be expected that the number of candidates is higher than the number of swaps eventually performed. The reason for this is that not all threshold overlaps allow a meaningful swap (see following section)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_03_values_in_valid_range from parquet file\n",
    "chartevents_cleaning_03_values_in_valid_range = pd.read_parquet('../data/chartevents_cleaning_03_values_in_valid_range.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "# Create empty data frames to which will be appended during the loop\n",
    "min_threshold_high_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'THRESHOLD_HIGH_MIN', 'ITEMID_VALUE'])\n",
    "max_threshold_high_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'THRESHOLD_LOW_MAX', 'ITEMID_VALUE'])\n",
    "\n",
    "for i, parameter in parameters.iterrows():\n",
    "\n",
    "    # For current parameter, compute minimum value of high threshold for all ICU stays\n",
    "    min_threshold_high = chartevents_cleaning_03_values_in_valid_range[\n",
    "        chartevents_cleaning_03_values_in_valid_range['ITEMID'] == parameter['THRESHOLD_HIGH']\n",
    "        ].groupby(['ICUSTAY_ID','ITEMID'])['VALUENUM'].min()\n",
    "    min_threshold_high = min_threshold_high.reset_index()\n",
    "    min_threshold_high = min_threshold_high[['ICUSTAY_ID','VALUENUM']].rename(columns = {'VALUENUM':'THRESHOLD_HIGH_MIN'}).assign(ITEMID_VALUE=parameter.VALUE)\n",
    "\n",
    "    # For current parameter, compute maximium value of low threshold for all ICU stays\n",
    "    max_threshold_low = chartevents_cleaning_03_values_in_valid_range[\n",
    "        chartevents_cleaning_03_values_in_valid_range['ITEMID'] == parameter['THRESHOLD_LOW']\n",
    "        ].groupby(['ICUSTAY_ID','ITEMID'])['VALUENUM'].max()\n",
    "    max_threshold_low = max_threshold_low.reset_index()\n",
    "    max_threshold_low = max_threshold_low[['ICUSTAY_ID','VALUENUM']].rename(columns = {'VALUENUM':'THRESHOLD_LOW_MAX'}).assign(ITEMID_VALUE=parameter.VALUE)\n",
    "\n",
    "    # Append the results of the current parameter to the data frames for the overall results\n",
    "    min_threshold_high_per_icustay = min_threshold_high_per_icustay.append(min_threshold_high, ignore_index=True)\n",
    "    max_threshold_high_per_icustay = max_threshold_high_per_icustay.append(max_threshold_low, ignore_index=True)\n",
    "\n",
    "# Merge data frames\n",
    "threshold_min_max_per_icustay = min_threshold_high_per_icustay.merge(max_threshold_high_per_icustay, on=['ICUSTAY_ID','ITEMID_VALUE'])\n",
    "threshold_min_max_per_icustay = threshold_min_max_per_icustay[['ICUSTAY_ID', 'ITEMID_VALUE', 'THRESHOLD_HIGH_MIN', 'THRESHOLD_LOW_MAX']]\n",
    "\n",
    "display(threshold_min_max_per_icustay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify threshold swap candidates by comparing the minimum high threshold to the maximum low threshold for each ICU stay/parameter combination.\n",
    "# If the minimum low threshold is below the maximum high threshold, the ICU stay/parameter combination is considered for threshold swapping. \n",
    "threshold_min_max_per_icustay['CROSS'] = threshold_min_max_per_icustay['THRESHOLD_HIGH_MIN'] < threshold_min_max_per_icustay['THRESHOLD_LOW_MAX']\n",
    "threshold_swap_candidates = threshold_min_max_per_icustay[threshold_min_max_per_icustay['CROSS'] == True][['ICUSTAY_ID','ITEMID_VALUE']].reset_index(drop=True)\n",
    "\n",
    "display(threshold_swap_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save threshold_swap_candidates as parquet file\n",
    "threshold_swap_candidates.to_parquet('../data/threshold_swap_candidates.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "### Prepare data set for local threshold swap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_03_values_in_valid_range from parquet file\n",
    "chartevents_cleaning_03_values_in_valid_range = pd.read_parquet('../data/chartevents_cleaning_03_values_in_valid_range.parquet', engine='pyarrow')\n",
    "\n",
    "# Read threshold_swap_candidates from parquet file\n",
    "threshold_swap_candidates = pd.read_parquet('../data/threshold_swap_candidates.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The threshold_swap_candidates data frame contains only the ITEMIDs of the vital sign values, not the ITEMIDs of the associated thresholds.\n",
    "# To facilitate the subsequent subsetting of the CHARTEVENTS data frame, auxiliary data frames are created with the threshold ITEMIDs.\n",
    "# The threshold ITEMIDs are combined into one data frame, which is then used to filter the CHARTEVENT data frame.\n",
    "# There is probably a smarter way to do this, but this was fast enough.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "# Create empty data frames to which will be appended during the loop\n",
    "itemid_threshold_high_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'ITEMID'])\n",
    "itemid_threshold_low_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'ITEMID'])\n",
    "\n",
    "for i, parameter in parameters.iterrows():\n",
    "\n",
    "    # For current parameter, create data frames with threshold ITEMIDs\n",
    "    itemid_threshold_high = threshold_swap_candidates[threshold_swap_candidates['ITEMID_VALUE'] == parameter['VALUE']][['ICUSTAY_ID']].assign(ITEMID=parameter.THRESHOLD_HIGH)\n",
    "    itemid_threshold_low = threshold_swap_candidates[threshold_swap_candidates['ITEMID_VALUE'] == parameter['VALUE']][['ICUSTAY_ID']].assign(ITEMID=parameter.THRESHOLD_LOW)\n",
    "\n",
    "    # Append the results of the current parameter to the data frames for the overall results\n",
    "    itemid_threshold_high_per_icustay = itemid_threshold_high_per_icustay.append(itemid_threshold_high, ignore_index=True)\n",
    "    itemid_threshold_low_per_icustay = itemid_threshold_low_per_icustay.append(itemid_threshold_low, ignore_index=True)\n",
    "\n",
    "# Merge data frames vertically\n",
    "threshold_swap_filter = pd.concat([itemid_threshold_high_per_icustay, itemid_threshold_low_per_icustay], axis= 0)\n",
    "\n",
    "# Sort to make it pretty (not important)\n",
    "threshold_swap_filter = threshold_swap_filter.sort_values(by=['ICUSTAY_ID','ITEMID']).reset_index(drop=True)\n",
    "\n",
    "display(threshold_swap_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the chartevents_subset based on the threshold_swap_filter\n",
    "threshold_swap_data = pd.merge(chartevents_cleaning_03_values_in_valid_range,threshold_swap_filter)\n",
    "display(threshold_swap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save threshold_swap_data as parquet file\n",
    "threshold_swap_data.to_parquet('../data/threshold_swap_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "### Perform local threshold swap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_03_values_in_valid_range from parquet file\n",
    "chartevents_cleaning_03_values_in_valid_range = pd.read_parquet('../data/chartevents_cleaning_03_values_in_valid_range.parquet', engine='pyarrow')\n",
    "\n",
    "# Read threshold_swap_data from parquet file\n",
    "threshold_swap_data = pd.read_parquet('../data/threshold_swap_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "icustays = threshold_swap_data.ICUSTAY_ID.unique()\n",
    "\n",
    "thresholds_fixed = pd.DataFrame(columns=['ICUSTAY_ID', 'ITEMID_VALUE', 'CHARTTIME', 'THRESHOLD_LOW_FIXED', 'THRESHOLD_HIGH_FIXED'])\n",
    "\n",
    "for icustay in icustays:\n",
    "    \n",
    "    for i, parameter in parameters.iterrows():\n",
    "        \n",
    "        threshold_high = threshold_swap_data[\n",
    "            (threshold_swap_data[\"ICUSTAY_ID\"] == icustay) & \n",
    "            (threshold_swap_data[\"ITEMID\"] == parameter['THRESHOLD_HIGH'])][\n",
    "            ['CHARTTIME','VALUENUM']\n",
    "            ].sort_values(by=['CHARTTIME']).rename(columns = {'VALUENUM':'THRESHOLD_HIGH'})\n",
    "\n",
    "        threshold_low = threshold_swap_data[\n",
    "            (threshold_swap_data[\"ICUSTAY_ID\"] == icustay) & \n",
    "            (threshold_swap_data[\"ITEMID\"] == parameter['THRESHOLD_LOW'])][\n",
    "            ['CHARTTIME','VALUENUM']\n",
    "            ].sort_values(by=['CHARTTIME']).rename(columns = {'VALUENUM':'THRESHOLD_LOW'})\n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime = threshold_high.merge(threshold_low, on=['CHARTTIME']).assign(ICUSTAY_ID=icustay, ITEMID_VALUE=parameter.VALUE)\n",
    "        \n",
    "        # Create a new column that contains the chronologically following threshold value of the same type\n",
    "        thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH_NEXT'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH'].shift(-1)\n",
    "        thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW_NEXT'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW'].shift(-1)\n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_HIGH_NEXT'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH_NEXT'] - thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH']\n",
    "        thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_LOW_NEXT'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW_NEXT'] - thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW']\n",
    "        \n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime.insert(loc=len(thresholds_by_icustay_parameter_charttime.columns), column='THRESHOLD_HIGH_FIXED', value=np.nan)\n",
    "        thresholds_by_icustay_parameter_charttime.insert(loc=len(thresholds_by_icustay_parameter_charttime.columns), column='THRESHOLD_LOW_FIXED', value=np.nan)\n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime.loc[\n",
    "            (thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH'] < thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW']) &\n",
    "            (abs(thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_HIGH_NEXT']) == abs(thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_LOW_NEXT'])),\n",
    "            'THRESHOLD_HIGH_FIXED'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW']\n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime.loc[\n",
    "            (thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH'] < thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW']) &\n",
    "            (abs(thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_HIGH_NEXT']) == abs(thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_LOW_NEXT'])),\n",
    "            'THRESHOLD_LOW_FIXED'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH']\n",
    "        \n",
    "        thresholds_by_icustay_parameter_charttime.dropna(inplace=True)\n",
    "        thresholds_fixed_for_icustayid_itemid = thresholds_by_icustay_parameter_charttime[['ICUSTAY_ID', 'ITEMID_VALUE', 'CHARTTIME', 'THRESHOLD_LOW_FIXED', 'THRESHOLD_HIGH_FIXED']]\n",
    "\n",
    "        thresholds_fixed = thresholds_fixed.append(thresholds_fixed_for_icustayid_itemid, ignore_index=True)\n",
    "\n",
    "display(thresholds_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save thresholds_fixed as parquet file\n",
    "thresholds_fixed.to_parquet('../data/thresholds_fixed.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_03_values_in_valid_range from parquet file\n",
    "chartevents_cleaning_03_values_in_valid_range = pd.read_parquet('../data/chartevents_cleaning_03_values_in_valid_range.parquet', engine='pyarrow')\n",
    "\n",
    "# Read thresholds_fixed from parquet file\n",
    "thresholds_fixed = pd.read_parquet('../data/thresholds_fixed.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the next step, data frames chartevents_cleaning_03_values_in_valid_range and thresholds_fixed are merged to form a new data frame chartevents_cleaning_04_exact_threshold_swaps_reverted. The latter will be extended/modified again in the next cleaning step and so on.\n",
    "\n",
    "chartevents_cleaning_04_exact_threshold_swaps_reverted = chartevents_cleaning_03_values_in_valid_range.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnecessarily complicated step; could be simplified by better preparation of the data frame to be merged.\n",
    "# Needed because the thresholds_fixed data frame does contain the ITEMID_VALUE but not the threshold ITEMIDs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "thresholds_fixed.insert(loc=len(thresholds_fixed.columns), column='ITEMID_THRESHOLD_HIGH', value=np.nan)\n",
    "thresholds_fixed.insert(loc=len(thresholds_fixed.columns), column='ITEMID_THRESHOLD_LOW', value=np.nan)\n",
    "\n",
    "for i, parameter in parameters.iterrows():\n",
    "\n",
    "    thresholds_fixed.loc[thresholds_fixed.ITEMID_VALUE == parameter['VALUE'], 'ITEMID_THRESHOLD_HIGH'] = parameter['THRESHOLD_HIGH']\n",
    "    thresholds_fixed.loc[thresholds_fixed.ITEMID_VALUE == parameter['VALUE'], 'ITEMID_THRESHOLD_LOW'] = parameter['THRESHOLD_LOW']\n",
    "\n",
    "display(thresholds_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_fixed_high = thresholds_fixed[\n",
    "    ['ICUSTAY_ID','CHARTTIME','THRESHOLD_HIGH_FIXED','ITEMID_THRESHOLD_HIGH']\n",
    "    ].rename(columns = {'THRESHOLD_HIGH_FIXED':'VALUENUM_CLEAN', 'ITEMID_THRESHOLD_HIGH':'ITEMID'})\n",
    "thresholds_fixed_high = thresholds_fixed_high[['ICUSTAY_ID','ITEMID','CHARTTIME','VALUENUM_CLEAN']]\n",
    "\n",
    "thresholds_fixed_low = thresholds_fixed[\n",
    "    ['ICUSTAY_ID','CHARTTIME','THRESHOLD_LOW_FIXED','ITEMID_THRESHOLD_LOW']\n",
    "    ].rename(columns = {'THRESHOLD_LOW_FIXED':'VALUENUM_CLEAN', 'ITEMID_THRESHOLD_LOW':'ITEMID'})\n",
    "thresholds_fixed_low = thresholds_fixed_low[['ICUSTAY_ID','ITEMID','CHARTTIME','VALUENUM_CLEAN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes quite long (approx. 11min); there is probably a better why to insert/replace the swapped threshold values in the VALUENUM_CLEAN column\n",
    "\n",
    "for i, row in thresholds_fixed_high.iterrows():\n",
    "\n",
    "    chartevents_cleaning_04_exact_threshold_swaps_reverted.loc[\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.CHARTTIME == row['CHARTTIME']), \n",
    "        'VALUENUM_CLEAN'] = row['VALUENUM_CLEAN']\n",
    "\n",
    "    chartevents_cleaning_04_exact_threshold_swaps_reverted.loc[\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.CHARTTIME == row['CHARTTIME']), \n",
    "        'CLEANING_FLAG'] = \"High threshold fixed by swap\"\n",
    "\n",
    "for i, row in thresholds_fixed_low.iterrows():\n",
    "\n",
    "    chartevents_cleaning_04_exact_threshold_swaps_reverted.loc[\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.CHARTTIME == row['CHARTTIME']), \n",
    "        'VALUENUM_CLEAN'] = row['VALUENUM_CLEAN']\n",
    "\n",
    "    chartevents_cleaning_04_exact_threshold_swaps_reverted.loc[\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_cleaning_04_exact_threshold_swaps_reverted.CHARTTIME == row['CHARTTIME']), \n",
    "        'CLEANING_FLAG'] = \"Low threshold fixed by swap\"\n",
    "\n",
    "display(chartevents_cleaning_04_exact_threshold_swaps_reverted[\n",
    "    chartevents_cleaning_04_exact_threshold_swaps_reverted.CLEANING_FLAG.isin(['High threshold fixed by swap','Low threshold fixed by swap'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_cleaning_04_exact_threshold_swaps_reverted as parquet file\n",
    "chartevents_cleaning_04_exact_threshold_swaps_reverted.to_parquet('../data/chartevents_cleaning_04_exact_threshold_swaps_reverted.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "### Clean thresholds outside clinically valid ranges"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_04_exact_threshold_swaps_reverted from parquet file to pandas data frame\n",
    "chartevents_cleaning_04_exact_threshold_swaps_reverted = pd.read_parquet('../data/chartevents_cleaning_04_exact_threshold_swaps_reverted.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinically valid threshold ranges\n",
    "# Currently, identical to the value ranges and the same for both threshold types (low and high).\n",
    "# It is conceivable to define the ranges for each threshold separately, although we currently lack the medical basis for this.\n",
    "# Heart rate Alarm - High (220046): 0-350\n",
    "# Heart Rate Alarm - Low (220047): 0-350\n",
    "# Non-Invasive Blood Pressure Alarm - High (223751): 0-375\n",
    "# Non-Invasive Blood Pressure Alarm - Low (223752): 0-375\n",
    "# O2 Saturation Pulseoxymetry Alarm - High (223769): 0-100\n",
    "# O2 Saturation Pulseoxymetry Alarm - Low (223770): 0-100\n",
    "\n",
    "# The approach of threshold flagging is similar to the value flagging  performed above.\n",
    "# However, in this case not the original VALUENUM is used but the VALUENUM_CLEAN.\n",
    "# The reason for this is that threshold values outside the valid ranges can also be among the swapped back threshold values.\n",
    "# This is done to include the reverted exact threshold swaps (see above), which may contain thresholds outside the valid ranges.\n",
    "\n",
    "chartevents_cleaning_05_thresholds_in_valid_range = chartevents_cleaning_04_exact_threshold_swaps_reverted.copy()\n",
    "\n",
    "chartevents_cleaning_05_thresholds_in_valid_range.loc[\n",
    "    ((chartevents_cleaning_05_thresholds_in_valid_range['ITEMID'].isin([220046, 220047])) & (chartevents_cleaning_05_thresholds_in_valid_range['VALUENUM_CLEAN'] < 0)) | \n",
    "    ((chartevents_cleaning_05_thresholds_in_valid_range['ITEMID'].isin([223751, 223752])) & (chartevents_cleaning_05_thresholds_in_valid_range['VALUENUM_CLEAN'] < 0)) | \n",
    "    ((chartevents_cleaning_05_thresholds_in_valid_range['ITEMID'].isin([223769, 223770])) & (chartevents_cleaning_05_thresholds_in_valid_range['VALUENUM_CLEAN'] < 0)),\n",
    "    'CLEANING_FLAG'] = \"Below valid threshold range\"\n",
    "\n",
    "chartevents_cleaning_05_thresholds_in_valid_range.loc[\n",
    "    ((chartevents_cleaning_05_thresholds_in_valid_range['ITEMID'].isin([220046, 220047])) & (chartevents_cleaning_05_thresholds_in_valid_range['VALUENUM_CLEAN'] > 350)) | \n",
    "    ((chartevents_cleaning_05_thresholds_in_valid_range['ITEMID'].isin([223751, 223752])) & (chartevents_cleaning_05_thresholds_in_valid_range['VALUENUM_CLEAN'] > 375)) | \n",
    "    ((chartevents_cleaning_05_thresholds_in_valid_range['ITEMID'].isin([223769, 223770])) & (chartevents_cleaning_05_thresholds_in_valid_range['VALUENUM_CLEAN'] > 100)),\n",
    "    'CLEANING_FLAG'] = \"Above valid threshold range\"\n",
    "\n",
    "chartevents_cleaning_05_thresholds_in_valid_range.loc[\n",
    "    (chartevents_cleaning_05_thresholds_in_valid_range['CLEANING_FLAG'].isin([\"Below valid threshold range\",\"Above valid threshold range\"])),\n",
    "    'VALUENUM_CLEAN'] = None\n",
    "\n",
    "display(chartevents_cleaning_05_thresholds_in_valid_range[\n",
    "    chartevents_cleaning_05_thresholds_in_valid_range.CLEANING_FLAG.isin([\"Below valid threshold range\",\"Above valid threshold range\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_cleaning_05_thresholds_in_valid_range as parquet file\n",
    "chartevents_cleaning_05_thresholds_in_valid_range.to_parquet('../data/chartevents_cleaning_05_thresholds_in_valid_range.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "### Identify potential candidates for local threshold removal due to overlap\n",
    "\n",
    "The approach to identifying potential candidates for local threshold removal due to overlap is similar to the candidate identification performed above in the context of threshold swapping. However, in this case not the original VALUENUM is used but the VALUENUM_CLEAN."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_05_thresholds_in_valid_range from parquet file\n",
    "chartevents_cleaning_05_thresholds_in_valid_range = pd.read_parquet('../data/chartevents_cleaning_05_thresholds_in_valid_range.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "# Create empty data frames to which will be appended during the loop\n",
    "min_threshold_high_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'THRESHOLD_HIGH_MIN', 'ITEMID_VALUE'])\n",
    "max_threshold_high_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'THRESHOLD_LOW_MAX', 'ITEMID_VALUE'])\n",
    "\n",
    "for i, parameter in parameters.iterrows():\n",
    "\n",
    "    # For current parameter, compute minimum value of high threshold for all ICU stays\n",
    "    min_threshold_high = chartevents_cleaning_05_thresholds_in_valid_range[\n",
    "        chartevents_cleaning_05_thresholds_in_valid_range['ITEMID'] == parameter['THRESHOLD_HIGH']\n",
    "        ].groupby(['ICUSTAY_ID','ITEMID'])['VALUENUM_CLEAN'].min()\n",
    "    min_threshold_high = min_threshold_high.reset_index()\n",
    "    min_threshold_high = min_threshold_high[['ICUSTAY_ID','VALUENUM_CLEAN']].rename(columns = {'VALUENUM_CLEAN':'THRESHOLD_HIGH_MIN'}).assign(ITEMID_VALUE=parameter.VALUE)\n",
    "\n",
    "    # For current parameter, compute maximium value of low threshold for all ICU stays\n",
    "    max_threshold_low = chartevents_cleaning_05_thresholds_in_valid_range[\n",
    "        chartevents_cleaning_05_thresholds_in_valid_range['ITEMID'] == parameter['THRESHOLD_LOW']\n",
    "        ].groupby(['ICUSTAY_ID','ITEMID'])['VALUENUM_CLEAN'].max()\n",
    "    max_threshold_low = max_threshold_low.reset_index()\n",
    "    max_threshold_low = max_threshold_low[['ICUSTAY_ID','VALUENUM_CLEAN']].rename(columns = {'VALUENUM_CLEAN':'THRESHOLD_LOW_MAX'}).assign(ITEMID_VALUE=parameter.VALUE)\n",
    "\n",
    "    # Append the results of the current parameter to the data frames for the overall results\n",
    "    min_threshold_high_per_icustay = min_threshold_high_per_icustay.append(min_threshold_high, ignore_index=True)\n",
    "    max_threshold_high_per_icustay = max_threshold_high_per_icustay.append(max_threshold_low, ignore_index=True)\n",
    "\n",
    "# Merge data frames\n",
    "threshold_min_max_per_icustay = min_threshold_high_per_icustay.merge(max_threshold_high_per_icustay, on=['ICUSTAY_ID','ITEMID_VALUE'])\n",
    "threshold_min_max_per_icustay = threshold_min_max_per_icustay[['ICUSTAY_ID', 'ITEMID_VALUE', 'THRESHOLD_HIGH_MIN', 'THRESHOLD_LOW_MAX']]\n",
    "\n",
    "display(threshold_min_max_per_icustay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify threshold removal candidates by comparing the minimum high threshold to the maximum low threshold for each ICU stay/parameter combination.\n",
    "# If the minimum low threshold is below the maximum high threshold, the ICU stay/parameter combination is considered for threshold removal. \n",
    "threshold_min_max_per_icustay['CROSS'] = threshold_min_max_per_icustay['THRESHOLD_HIGH_MIN'] < threshold_min_max_per_icustay['THRESHOLD_LOW_MAX']\n",
    "threshold_removal_candidates = threshold_min_max_per_icustay[threshold_min_max_per_icustay['CROSS'] == True][['ICUSTAY_ID','ITEMID_VALUE']].reset_index(drop=True)\n",
    "\n",
    "display(threshold_removal_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save threshold_removal_candidates as parquet file\n",
    "threshold_removal_candidates.to_parquet('../data/threshold_removal_candidates.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "### Prepare data set for local threshold removal due to overlap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_05_thresholds_in_valid_range from parquet file\n",
    "chartevents_cleaning_05_thresholds_in_valid_range = pd.read_parquet('../data/chartevents_cleaning_05_thresholds_in_valid_range.parquet', engine='pyarrow')\n",
    "\n",
    "# Read threshold_removal_candidates from parquet file\n",
    "threshold_removal_candidates = pd.read_parquet('../data/threshold_removal_candidates.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The threshold_removal_candidates data frame contains only the ITEMIDs of the vital sign values, not the ITEMIDs of the associated thresholds.\n",
    "# To facilitate the subsequent subsetting, auxiliary data frames are created with the threshold ITEMIDs.\n",
    "# The threshold ITEMIDs are combined into one data frame, which is then used to filter the data frame.\n",
    "# There is probably a smarter way to do this, but this was fast enough.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "# Create empty data frames to which will be appended during the loop\n",
    "itemid_threshold_high_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'ITEMID'])\n",
    "itemid_threshold_low_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'ITEMID'])\n",
    "\n",
    "for i, parameter in parameters.iterrows():\n",
    "\n",
    "    # For current parameter, create data frames with threshold ITEMIDs\n",
    "    itemid_threshold_high = threshold_removal_candidates[threshold_removal_candidates['ITEMID_VALUE'] == parameter['VALUE']][['ICUSTAY_ID']].assign(ITEMID=parameter.THRESHOLD_HIGH)\n",
    "    itemid_threshold_low = threshold_removal_candidates[threshold_removal_candidates['ITEMID_VALUE'] == parameter['VALUE']][['ICUSTAY_ID']].assign(ITEMID=parameter.THRESHOLD_LOW)\n",
    "\n",
    "    # Append the results of the current parameter to the data frames for the overall results\n",
    "    itemid_threshold_high_per_icustay = itemid_threshold_high_per_icustay.append(itemid_threshold_high, ignore_index=True)\n",
    "    itemid_threshold_low_per_icustay = itemid_threshold_low_per_icustay.append(itemid_threshold_low, ignore_index=True)\n",
    "\n",
    "# Merge data frames vertically\n",
    "threshold_removal_filter = pd.concat([itemid_threshold_high_per_icustay, itemid_threshold_low_per_icustay], axis= 0)\n",
    "\n",
    "# Sort to make it pretty (not important)\n",
    "threshold_removal_filter = threshold_removal_filter.sort_values(by=['ICUSTAY_ID','ITEMID']).reset_index(drop=True)\n",
    "\n",
    "display(threshold_removal_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the chartevents_cleaning_05_thresholds_in_valid_range based on the threshold_removal_filter\n",
    "threshold_removal_data = pd.merge(chartevents_cleaning_05_thresholds_in_valid_range,threshold_removal_filter)\n",
    "display(threshold_removal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save threshold_removal_data as parquet file\n",
    "threshold_removal_data.to_parquet('../data/threshold_removal_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "### Perform local threshold removal due to overlap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_05_thresholds_in_valid_range from parquet file\n",
    "chartevents_cleaning_05_thresholds_in_valid_range = pd.read_parquet('../data/chartevents_cleaning_05_thresholds_in_valid_range.parquet', engine='pyarrow')\n",
    "\n",
    "# Read threshold_removal_data from parquet file\n",
    "threshold_removal_data = pd.read_parquet('../data/threshold_removal_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "icustays = threshold_removal_data.ICUSTAY_ID.unique()\n",
    "\n",
    "thresholds_to_be_removed = pd.DataFrame(columns=['ICUSTAY_ID', 'ITEMID_VALUE', 'CHARTTIME'])\n",
    "\n",
    "for icustay in icustays:\n",
    "    \n",
    "    for i, parameter in parameters.iterrows():\n",
    "        \n",
    "        threshold_high = threshold_removal_data[\n",
    "            (threshold_removal_data[\"ICUSTAY_ID\"] == icustay) & \n",
    "            (threshold_removal_data[\"ITEMID\"] == parameter['THRESHOLD_HIGH'])][\n",
    "            ['CHARTTIME','VALUENUM_CLEAN']\n",
    "            ].sort_values(by=['CHARTTIME']).rename(columns = {'VALUENUM_CLEAN':'THRESHOLD_HIGH'})\n",
    "\n",
    "        threshold_low = threshold_removal_data[\n",
    "            (threshold_removal_data[\"ICUSTAY_ID\"] == icustay) & \n",
    "            (threshold_removal_data[\"ITEMID\"] == parameter['THRESHOLD_LOW'])][\n",
    "            ['CHARTTIME','VALUENUM_CLEAN']\n",
    "            ].sort_values(by=['CHARTTIME']).rename(columns = {'VALUENUM_CLEAN':'THRESHOLD_LOW'})\n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime = threshold_high.merge(threshold_low, on=['CHARTTIME']).assign(ICUSTAY_ID=icustay, ITEMID_VALUE=parameter.VALUE)\n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime.insert(loc=len(thresholds_by_icustay_parameter_charttime.columns), column='CLEANING_FLAG', value=np.nan)\n",
    "        thresholds_by_icustay_parameter_charttime.loc[\n",
    "            (thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH'] < thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW']),\n",
    "            'CLEANING_FLAG'] = \"Threshold removal due to overlap\"\n",
    "        \n",
    "        thresholds_by_icustay_parameter_charttime.dropna(inplace=True)\n",
    "        thresholds_to_be_removed_for_icustayid_itemid = thresholds_by_icustay_parameter_charttime[['ICUSTAY_ID', 'ITEMID_VALUE', 'CHARTTIME', 'CLEANING_FLAG']]\n",
    "\n",
    "        thresholds_to_be_removed = thresholds_to_be_removed.append(thresholds_to_be_removed_for_icustayid_itemid, ignore_index=True)\n",
    "\n",
    "display(thresholds_to_be_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save thresholds_to_be_removed as parquet file\n",
    "thresholds_to_be_removed.to_parquet('../data/thresholds_to_be_removed.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_cleaning_05_thresholds_in_valid_range from parquet file\n",
    "chartevents_cleaning_05_thresholds_in_valid_range = pd.read_parquet('../data/chartevents_cleaning_05_thresholds_in_valid_range.parquet', engine='pyarrow')\n",
    "\n",
    "# Read thresholds_to_be_removed from parquet file\n",
    "thresholds_to_be_removed = pd.read_parquet('../data/thresholds_to_be_removed.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_cleaning_06_overlapping_thresholds_removed = chartevents_cleaning_05_thresholds_in_valid_range.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnecessarily complicated step; could be simplified by better preparation of the data frame to be merged.\n",
    "# Needed because the thresholds_to_be_removed data frame does contain the ITEMID_VALUE but not the threshold ITEMIDs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "thresholds_to_be_removed.insert(loc=len(thresholds_to_be_removed.columns), column='ITEMID_THRESHOLD_HIGH', value=np.nan)\n",
    "thresholds_to_be_removed.insert(loc=len(thresholds_to_be_removed.columns), column='ITEMID_THRESHOLD_LOW', value=np.nan)\n",
    "\n",
    "for i, parameter in parameters.iterrows():\n",
    "\n",
    "    thresholds_to_be_removed.loc[thresholds_to_be_removed.ITEMID_VALUE == parameter['VALUE'], 'ITEMID_THRESHOLD_HIGH'] = parameter['THRESHOLD_HIGH']\n",
    "    thresholds_to_be_removed.loc[thresholds_to_be_removed.ITEMID_VALUE == parameter['VALUE'], 'ITEMID_THRESHOLD_LOW'] = parameter['THRESHOLD_LOW']\n",
    "\n",
    "display(thresholds_to_be_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_to_be_removed_high = thresholds_to_be_removed[\n",
    "    ['ICUSTAY_ID','CHARTTIME','CLEANING_FLAG','ITEMID_THRESHOLD_HIGH']\n",
    "    ].rename(columns = {'ITEMID_THRESHOLD_HIGH':'ITEMID'})\n",
    "thresholds_to_be_removed_high = thresholds_to_be_removed_high[['ICUSTAY_ID','ITEMID','CHARTTIME','CLEANING_FLAG']]\n",
    "\n",
    "thresholds_to_be_removed_low = thresholds_to_be_removed[\n",
    "    ['ICUSTAY_ID','CHARTTIME','CLEANING_FLAG','ITEMID_THRESHOLD_LOW']\n",
    "    ].rename(columns = {'ITEMID_THRESHOLD_LOW':'ITEMID'})\n",
    "thresholds_to_be_removed_low = thresholds_to_be_removed_low[['ICUSTAY_ID','ITEMID','CHARTTIME','CLEANING_FLAG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes quite long (approx. 24min); there is probably a better why to insert/replace the swapped threshold values in the VALUENUM_CLEAN column\n",
    "\n",
    "for i, row in thresholds_to_be_removed_high.iterrows():\n",
    "\n",
    "    chartevents_cleaning_06_overlapping_thresholds_removed.loc[\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.CHARTTIME == row['CHARTTIME']), \n",
    "        'VALUENUM_CLEAN'] = None\n",
    "\n",
    "    chartevents_cleaning_06_overlapping_thresholds_removed.loc[\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.CHARTTIME == row['CHARTTIME']), \n",
    "        'CLEANING_FLAG'] = \"Threshold removal due to overlap\"\n",
    "\n",
    "for i, row in thresholds_to_be_removed_low.iterrows():\n",
    "\n",
    "    chartevents_cleaning_06_overlapping_thresholds_removed.loc[\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.CHARTTIME == row['CHARTTIME']), \n",
    "        'VALUENUM_CLEAN'] = None\n",
    "\n",
    "    chartevents_cleaning_06_overlapping_thresholds_removed.loc[\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_cleaning_06_overlapping_thresholds_removed.CHARTTIME == row['CHARTTIME']), \n",
    "        'CLEANING_FLAG'] = \"Threshold removal due to overlap\"\n",
    "\n",
    "display(chartevents_cleaning_06_overlapping_thresholds_removed[\n",
    "    chartevents_cleaning_06_overlapping_thresholds_removed.CLEANING_FLAG == \"Threshold removal due to overlap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_cleaning_06_overlapping_thresholds_removed as parquet file\n",
    "chartevents_cleaning_06_overlapping_thresholds_removed.to_parquet('../data/chartevents_cleaning_06_overlapping_thresholds_removed.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Save final chartevents_clean data frame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# For now, the data frame is stored twice with different names, because it may be that further cleanup steps follow later, so that chartevents_cleaning_06_overlapping_thresholds_removed is not the final chartevents_clean anymore.\n",
    "chartevents_clean = chartevents_cleaning_06_overlapping_thresholds_removed\n",
    "\n",
    "# Save chartevents_cleaning_05_thresholds_in_valid_range as parquet file\n",
    "chartevents_clean.to_parquet('../data/chartevents_clean.parquet', engine='pyarrow')"
   ]
  }
 ]
}