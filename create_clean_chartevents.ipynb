{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd0e2bfb1b1dd0bcdebdb315279aa118b1f834444d4ba3ba6d660e9f6ce7703f6a2",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e2bfb1b1dd0bcdebdb315279aa118b1f834444d4ba3ba6d660e9f6ce7703f6a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Create clean CAHRTEVENTS data set\n",
    "\n",
    "1. Create chartevents_subset by filtering for relevant ITEMIDs\n",
    "2. Compute unique ICUSTAY_IDs in chartevents_subset\n",
    "3. Remove rows with insufficient measurements from chartevents_subset\n",
    "4. Mark parameter values outside clinically valid ranges\n",
    "5. Threshold cleaning\n",
    "  - Identify potential candidates for local threshold swap\n",
    "  - Prepare data set for local threshold swap\n",
    "  - Perform local threshold swap\n",
    "6. Combine cleaned values and thresholds to chartevents_clean"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Create chartevents_subset by filtering for relevant ITEMIDs\n",
    "\n",
    "* Create subset of MIMIC-III data set called `CHARTEVENTS.csv` (see also respective [MIMIC schema website](https://mit-lcp.github.io/mimic-schema-spy/tables/chartevents.html))\n",
    "* No change in columns, keep all of them.\n",
    "* Reduce number of rows by filtering for specific ITEMIDs and removing rows without ICUSTAY_ID"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import pyarrow as pa\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Read CHARTEVENTS.csv as Dask DataFrame\n",
    "# Data types based on MIMIC schema specification https://mit-lcp.github.io/mimic-schema-spy/tables/chartevents.html\n",
    "# Problem: Complicated use of intger data types with NaNs in Pandas, see https://pandas.pydata.org/pandas-docs/stable/user_guide/gotchas.html#nan-integer-na-values-and-na-type-promotions\n",
    "# Decision: Floats and integers are read in as 'float64', strings as 'object', and timestamps via Dask's parse_dates provided for this purpose.\n",
    "chartevents = dd.read_csv('../mimic/CHARTEVENTS.csv', parse_dates=['CHARTTIME','STORETIME'], dtype={\n",
    "    'ROW_ID': 'float64', # int4 according to specification\n",
    "    'SUBJECT_ID': 'float64', # int4 according to specification\n",
    "    'HADM_ID': 'float64', # int4 according to specification\n",
    "    'ICUSTAY_ID': 'float64', # int4 according to specification\n",
    "    'ITEMID': 'float64', # int4 according to specification\n",
    "    'CGID': 'float64', # int4 according to specification\n",
    "    'VALUE': 'object',\n",
    "    'VALUENUM': 'float64', # float8 according to specification\n",
    "    'VALUEUOM': 'object',\n",
    "    'WARNING': 'float64', # int4 according to specification\n",
    "    'ERROR': 'float64', # int4 according to specification\n",
    "    'RESULTSTATUS': 'object',\n",
    "    'STOPPED': 'object'})\n",
    "\n",
    "# Create set of relevant ITEMIDs to filter by\n",
    "itemid_filter = [220045, 220046, 220047, 220179, 223751, 223752, 220180, 220277, 223769, 223770]\n",
    "# 220045 Heart Rate\n",
    "# 220046 Heart rate Alarm - High\n",
    "# 220047 Heart Rate Alarm - Low\n",
    "# 220179 Non Invasive Blood Pressure systolic\n",
    "# 223751 Non-Invasive Blood Pressure Alarm - High\n",
    "# 223752 Non-Invasive Blood Pressure Alarm - Low\n",
    "# 220180 Non Invasive Blood Pressure diastolic\n",
    "# 220277 O2 saturation pulseoxymetry\n",
    "# 223769 O2 Saturation Pulseoxymetry Alarm - High\n",
    "# 223770 O2 Saturation Pulseoxymetry Alarm - Low\n",
    "\n",
    "with ProgressBar():\n",
    "    # Filter by ITEMIDs\n",
    "    chartevents_subset = chartevents[chartevents.ITEMID.isin(itemid_filter)]\n",
    "    # Drop rows without ICUSTAY_ID (The ICUSTAY_ID is missing in 1811 rows, so these are removed.)\n",
    "    chartevents_subset = chartevents_subset.dropna(how='any', subset=['ICUSTAY_ID'])\n",
    "    # Keep only the rows for which no error occurred, which is coded by a 0. (5584 rows are dropped because the boolean ERROR column equals 1, indicating an error.)\n",
    "    chartevents_subset = chartevents_subset[chartevents_subset.ERROR.isin([0])]\n",
    "    # Apply the previously defined commands to the Dask DataFrame, resulting in the desired Pandas DataFrame.\n",
    "    chartevents_subset = chartevents_subset.compute()\n",
    "    # Computing duration on Marius' laptop (Intel i5-5200U CPU @ 2.20GHz): 21min\n",
    "\n",
    "# Sort the rows (not essential, but gives a better overview)\n",
    "chartevents_subset = chartevents_subset.sort_values(by=['ICUSTAY_ID', 'CHARTTIME','ITEMID'])\n",
    "\n",
    "# Rest index\n",
    "chartevents_subset = chartevents_subset.reset_index(drop=True)\n",
    "\n",
    "# Save as parquet file\n",
    "pd.DataFrame(chartevents_subset).to_parquet('../data/chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Compute unique ICUSTAY_IDs in chartevents_subset\n",
    "\n",
    "Create DataFrame that contains only the `ICUSTAY_ID` column, which contains all unique ICUSTAY_IDs contained in `chartevents_subset.parquet`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "chartevents_subset = pd.read_parquet('../data/chartevents_subset.parquet', engine='pyarrow')\n",
    "\n",
    "# Compute unqiue ICU stays in chartevents_subset \n",
    "unique_icustays_in_chartevents_subset = pd.Series(chartevents_subset.ICUSTAY_ID.unique()).rename('ICUSTAY_ID')\n",
    "\n",
    "# Save as parquet file (To do this, the Pandas Series must be converted to a Pandas DataFrame.)\n",
    "pd.DataFrame(unique_icustays_in_chartevents_subset).to_parquet('../data/unique_icustays_in_chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Remove rows with insufficient measurements from chartevents_subset\n",
    "\n",
    "Keep only those ICUSTAY_ID-ITEMID combinations for which more than one measurement is available."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file to pandas data frame\n",
    "chartevents_subset = pd.read_parquet('../data/chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider only those ITEMIDs for the analysis which refer to vital parameter values; threshold values are intentionally not included.\n",
    "itemids = [220045, 220179, 220180, 220277]\n",
    "# 220045 Heart Rate\n",
    "# 220179 Non Invasive Blood Pressure systolic\n",
    "# 220180 Non Invasive Blood Pressure diastolic\n",
    "# 220277 O2 saturation pulseoxymetry\n",
    "\n",
    "# Create subset of chartevents_subset for measurement analysis\n",
    "chartevents_subset_measurement_analysis = chartevents_subset[['ICUSTAY_ID','ITEMID','VALUENUM']].copy()\n",
    "chartevents_subset_measurement_analysis = chartevents_subset_measurement_analysis[chartevents_subset_measurement_analysis.ITEMID.isin(itemids)]\n",
    "\n",
    "# For each ICUSTAY_ID-ITEMID combination, compute the number of available values as VALUENUM_COUNT\n",
    "chartevents_subset_measurement_count = chartevents_subset_measurement_analysis.groupby(['ICUSTAY_ID','ITEMID']).count()\n",
    "chartevents_subset_measurement_count = chartevents_subset_measurement_count.rename(columns = {'VALUENUM':'VALUENUM_COUNT'})\n",
    "chartevents_subset_measurement_count = chartevents_subset_measurement_count.reset_index()\n",
    "display(chartevents_subset_measurement_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_subset_measurement_count as parquet file\n",
    "chartevents_subset_measurement_count.to_parquet('../data/chartevents_subset_measurement_count.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file\n",
    "chartevents_subset = pd.read_parquet('../data/chartevents_subset.parquet', engine='pyarrow')\n",
    "\n",
    "# Read chartevents_subset_measurement_count from parquet file\n",
    "chartevents_subset_measurement_count = pd.read_parquet('../data/chartevents_subset_measurement_count.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ICUSTAY_ID-ITEMID combinations for which more than one measurement is available\n",
    "icustayid_and_itemid_with_multiple_measurements = chartevents_subset_measurement_count[chartevents_subset_measurement_count['VALUENUM_COUNT'] > 1][['ICUSTAY_ID','ITEMID']].reset_index(drop=True)\n",
    "\n",
    "display(icustayid_and_itemid_with_multiple_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the chartevents_subset based on icustayid_and_itemid_with_multiple_measurements\n",
    "chartevents_subset_multiple_values_only = pd.merge(chartevents_subset,icustayid_and_itemid_with_multiple_measurements)\n",
    "# The chartevents_subset_multiple_values_only data frame will be used as the basis for the final chartevents_clean data frame\n",
    "display(chartevents_subset_multiple_values_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_subset_multiple_values as parquet file\n",
    "chartevents_subset_multiple_values_only.to_parquet('../data/chartevents_subset_multiple_values_only.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Mark parameter values outside clinically valid ranges\n",
    "\n",
    "Values outside the clinically valid ranges are flagged in a new column, not deleted."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset_multiple_values_only from parquet file\n",
    "chartevents_subset_multiple_values_only = pd.read_parquet('../data/chartevents_subset_multiple_values_only.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinically valid value ranges\n",
    "# Heart Rate (220045): 0-350\n",
    "# Non Invasive Blood Pressure systolic (220179): 0-375\n",
    "# Non Invasive Blood Pressure diastolic (220180): 0-375\n",
    "# O2 saturation pulseoxymetry (220277): 0-100\n",
    "\n",
    "# Add new column CLEANING_FLAG, which is used to mark values outside the respective clinically valid range as \"Below valid value range\" or \"Above valid value range\".\n",
    "import numpy as np\n",
    "chartevents_subset_values_flagged = chartevents_subset_multiple_values_only[['ICUSTAY_ID','ITEMID','CHARTTIME','VALUENUM']].copy()\n",
    "chartevents_subset_values_flagged.insert(loc=len(chartevents_subset_values_flagged.columns), column='CLEANING_FLAG', value=np.nan)\n",
    "\n",
    "chartevents_subset_values_flagged.loc[\n",
    "    ((chartevents_subset_values_flagged['ITEMID'] == 220045) & (chartevents_subset_values_flagged['VALUENUM'] < 0)) | \n",
    "    ((chartevents_subset_values_flagged['ITEMID'] == 220179) & (chartevents_subset_values_flagged['VALUENUM'] < 0)) | \n",
    "    ((chartevents_subset_values_flagged['ITEMID'] == 220180) & (chartevents_subset_values_flagged['VALUENUM'] < 0)) |\n",
    "    ((chartevents_subset_values_flagged['ITEMID'] == 220277) & (chartevents_subset_values_flagged['VALUENUM'] < 0)),\n",
    "    'CLEANING_FLAG'] = \"Below valid value range\"\n",
    "\n",
    "chartevents_subset_values_flagged.loc[\n",
    "    ((chartevents_subset_values_flagged['ITEMID'] == 220045) & (chartevents_subset_values_flagged['VALUENUM'] > 350)) | \n",
    "    ((chartevents_subset_values_flagged['ITEMID'] == 220179) & (chartevents_subset_values_flagged['VALUENUM'] > 375)) | \n",
    "    ((chartevents_subset_values_flagged['ITEMID'] == 220180) & (chartevents_subset_values_flagged['VALUENUM'] > 375)) |\n",
    "    ((chartevents_subset_values_flagged['ITEMID'] == 220277) & (chartevents_subset_values_flagged['VALUENUM'] > 100)),\n",
    "    'CLEANING_FLAG'] = \"Above valid value range\"\n",
    "\n",
    "# The chartevents_subset_values_flagged data frame will eventually be merged with the chartevents_subset_multiple_values_only data frame to create the final chartevents_clean data frame.\n",
    "# Only the column CLEANING_FLAG constitutes a new infomration. It is stored together with columns ICUSTAY_ID, ITEMID, CHARTTIME, and VALUENUM, which will be used during merging. The other columns are already available in the chartevents_subset_multiple_values_only data frame. For the sake of storage space and read-in speed, they are not stored again. (Strictly speaking, the VALUENUM column is not needed for merging, but for comprehensibility it is included.)\n",
    "display(chartevents_subset_values_flagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_subset_values_flagged as parquet file\n",
    "chartevents_subset_values_flagged.to_parquet('../data/chartevents_subset_values_flagged.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 215 rows, i.e. values, are below or above valid value range\n",
    "chartevents_subset_values_flagged[\n",
    "    (chartevents_subset_values_flagged.CLEANING_FLAG == \"Below valid value range\") | \n",
    "    (chartevents_subset_values_flagged.CLEANING_FLAG == \"Above valid value range\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 values are below valid value range\n",
    "chartevents_subset_values_flagged[chartevents_subset_values_flagged.CLEANING_FLAG == \"Below valid value range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 211 values are below valid value range\n",
    "chartevents_subset_values_flagged[chartevents_subset_values_flagged.CLEANING_FLAG == \"Above valid value range\"].sort_values(by=['VALUENUM'])"
   ]
  },
  {
   "source": [
    "## Threshold cleaning\n",
    "\n",
    "In the data of some ICU stays, the high and low thresholds overlap at certain points. For example, during a certain period of time, the threshold for a heart rate that is too high may be below the threshold for a heart rate that is too low, and vice versa.\n",
    "\n",
    "According to the medical experts consulted, there is no plausible reason for this. In fact, medical devices should not allow the setting of such overlapping alarm thresholds in the first place.\n",
    "\n",
    "The overlap can show up in different ways. Roughly speaking, we have observed three variants looking at time series plots:\n",
    "\n",
    "1. The low threshold temporarily exceeds the high threshold, while the latter continues 'normally'.\n",
    "2. The high threshold value temporarily falls below the low threshold value, while the latter continues 'normally'.\n",
    "3. Both thresholds temporarily overlap so that they appear swapped, which is 'abnormal' for both.\n",
    "\n",
    "There are two sub-variants for variant (3):\n",
    "\n",
    "- 3a The threshold values are swapped, but do not decrease/increase to the same extent, so it is not an exact swap.\n",
    "- 3b The thresholds are swapped, decreasing/increasing  to the same extent, so it looks like an exact swap.\n",
    "\n",
    "According to the agreement with medical experts, the two threshold values for case 3b (exact swap) are swapped back for the time period affected.\n",
    "\n",
    "Possibly this would also be possible for case 3a. However, this seems very complex as this case is difficult for us to distinguish from cases 1 and 2."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial thoughts on the threshold cleaning process, which I don't want to delete yet in case we still need them:\n",
    "\n",
    "    # Interpoliere für Timestamps (noch nicht implementiert)\n",
    "\n",
    "    # Für jene ICUSTAY_IDs bei denen für eine Threshold-Kombination eine Überschnitt vorliegt\n",
    "    # d.h. Wenn LOW threshold > HIGH threshold\n",
    "    # führe nachstehende Schritte durch\n",
    "\n",
    "    # Pro Threshold-Type, bereche Differenz zwischen aktuellem Threshold und zeitlich vorangegangenem Threshold\n",
    "    # Wenn der Betrag für beide Threshold-Types derselbe ist, handelt es sich entweder um einen Einstieg oder Ausstieg des Swaps\n",
    "    # Ob es ein Einstieg oder Ausstieg ist, hängt von der Kombinations aus Vorzeichen und Threshold-Type ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DRAFT PREFILTER ONLY CASES WITH CROSSING THRESHOLDS\n",
    "# thresholds_by_icustay_parameter_charttime['CROSS'] = ( thresholds_by_icustay_parameter_charttime.THRESHOLD_HIGH < thresholds_by_icustay_parameter_charttime.THRESHOLD_LOW)\n",
    "# index_list = thresholds_by_icustay_parameter_charttime[thresholds_by_icustay_parameter_charttime.CROSS == True].index\n",
    "# test = thresholds_by_icustay_parameter_charttime[\n",
    "#     (thresholds_by_icustay_parameter_charttime.CROSS == True) | \n",
    "#     (thresholds_by_icustay_parameter_charttime.index == min(index_list)-1) |\n",
    "#     (thresholds_by_icustay_parameter_charttime.index == max(index_list)+1)\n",
    "#     ].copy()\n",
    "# test"
   ]
  },
  {
   "source": [
    "### Identify potential candidates for local threshold swap\n",
    "\n",
    "Coarse detection of the ICU stay/parameter combinations for which the local swapping of thresholds is a possible option. Purpose of this preliminary step is to reduce the computational effort. The aim is to reduce the relatively complex threshold swap step to potentially affected cases.\n",
    "\n",
    "The coarse detection is done by comparing the minimum high threshold to the maximum low threshold for each ICU stay/parameter combination. If the minimum high threshold is below the maximum low threshold, the ICU stay/parameter combination is considered for threshold swapping.\n",
    "\n",
    "The output of this section is a data frame that includes the ICU stay/parameter combinations that are possible candidates for swapping. It is to be expected that the number of candidates is higher than the number of swaps eventually performed. The reason for this is that not all threshold overlaps allow a meaningful swap (see following section)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file\n",
    "chartevents_subset = pd.read_parquet('../data/chartevents_subset.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "# Create empty data frames to which will be appended during the loop\n",
    "min_threshold_high_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'THRESHOLD_HIGH_MIN', 'ITEMID_VALUE'])\n",
    "max_threshold_high_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'THRESHOLD_LOW_MAX', 'ITEMID_VALUE'])\n",
    "\n",
    "for i, parameter in parameters.iterrows():\n",
    "\n",
    "    # For current parameter, compute minimum value of high threshold for all ICU stays\n",
    "    min_threshold_high = chartevents_subset[chartevents_subset['ITEMID'] == parameter['THRESHOLD_HIGH']].groupby(['ICUSTAY_ID','ITEMID'])['VALUENUM'].min()\n",
    "    min_threshold_high = min_threshold_high.reset_index()\n",
    "    min_threshold_high = min_threshold_high[['ICUSTAY_ID','VALUENUM']].rename(columns = {'VALUENUM':'THRESHOLD_HIGH_MIN'}).assign(ITEMID_VALUE=parameter.VALUE)\n",
    "\n",
    "    # For current parameter, compute maximium value of low threshold for all ICU stays\n",
    "    max_threshold_low = chartevents_subset[chartevents_subset['ITEMID'] == parameter['THRESHOLD_LOW']].groupby(['ICUSTAY_ID','ITEMID'])['VALUENUM'].max()\n",
    "    max_threshold_low = max_threshold_low.reset_index()\n",
    "    max_threshold_low = max_threshold_low[['ICUSTAY_ID','VALUENUM']].rename(columns = {'VALUENUM':'THRESHOLD_LOW_MAX'}).assign(ITEMID_VALUE=parameter.VALUE)\n",
    "\n",
    "    # Append the results of the current parameter to the data frames for the overall results\n",
    "    min_threshold_high_per_icustay = min_threshold_high_per_icustay.append(min_threshold_high, ignore_index=True)\n",
    "    max_threshold_high_per_icustay = max_threshold_high_per_icustay.append(max_threshold_low, ignore_index=True)\n",
    "\n",
    "# Merge data frames\n",
    "threshold_min_max_per_icustay = min_threshold_high_per_icustay.merge(max_threshold_high_per_icustay, on=['ICUSTAY_ID','ITEMID_VALUE'])\n",
    "threshold_min_max_per_icustay = threshold_min_max_per_icustay[['ICUSTAY_ID', 'ITEMID_VALUE', 'THRESHOLD_HIGH_MIN', 'THRESHOLD_LOW_MAX']]\n",
    "\n",
    "display(threshold_min_max_per_icustay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify threshold swap candidates by comparing the minimum high threshold to the maximum low threshold for each ICU stay/parameter combination.\n",
    "# If the minimum low threshold is below the maximum high threshold, the ICU stay/parameter combination is considered for threshold swapping. \n",
    "threshold_min_max_per_icustay['CROSS'] = threshold_min_max_per_icustay['THRESHOLD_HIGH_MIN'] < threshold_min_max_per_icustay['THRESHOLD_LOW_MAX']\n",
    "threshold_swap_candidates = threshold_min_max_per_icustay[threshold_min_max_per_icustay['CROSS'] == True][['ICUSTAY_ID','ITEMID_VALUE']].reset_index(drop=True)\n",
    "\n",
    "display(threshold_swap_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save threshold_swap_candidates as parquet file\n",
    "threshold_swap_candidates.to_parquet('../data/threshold_swap_candidates.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "### Prepare data set for local threshold swap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file\n",
    "chartevents_subset = pd.read_parquet('../data/chartevents_subset.parquet', engine='pyarrow')\n",
    "\n",
    "# Read threshold_swap_candidates from parquet file\n",
    "threshold_swap_candidates = pd.read_parquet('../data/threshold_swap_candidates.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The threshold_swap_candidates data frame contains only the ITEMIDs of the vital sign values, not the ITEMIDs of the associated thresholds.\n",
    "# To facilitate the subsequent subsetting of the CHARTEVENTS data frame, auxiliary data frames are created with the threshold ITEMIDs.\n",
    "# The threshold ITEMIDs are combined into one data frame, which is then used to filter the CHARTEVENT data frame.\n",
    "# There is probably a smarter way to do this, but this was fast enough.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "# Create empty data frames to which will be appended during the loop\n",
    "itemid_threshold_high_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'ITEMID'])\n",
    "itemid_threshold_low_per_icustay = pd.DataFrame(columns=['ICUSTAY_ID', 'ITEMID'])\n",
    "\n",
    "for i, parameter in parameters.iterrows():\n",
    "\n",
    "    # For current parameter, create data frames with threshold ITEMIDs\n",
    "    itemid_threshold_high = threshold_swap_candidates[threshold_swap_candidates['ITEMID_VALUE'] == parameter['VALUE']][['ICUSTAY_ID']].assign(ITEMID=parameter.THRESHOLD_HIGH)\n",
    "    itemid_threshold_low = threshold_swap_candidates[threshold_swap_candidates['ITEMID_VALUE'] == parameter['VALUE']][['ICUSTAY_ID']].assign(ITEMID=parameter.THRESHOLD_LOW)\n",
    "\n",
    "    # Append the results of the current parameter to the data frames for the overall results\n",
    "    itemid_threshold_high_per_icustay = itemid_threshold_high_per_icustay.append(itemid_threshold_high, ignore_index=True)\n",
    "    itemid_threshold_low_per_icustay = itemid_threshold_low_per_icustay.append(itemid_threshold_low, ignore_index=True)\n",
    "\n",
    "# Merge data frames vertically\n",
    "threshold_swap_filter = pd.concat([itemid_threshold_high_per_icustay, itemid_threshold_low_per_icustay], axis= 0)\n",
    "\n",
    "# Sort to make it pretty (not important)\n",
    "threshold_swap_filter = threshold_swap_filter.sort_values(by=['ICUSTAY_ID','ITEMID']).reset_index(drop=True)\n",
    "\n",
    "display(threshold_swap_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the chartevents_subset based on the threshold_swap_filter\n",
    "threshold_swap_data = pd.merge(chartevents_subset,threshold_swap_filter)\n",
    "display(threshold_swap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save threshold_swap_data as parquet file\n",
    "threshold_swap_data.to_parquet('../data/threshold_swap_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "### Perform local threshold swap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file\n",
    "chartevents_subset = pd.read_parquet('../data/chartevents_subset.parquet', engine='pyarrow')\n",
    "\n",
    "# Read threshold_swap_candidates from parquet file\n",
    "threshold_swap_data = pd.read_parquet('../data/threshold_swap_data.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "icustays = threshold_swap_data.ICUSTAY_ID.unique()\n",
    "\n",
    "thresholds_fixed = pd.DataFrame(columns=['ICUSTAY_ID', 'ITEMID_VALUE', 'CHARTTIME', 'THRESHOLD_LOW_FIXED', 'THRESHOLD_HIGH_FIXED'])\n",
    "\n",
    "for icustay in icustays:\n",
    "    \n",
    "    for i, parameter in parameters.iterrows():\n",
    "        \n",
    "        threshold_high = threshold_swap_data[\n",
    "            (threshold_swap_data[\"ICUSTAY_ID\"] == icustay) & \n",
    "            (threshold_swap_data[\"ITEMID\"] == parameter['THRESHOLD_HIGH'])][\n",
    "            ['CHARTTIME','VALUENUM']\n",
    "            ].sort_values(by=['CHARTTIME']).rename(columns = {'VALUENUM':'THRESHOLD_HIGH'})\n",
    "\n",
    "        threshold_low = threshold_swap_data[\n",
    "            (threshold_swap_data[\"ICUSTAY_ID\"] == icustay) & \n",
    "            (threshold_swap_data[\"ITEMID\"] == parameter['THRESHOLD_LOW'])][\n",
    "            ['CHARTTIME','VALUENUM']\n",
    "            ].sort_values(by=['CHARTTIME']).rename(columns = {'VALUENUM':'THRESHOLD_LOW'})\n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime = threshold_high.merge(threshold_low, on=['CHARTTIME']).assign(ICUSTAY_ID=icustay, ITEMID_VALUE=parameter.VALUE)\n",
    "        \n",
    "        # Create a new column that contains the chronologically following threshold value of the same type\n",
    "        thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH_NEXT'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH'].shift(-1)\n",
    "        thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW_NEXT'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW'].shift(-1)\n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_HIGH_NEXT'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH_NEXT'] - thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH']\n",
    "        thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_LOW_NEXT'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW_NEXT'] - thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW']\n",
    "        \n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime.insert(loc=len(thresholds_by_icustay_parameter_charttime.columns), column='THRESHOLD_HIGH_FIXED', value=np.nan)\n",
    "        thresholds_by_icustay_parameter_charttime.insert(loc=len(thresholds_by_icustay_parameter_charttime.columns), column='THRESHOLD_LOW_FIXED', value=np.nan)\n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime.loc[\n",
    "            (thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH'] < thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW']) &\n",
    "            (abs(thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_HIGH_NEXT']) == abs(thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_LOW_NEXT'])),\n",
    "            'THRESHOLD_HIGH_FIXED'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW']\n",
    "\n",
    "        thresholds_by_icustay_parameter_charttime.loc[\n",
    "            (thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH'] < thresholds_by_icustay_parameter_charttime['THRESHOLD_LOW']) &\n",
    "            (abs(thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_HIGH_NEXT']) == abs(thresholds_by_icustay_parameter_charttime['DIF_THRESHOLD_LOW_NEXT'])),\n",
    "            'THRESHOLD_LOW_FIXED'] = thresholds_by_icustay_parameter_charttime['THRESHOLD_HIGH']\n",
    "        \n",
    "        thresholds_by_icustay_parameter_charttime.dropna(inplace=True)\n",
    "        thresholds_fixed_for_icustayid_itemid = thresholds_by_icustay_parameter_charttime[['ICUSTAY_ID', 'ITEMID_VALUE', 'CHARTTIME', 'THRESHOLD_LOW_FIXED', 'THRESHOLD_HIGH_FIXED']]\n",
    "\n",
    "        thresholds_fixed = thresholds_fixed.append(thresholds_fixed_for_icustayid_itemid, ignore_index=True)\n",
    "\n",
    "display(thresholds_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save thresholds_fixed as parquet file\n",
    "thresholds_fixed.to_parquet('../data/thresholds_fixed.parquet', engine='pyarrow')"
   ]
  },
  {
   "source": [
    "## Combine cleaned values and thresholds to chartevents_clean"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Read chartevents_subset from parquet file\n",
    "chartevents_subset = pd.read_parquet('../data/chartevents_subset.parquet', engine='pyarrow')\n",
    "\n",
    "# Read chartevents_subset_multiple_values_only from parquet file\n",
    "# chartevents_subset_multiple_values_only = pd.read_parquet('../data/chartevents_subset_multiple_values_only.parquet', engine='pyarrow')\n",
    "\n",
    "# Read chartevents_subset_values_flagged from parquet file\n",
    "chartevents_subset_values_flagged = pd.read_parquet('../data/chartevents_subset_values_flagged.parquet', engine='pyarrow')\n",
    "\n",
    "# Read thresholds_fixed from parquet file\n",
    "thresholds_fixed = pd.read_parquet('../data/thresholds_fixed.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge as follows\n",
    "# In the main data frame, create a new column 'VALUENUM_CLEAN' that equals 'VALUENUM' values in the first step\n",
    "# Next, set all 'VALUENUM_CLEAN' cells to NaN, where we identified a cleaning flag (above or below valid range) in the value cleaning step\n",
    "# Next, replace all 'VALUENUM_CLEAN' cells with the fixed threshold value (high or low) as applicable.\n",
    "# This means that we can use 'VALUENUM_CLEAN' in our future analysis without having to worry about the cleaning columns etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: I overlooked the fact that we are applying threshold swapping to chartevents_subset instead of chartevents_subset_multiple_values_only. \n",
    "# This can't be changed quickly since the threshold rows are not included in chartevents_subset_multiple_values_only.\n",
    "# As a result, theoretically, there may be threshold values in the combined data set for which the associated parameter values have been removed because there was not more than one data point.\n",
    "# With this in mind, please do not consider the following combination of the individual data sets as finished!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_clean = chartevents_subset.copy()\n",
    "\n",
    "# Create new column 'VALUENUM_CLEAN' that equals 'VALUENUM' values\n",
    "chartevents_clean['VALUENUM_CLEAN'] = chartevents_clean['VALUENUM']\n",
    "\n",
    "# Set all 'VALUENUM_CLEAN' cells to NaN, where we identified a cleaning flag (above or below valid range) in the value cleaning step\n",
    "chartevents_clean = chartevents_clean.merge(chartevents_subset_values_flagged, how='left', on=['ICUSTAY_ID','ITEMID','CHARTTIME','VALUENUM'])\n",
    "chartevents_clean.loc[\n",
    "    (chartevents_clean.CLEANING_FLAG == \"Below valid value range\") | \n",
    "    (chartevents_clean.CLEANING_FLAG == \"Above valid value range\"),\n",
    "    'VALUENUM_CLEAN'] = None\n",
    "\n",
    "display(chartevents_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnecessarily complicated step; could be simplified by better preparation of the data frame to be merged.\n",
    "# Needed because the thresholds_fixed data frame does contain the ITEMID_VALUE but not the threshold ITEMIDs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "parameters = pd.DataFrame({\n",
    "    'LABEL':            ['HR',      'NBPs',     'SpO2'],\n",
    "    'VALUE':            [220045,    220179,     220277],\n",
    "    'THRESHOLD_HIGH':   [220046,    223751,     223769],\n",
    "    'THRESHOLD_LOW':    [220047,    223752,     223770]})\n",
    "\n",
    "thresholds_fixed.insert(loc=len(thresholds_fixed.columns), column='ITEMID_THRESHOLD_HIGH', value=np.nan)\n",
    "thresholds_fixed.insert(loc=len(thresholds_fixed.columns), column='ITEMID_THRESHOLD_LOW', value=np.nan)\n",
    "\n",
    "for i, parameter in parameters.iterrows():\n",
    "\n",
    "    thresholds_fixed.loc[thresholds_fixed.ITEMID_VALUE == parameter['VALUE'], 'ITEMID_THRESHOLD_HIGH'] = parameter['THRESHOLD_HIGH']\n",
    "    thresholds_fixed.loc[thresholds_fixed.ITEMID_VALUE == parameter['VALUE'], 'ITEMID_THRESHOLD_LOW'] = parameter['THRESHOLD_LOW']\n",
    "\n",
    "display(thresholds_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_fixed_high = thresholds_fixed[\n",
    "    ['ICUSTAY_ID','CHARTTIME','THRESHOLD_HIGH_FIXED','ITEMID_THRESHOLD_HIGH']\n",
    "    ].rename(columns = {'THRESHOLD_HIGH_FIXED':'VALUENUM_CLEAN', 'ITEMID_THRESHOLD_HIGH':'ITEMID'})\n",
    "thresholds_fixed_high = thresholds_fixed_high[['ICUSTAY_ID','ITEMID','CHARTTIME','VALUENUM_CLEAN']]\n",
    "\n",
    "thresholds_fixed_low = thresholds_fixed[\n",
    "    ['ICUSTAY_ID','CHARTTIME','THRESHOLD_LOW_FIXED','ITEMID_THRESHOLD_LOW']\n",
    "    ].rename(columns = {'THRESHOLD_LOW_FIXED':'VALUENUM_CLEAN', 'ITEMID_THRESHOLD_LOW':'ITEMID'})\n",
    "thresholds_fixed_low = thresholds_fixed_low[['ICUSTAY_ID','ITEMID','CHARTTIME','VALUENUM_CLEAN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes quite long (approx. 11min); there is probably a better why to insert/replace the swapped threshold values in the VALUENUM_CLEAN column\n",
    "\n",
    "for i, row in thresholds_fixed_high.iterrows():\n",
    "\n",
    "    chartevents_clean.loc[\n",
    "        (chartevents_clean.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_clean.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_clean.CHARTTIME == row['CHARTTIME']), \n",
    "        'VALUENUM_CLEAN'] = row['VALUENUM_CLEAN']\n",
    "\n",
    "    chartevents_clean.loc[\n",
    "        (chartevents_clean.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_clean.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_clean.CHARTTIME == row['CHARTTIME']), \n",
    "        'CLEANING_FLAG'] = \"High threshold fixed by swap\"\n",
    "\n",
    "for i, row in thresholds_fixed_low.iterrows():\n",
    "\n",
    "    chartevents_clean.loc[\n",
    "        (chartevents_clean.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_clean.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_clean.CHARTTIME == row['CHARTTIME']), \n",
    "        'VALUENUM_CLEAN'] = row['VALUENUM_CLEAN']\n",
    "\n",
    "    chartevents_clean.loc[\n",
    "        (chartevents_clean.ICUSTAY_ID == row['ICUSTAY_ID']) &\n",
    "        (chartevents_clean.ITEMID == row['ITEMID']) &\n",
    "        (chartevents_clean.CHARTTIME == row['CHARTTIME']), \n",
    "        'CLEANING_FLAG'] = \"Low threshold fixed by swap\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check \n",
    "chartevents_clean[chartevents_clean.CLEANING_FLAG.isin(['High threshold fixed by swap','Low threshold fixed by swap'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Save chartevents_clean as parquet file\n",
    "chartevents_clean.to_parquet('../data/chartevents_clean.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDos:\n",
    "# Check whether merging the final chartevents_clean data frame works correctly\n",
    "# See issue described above, regarding the multiple values stuff"
   ]
  }
 ]
}